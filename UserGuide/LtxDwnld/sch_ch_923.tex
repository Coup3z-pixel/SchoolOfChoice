\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{amsthm}
\makeatletter
\usepackage{graphicx,epsf}
\usepackage{times,float}
\usepackage{enumerate}
\usepackage[round,comma]{natbib}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}
\usepackage{bm}
\usepackage{multirow}
%\usepackage{blkarray}
\usepackage{rotating}

\setlength{\textwidth}{6.4in} \setlength{\textheight}{8.5in}
\setlength{\topmargin}{-.2in} \setlength{\oddsidemargin}{.1in}
\renewcommand{\baselinestretch}{1.3}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem*{thm*}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{rem}{Remark}
\newtheorem{ex}{Example}
\newtheorem{fact}{Fact}
\newtheorem*{fact*}{Fact}
\newtheorem{remark}{Remark}


\newcommand{\rR}{\mathrel{R}}
\newcommand{\rP}{\mathrel{P}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\norev}{\medskip \centerline{\textbf{No Revisions Below}} \medskip}
\renewcommand{\Re}{\mathbb{R}}
\newcommand{\In}{\mathbb{Z}}

\newcommand{\bare}{\overline{e}}

\newcommand{\bq}{\mathbf{q}}

\newcommand{\cE}{\mathcal{E}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cX}{\mathcal{X}}

\newcommand{\dr}{{\dot r}}
\newcommand{\dq}{{\dot q}}
\newcommand{\dg}{{\dot g}}
\newcommand{\ddp}{{\dot p}}

\newcommand{\ho}{{\hat o}}

\newcommand{\hA}{{\hat A}}
\newcommand{\hO}{{\hat O}}

\newcommand{\halpha}{{\hat \alpha}}

\newcommand{\ta}{{\tilde a}}
\newcommand{\te}{{\tilde e}}
\newcommand{\tm}{{\tilde m}}
\newcommand{\tn}{{\tilde n}}

\newcommand{\tB}{{\tilde B}}

\newcommand{\bark}{{\overline k}}
\newcommand{\bart}{{\overline t}}

\newcommand{\varep}{\varepsilon}

\newcommand{\bone}{\mathbf{1}}

\begin{document}

\title{An Efficient, Computationally Tractable School Choice Mechanism}

\author{Andrew McLennan\footnote{School of Economics, University of
    Queensland, {\tt a.mclennan@economics.uq.edu.au}} \and  Shino
Takayama\footnote{School of Economics, University of
  Queensland, {\tt s.takayama1@uq.edu.au}} \and Yuki Tamura\footnote{Center for Behavioral Institutional Design, NYU Abu Dhabi; {\tt yuki.tamura@nyu.edu}}}

\date{\today}

\maketitle

\begin{abstract}
We provide a generalization of Hall's marriage theorem that supports a new algorithm implementing the Generalized Constrained Probabilistic Serial (GCPS) mechanism of \cite{balbuzanov22jet}, which extends the probabilistic serial mechanism of \cite{bm01} to problems with various constraints. If either the number of agents or the number of objects is not too large, this algorithm is computationally tractable. In particular, it can be applied to school choice problems with a moderate number of schools.  In our context the GCPS mechanism is efficient in a strong sense, and has no justified envy.  We provide a variant of the result of \cite{km10jet} showing that the mechanism is effectively strategy proof when the number of agents competing for each object is large.
\end{abstract}

Key Words: School Choice, Object Allocation, Efficiency, Fairness, Probabilistic Serial Mechanism, Hall's Marriage Theorem.

% \pagebreak

\bigskip

We propose a new  mechanism for allocating objects that is a specialization of the generalized constrained probabilistic serial (GCPS) mechanism of \cite{balbuzanov22jet}, which is in turn a generalization of the probabilistic serial (PS) mechanism of \cite{bm01} (henceforth BM).   In its application to school choice, which we focus on in this paper, this mechanism has several advantages over the mechanisms that are currently most commonly used.  

As in the BM ``eating'' algorithm, during the unit interval of time each students is assigned probability of receiving a seat in her favorite school, among those she is eligible for, at unit speed, until some constraint is encountered.
The general form of a constraint is that  a set of schools has only enough remaining capacity to serve the students who cannot be assigned to schools outside the set.  When this happens students who can be assigned to schools outside the set lose eligibility for additional probability of a seat at schools in the set, and the eating process continues with the students' new eligibility sets until another constraint is encountered, and so forth. In effect the constraint splits the process into two subprocesses of the same type, one related to schools in the set and another related to schools outside the set.  In this sense the process has a recursive character.

At time 1 there is a matrix of assignment probabilities that gives each student a probability distribution over schools. 
The assignment probabilities coming from our mechanism are implementable \citep{bckm13aer} in the sense that they can be achieved by probability distributions over pure assignments.  As we explain in Section \ref{sec:Implementability}, there is an efficient algorithm for generating such a random pure assignment.

We focus on a version of our mechanism in which each student is provided with a ``safe school,'' which could be the school closest to her home, with an absolute guarantee that she will not be assigned to a school that is worse than this according to her expressed preferences.  This is desirable intuitively, because of its direct consequences for welfare, but it also has important consequences for incentive compatibility.  Mechanisms that are not manipulable if agents report complete rankings of all schools become manipulable if the students are allowed to rank only a certain number of schools, as is the case in almost all actual school choice mechanisms.  Incentive compatibility is largely restored if a student only needs to rank schools that she prefers to her safe school and the number of these is usually fewer than the number she is allowed to rank.

In contrast with matching based school choice mechanisms, which produce assignments that are ex post inefficient (e.g., \cite{apr09aer}) the assignment probabilities produced by our mechanism satisfy BM's notion of $sd$-efficiency: it is impossible to give each student a probability distribution over schools that is first order stochastically dominant for her ordinal preferences, and strictly dominant for some students.   Since they are $sd$-efficient, they are ex post efficient: an implementation does not assign any probability to inefficient deterministic assignments.  

While our mechanism is not fully strategy proof, we give results showing that (unlike the Boston mechanism) it is very difficult to manipulate, roughly because manipulation by a student changes the allocation only in proportion to the extent that the student consumes probability at inferior (for her true preferences) schools, and the induced opportunities to consume preferred schools are fleeting when many students are competing for seats in each school.

Perhaps the most surprising aspect of our mechanism is its computational tractability.  For the general GCPS mechanism the computation of the relevant constraints can be burdensome.  Our Theorem \ref{th:MultiHall} is a generalization of Hall's marriage theorem that, for a somewhat larger class of problems, gives the relevant constraints in closed form.  This will allow us to describe an algorithmic implementation of the mechanism whose complexity analysis shows that the mechanism is computationally feasible, perhaps even for very large school choice problems.  One of us has implemented this algorithm, and we can report encouraging computational results.  

\section{Background and Related Literature}

In this section we briefly review the history of school choice and describe our mechanism in relation to it.  In addition we survey some of the most closely related papers. (The literature on school choice is now vast; \citet{aa22nber} is a recent survey.)  The section concludes with an overview of the contents of the rest of the paper.

The initial generation of school choice mechanisms was not theoretically well founded, and ran into difficulties.  The most famous is the Boston mechanism (also known as the immediate acceptance mechanism) in which the mechanism first tries to place as many students as possible at their top choices, then tries to place as many of the remaining students at their second choices, and so forth.  This mechanism is not strategy proof because, for example, a student who has little chance of being accepted by her favorite school may be able to significantly increase her chance of acceptance at her second favorite if she lists it as her favorite.

This problem was quickly observed in practice, and was recognized theoretically by \cite{as03aer}, who suggested mechanisms based on deferred acceptance and top trading cycles, which are bilateral matching mechanisms.   Student proposes deferred acceptance is now widely used around the world.

Mechanisms based on bilateral matching generally require that both sides of the market have strict preferences, and in some cases the preferences of the schools, which are called \emph{priorities}, are assigned randomly from among those that refine priorities mandated by policies such as eligibility for selective schools.  Respecting these priorities can result in outcomes that are inefficient in the sense that there are reassignments that respect the priorities mandated by policy, make each student no worse off, and strictly improve the assignments of some students.   In the simplest instance, if Bob prefers Carol School to Alice School, while Ted prefers Alice School, the mechanism may nevertheless assign Bob to Alice School and Ted to Carol School if Bob has higher priority than Ted at Alice School and Ted has higher priority than Bob at Carol School. In a study of New York City data \cite{apr09aer} found that the inefficiencies arising in this way are quantitatively significant.  There is less inefficiency if the students are ranked in the same way at all of the schools they are eligible for, but this does not completely eliminate inefficiency. 

\cite{ee08aer} and \cite{ku15te} propose mechanisms that adjust the outcome produced by deferred acceptance by repeated Pareto improvements, until an efficient outcome is achieved.  These adjustments necessarily violate the given priorities.  Although a student's priorities (beyond those mandated by law) are artificial, they are, in a sense, part of the student's endowment.  \cite{kesten10qje} (see also \cite{TaYu14}) proposes methods of adjustment that only violate priorities that students voluntarily relinquish, and shows that relinquishing priorities never results in a worse outcome.  In fact there are theoretical barriers to improving efficiency by manipulating the breaking of ties in the schools' rankings.  \cite{GaSh62} show that the student proposes deferred acceptance algorithm yields the best outcome for each student that can be achieved in any allocation without justified envy for the given priorities.   
Improving on results of \cite{kesten06jet} and \cite{ee08aer}, Theorem 1 of Abdulkadiro{\u{g}}lu et al.~asserts that, for any member of a large class of tie breaking rules, there is no mechanism that is both strategy proof for that tie breaking rule and gives outcomes that weakly Pareto dominate those produced by student proposes deferred acceptance.  
Priority based deferred acceptance mechanisms, and the closely related priority based top trading cycles mechanisms (c.f.~\cite{acprt20aeri} and references therein) continue to be active areas of research, and the literature is now far too extensive to survey systematically here.

We now describe the PS mechanism of BM and subsequent generalizations.  BM study a problem in which there are finite sets of agents and objects, and the problem is to assign a different object to each agent, based on their reported strict ordinal preferences.  The most common procedure for this problem is random priority: the agents are ordered randomly, the first agent chooses her favorite item, the second agent chooses her favorite of the remaining objects, and so forth.  Random priority is strategy proof, but it can produce random assignments that are not $sd$-efficient.

BM provide an intuitive description of the PS mechanism in terms of simultaneous eating.  Each object is regarded as a perfectly divisible cake of unit size.  At the beginning each agent consumes probability of her favorite cake at unit speed, and this continues until some cake is fully allocated.  At that time each agent who was eating such a cake switches to her favorite among those cakes that are not yet fully allocated, and the process continues similarly, with each agent always consuming probability of her favorite among those cakes that are not fully allocated.  Provided that there are at least as many objects as agents, at time 1 each agent has a probability distribution over the objects, and for each object the sum of the assignment probabilities is not greater than one.  The Birkhoff-von Neumann theorem implies that any such assignment of probabilities can be implemented as a probability distribution over deterministic assignments.  The PS mechanism is $sd$-efficient.

Extensions of BM's cake eating procedure have been proposed in (at least) five other papers.  \cite{KaSe06} extend the probabilistic serial mechanism to profiles of preferences that have indifferences.  Using the method of network flows (see Section \ref{sec:GenHall}) they first maximize the amount that every agent can be given of objects in their top indifference class.   Some set of agents is  a maximal ``bottleneck'' for this problem because giving them this quantity fully exhausts the relevant objects.  These objects are allocated to these agents, leaving a residual problem, to which the procedure can be applied, and this is done repeatedly, until each agent has total probability one.  Their mechanism has both the mechanism proposed by BM for strict preferences and the mechanism proposed by \cite{bm04} for matching problems with dichotomous preferences as special cases. \cite{bog15} provides a welfarist characterization of the serial rule, as extended by Katta and Sethuraman.

\cite{kojima09mss} studies perhaps the simplest extension of BM in which agents receive multiple objects.  Each agent receives $r \ge 2$ objects, and the number of objects is $r$ times the number of agents.  Each agent has a strict preference ordering of the objects and a cardinal utility function consistent with that preference, and the utility of any bundle of $r$ objects is the sum of the utilities of its elements.  The eating algorithm is defined as in BM: each agent consumes (at unit speed) probability of receiving her favorite object among those that have not already been fully allocated.  The mechanism is shown to be ordinally efficient and envy-free, but not weakly strategy proof, as we explain in more detail in Section \ref{sec:StrategyProof}.

\cite{yilmaz10geb} studies house allocation problems with existing tenants, which are object allocation problems in which some objects have owners who can insist on not receiving a worse object.  He proposes the special case of the mechanism studied here for that problem, and in particular he recognizes the relationship between Hall's marriage theorem, its generalization by \cite{Gal57}, and the set of feasible allocations.  \cite{yilmaz09geb} uses the methods of Katta and Sethuraman to extend the mechanism to the domain of preferences with indifferences.

\cite{bckm13aer} study problems in which there are constraints that require that certain sums of probabilities are bounded, either below, in which case the constraint is a \emph{floor constraint}, or above, in which case it is a \emph{ceiling constraint}.  For a problem with only ceiling constraints in which  there is a ``null object'' (e.g., being unemployed, unhoused, or unschooled) that is available in infinite supply, and which is not involved in any constraint, they propose a \emph{generalized probabilistic serial} (GPS) mechanism.  As in BM, at each moment in $[0,1]$ each agent increases her probability of receiving her favorite object among those that are available to her.  When a ceiling constraint binds with equality, the sets of available objects are revised by disallowing further consumption of probabilities that would lead to the constraint being violated.  Since the null object is always available, each agent's set of available objects is always nonempty.  Thus at time 1 each agent has total probability one, and the GPS assignment is defined as the probability shares that have been eaten by each agent at time 1.

In \cite{balbuzanov22jet} the set of feasible allocations is a given polytope $Q$ in the nonnegative orthant of the space of matrices of assignment probabilities. (\cite{EcMiZh21} follow this approach in their study of pseudo-market equilibria with constraints.)   To facilitate the discussion we quickly review some basic results (without proofs) and terminology. A \emph{polytope} may be defined to be the convex hull of a finite set of points, or as an intersection of finitely many closed half spaces that happens to be bounded.  To avoid technical detail we assume that $Q$ is full dimensional, in the sense that its affine hull is the entire Euclidean space of which it is a subset. Among the finite systems of weak linear inequalities that may be used to define $Q$, there is a unique (up to rescaling of inequalities by multiplication by positive scalars) such system that is minimal, and that is contained in any other such system.  Its elements are the \emph{facet inequalities} of $Q$.  For each facet inequality the corresponding \emph{facet} is the subset of $Q$ on which the facet inequality holds with equality.  A subset of $Q$ is a \emph{face} if it is $Q$ itself, the null set, or the intersection of some set of facets.  A polytope $Q$ is the convex hull of a finite set of points, and among the finite sets whose convex hulls are $Q$, there is a unique such set that is minimal in the sense that it is contained in any other such set, whose elements are the \emph{vertices} of $Q$.  The vertices of $Q$ may also be described as its extreme points, where an \emph{extreme point} of $Q$ is a point that cannot be expressed as a convex combination of other points of $Q$.

Balbuzanov's \emph{generalized constrained probabilistic serial} (GCPS) mechanism first constructs the intersection $R$ of the nonnegative orthant with the sum of $Q$ and the nonpositive orthant.  That is, a point in the nonnegative orthant is in  $R$ if and only if it lies below some point of $Q$.  A key result (Balbuzanov's Proposition 1) is that the facet inequalities of $R$ (other than the nonnegativity conditions) require that weighted sums of probabilities, with nonnegative weights, not exceed certain quantities.
The simplest version of Balbuzanov's procedure begins at the origin and increases each agent's probability of receiving her favorite object at unit speed until one or more of the facet inequalities of $R$ holds with equality.  At this point each agent's set of allowed objects is updated by disallowing further consumption of probabilities that would result in one of these facet inequalities being violated.  The process then continues, with each agent increasing the probability of receiving her favorite allowed object, if an allowed object exists, until additional facet inequalities of $R$ are encountered. Again each agent's set of allowed objects is updated, and so forth.  Any point in $R$ that is not in $Q$ lies below some point of $Q$, so there are some probabilities that can be increased, hence some agents that have nonempty sets of allowed objects, and consequently the process cannot halt at such a point.  For this reason the process necessarily arrives at a point in $Q$.  

In our most general model there are finite sets of agents and objects.  Each agent has a \emph{requirement}, and each object has a \emph{quota}; these are  positive real numbers.  In addition, for each agent-object pair there is an upper bound on the amount of the object that the agent is allowed to consume, or can be required to consume.  In a school choice problem the requirement of each student is one, the quota of each school is the number of seats it has, and the upper bound for a student-school pair is either zero or one, according to whether the student is eligible to attend the school and can be required in some circumstance to attend the school.
A feasible allocation is an assignment of an amount of each object to each agent that does not exceed the agent-object upper bound, such that for each agent the sum of the assignments is that agent's requirement, and for each object the sum of assignments does not exceed that object's quota.  In a feasible allocation for a school choice problem the amount of a school that is assigned to a student is the probability of the student being assigned a seat in the school.

The vast majority of school choice mechanisms limit the number of schools each student is allowed to rank, which leads to variety of problems.  Obviously, mechanisms that are strategy proof when all alternatives are ranked,  such as student proposes deferred acceptance, cease to be strategy proof when there are such limitations.    \cite{hk09jet} study the Nash equilibria of matching based mechanisms with such limitations.  \cite{chk10aer} is an experimental study of the effects of constraining the number of schools that can be ranked, for student proposes deferred acceptance and top trading cycles; a main finding is that constraints have a large negative effect on manipulability, and reduce efficiency and stability while increasing segregation.


As of 2006, of the roughly 100,000 students participating in the New York City High School match, over 8,000 were unmatched after the main round \citep{Pat06} meaning that they did not receive a seat from any school they ranked.  These students were asked to submit new rank ordered lists for the supplementary round, in which schools with unfilled capacity participated.  Students who did not receive a seat in the supplementary round were assigned administratively.  Since it is possible that a student might have been accepted at a school that filled up during the main round if she had ranked that school, students were potentially incentivized to report a false preference in order to avoid such a disastrous outcome.  

In our version of the GCPS mechanism we assume that each student has been assigned a ``safe school,'' which is the least preferred outcome the student might receive.  The safe school could be the school in the student's walk zone, or the favorite of that school and a sibling's school.  In order to achieve greater fairness, safe schools might be assigned randomly from among nearby schools.  

Having safe schools has several advantages.  The GCPS mechanism requires that a feasible allocation exists, and this requirement is met automatically if the assignment of safe schools is itself a feasible allocation.  Provided that the student has a safe school, she need only submit a ranking of the schools that she is eligible for and that are weakly preferred to the safe school.  With minor qualifications described in Section \ref{sec:StrategyProof}, if the number of schools that are preferred to the safe school is less than the number the student is allowed to rank, truthful revelation is optimal.  

The welfare comparison with systems without safe schools is theoretically ambiguous. (For a student assigned to a school that is worse than what would have been her safe school, the decrease in the ranking of her assignment is roughly offset by other students receiving assignments with higher rankings than what they would have received.) But in a more human sense it is difficult to imagine the improved assignments of the students matched in the main round of  the New York City High School match outweighing the disastrous outcomes of the students who are not matched in this round.   Intuitively, one expects such guaranteed lower bounds to be popular with students and parents for reasons that might be dismissed as ``emotional'' or ``psychological.'' 
However, the moral intuition that such guarantees are desirable seems to involve more than efficiency or welfare considerations, narrowly construed.

It turns out that safe schools can also be implemented in the context of student proposes deferred acceptance, by requiring that each school's priorities give the highest possible ranking to the students for whom that school is the safe school, and only to those students.  (If, for each school, the number of students for whom that school is the safe school is not greater than the school's capacity, student proposes deferred acceptance is well defined even though each school has an indifference class with multiple elements, because no school is ever required to decide which of several top ranked students to reject.)  In the New York City context, even if  other considerations in favor of safe schools were not thought to be compelling, a system with safe schools would be unambiguously less expensive and time consuming.  We find it quite surprising that this variant of deferred acceptance has not been noticed in the literature.

A cautious transition path to our mechanism would be to first move to student proposes deferred acceptance with safe schools.  This would generate data to which our algorithm could be applied, both to ascertain computational feasibility, and to measure the additional welfare gains, if any, that would result from switching again to our mechanism.

In its application to school choice, the mechanism proposed here need not be based on endowing the schools with artificial strict priorities.  In the most basic version the schools' priorities are dichotomous: either a student is eligible to attend a school, because she meets criteria possibly based on test scores, minority status, or gender, and she weakly prefers the school to her safe school, or she is not.  The mechanism produces assignments that are efficient, relative to the expressed preferences, including the implicit indifference of the schools and society concerning which eligible students are assigned to which schools.

In matching based mechanisms the schools' priorities can be used to advance certain policy objectives, so we need to see how our mechanism can replicate these effects.  One concern is to direct high quality or sought after resources to students for whom they are appropriate or most beneficial.  In many countries this takes the form of restricting eligibility for selective high schools to students with good grades or high test scores, and this is easily incorporated in eligibility conditions. 

In some applications of deferred acceptance the schools' priorities are used not only to break ties between students of otherwise equal priority, but also to influence the allocation of resources in a more quantitative sense.
In China \citep{WaZh20} the student's score on a standardized exam is taken to be her priority, presumably reflecting a policy objective of providing the most highly demanded resources, and the widest range of options, to the most talented students.  Some school systems assign priority points to promote affirmative action goals, or to make it more likely that students will attend schools near their homes.  In effect, deferred acceptance implicitly computes a vector of eligibility thresholds for the schools.

Our mechanism can be used to achieve a similar effect.  Suppose that each student begins with a numerical priority at each school.  If each school has a priority threshold, we can pass from this data to the dichotomous version by mandating that a student is eligible to attend a school if she weakly prefers it to her safe school and her priority at that school exceeds the school's threshold, and not otherwise.  The algorithm can be run multiple times, at each iteration increasing the eligibility thresholds of schools with high demand (as indicated by many students receiving assignment probabilities that are not close to one) and decreasing the thresholds of schools with unused capacity, until a satisfactory balance is attained.  (This more elaborate version of the mechanism continues to produce outcomes that are efficient if we regard the restriction imposed by the schools' priorities as constraints.  From the point of view of the final run, it is effectively strategy proof, so the only way that misreporting might possibly be beneficial is if the manipulator managed to maneuver the iterative adjustment process to a different endpoint, and of course it is implausible that anyone could be that foresightful.)

Whether it is a good idea to use priorities in this way is an extremely complex question.  On the one hand there is an obvious sense in which it is desirable to provide the best resources to those who can extract the greatest benefit.  On the other side, the Chinese system intensifies the intergenerational transmission of advantage.  The literature on peer effects in education \citep{EpRo11,Sac11} is extensive, finding significant effects with causal pathways that are not yet well understood.  In particular, \cite{BuSa13} find that low achieving students derive substantial benefits from having high achieving peers,  and  \cite{ViNe07} find that classroom heterogeneity can lead to higher test scores.
One could easily list numerous additional issues.  Balancing various concerns in practice requires information concerning what would actually happen under various policies.  Because our mechanism allows priorities to be coarse rather than strict, we widen the range of alternatives that can be considered, and our computational methods allow easy computation of counterfactual outcomes resulting from applying various alternatives to historical data.

One way to implement affirmative action objectives has been suggested by \cite{as03aer}.  For example, a school may be divided into three subschools, one with 30\% of the seats that is reserved for minority students, one with 30\% of the seats that is reserved for majority students, and one with 40\% of the seats that accepts all students. ``Hard'' upper and lower bounds for the percentages of students of different types are extensively used in practice, but \cite{Koj12} and \cite{HaYeYi13} point out that they lead to conflicts with other objectives, and \cite{EHYY14} suggest implementing affirmative action goals using soft bounds.  Such an approach can be implemented, at least informally, by running our algorithm multiple times while adjusting the parameters to better reconcile competing objectives.  

Motivated by matching of medical residents with hospitals in Japan and similar problems, \cite{KaKo15} study mechanisms in which regional caps on the number of residencies are implemented by imposing caps on the number of residencies at individual hospitals in the region.  (More detailed theoretical background is provided in \cite{KaKo17}.)  This can lead to a hospital rejecting applicants as a result of the hospital's cap even though other hospitals in the region have unfilled vacancies.  They propose a more flexible version of deferred acceptance in which some hospitals are allowed to exceed their caps if the total number of doctors matched to the region is below the region's cap.  Again, similar effects can be achieved by running our mechanism repeatedly while adjusting the caps of individual hospitals.  An assignment of ``safe hospitals'' to the doctors is potentially an additional policy tool, though how it might best be used is far from clear.

None of this would be of great interest if our mechanism was not also computationally tractable. One computational implementation of Balbuzanov's procedure first passes to the description of $Q$ as a convex hull of vertices.  To compute $R$ as a convex hull of vertices one adds to this vertex set all the points obtained from vertices of $Q$ by changing some of the components to zero.  After that one can pass to the description of $R$ as an intersection of finitely many half spaces, and this description can be used in the computation of the outcome, as described above.  The computational problem of passing from the description of a polytope as a convex hull of vertices to its description as an intersection of finitely many half spaces, and the reverse computation, are well studied, and efficient softwares for these tasks are available.  (See Section 3 of \cite{balbuzanov22jet}.)  However, even if the number of bounding inequalities of $Q$ and the number of bounding inequalities of $R$ are small, large data structures can arise at intermediate stages of the computation.  For example, for the problem of assigning $n$ objects to $n$ agents the numbers of facet inequalities of $Q$ and $R$ are constant multiples of $n$, but $Q$ has $n!$ vertices.

In Section \ref{sec:GenHall} we state Hall's marriage theorem and our generalization of it (Theorem \ref{th:MultiHall}) which states that there is a feasible allocation for an allocation problem of the sort we study if and only a collection of \emph{generalized marriage condition (GMC) inequalities} are satisfied, where there is one GMC inequality (which may not bind) for each pair $(J,P)$ with $J \subset I$ and $P \subset O$, where  $I$ is the set of agents and $O$ is the set of objects.
We introduce a network that is used to prove our generalization by applying the max-flow min-cut theorem of \cite{FoFu56}. We then use this result to derive sets of inequalities in closed form that contain the facet inequalities of $Q$ and $R$.  In each of the two cases there is an inequality for each pair $(J,P)$.

A pair $(J,P)$ is \emph{critical} for an allocation if its GMC inequality holds with equality.  Section \ref{sec:Critical} studies the relations between critical pairs and how they relate to feasible allocations.  A key idea is that during the allocation process, if $(J,P)$ becomes critical, then the allocation problem splits into two subproblems of the same type, one related to $J$ and $P$, and the other related to $I \setminus J$ and $O \setminus P$.  This allows us to implement the computation of the GCPS outcome using an algorithm that is recursive, in the sense that it calls itself to compute the allocations for the subproblems that arise.  

Section \ref{sec:Procedure} gives a detailed description of the computation of the GCPS outcome, in general, and in its application to school choice.  Our main concern is to show that computational complexity considerations do not pose a barrier to the application of this procedure to school choice problems of moderate size, and perhaps even to very large school choice problems.  
It turns out that for a given $J \subset I$, to determine whether a point satisfies the inequality for the pair $(J,P)$ for every $P \subset O$ is a problem whose complexity is on the order of $O(|I|\cdot|O|)$.  Similarly, for a given $J \subset I$, determining the earliest time that the allocation process encounters one of the facet inequalities for $(J,P)$ for some $P \subset O$ has similar complexity.  The situation is symmetric: for given $P \subset O$, determining whether a point satisfies the inequalities for $(J,P)$ for every $J \subset I$, and determining the earliest time in the allocation process such that one of these inequalities holds with equality, are problems of complexity  $O(|I|\cdot|O|)$.  Thus we obtain an approximate complexity of a basic step in the process of order $O(|I|\cdot|O|\cdot \min\{2^{|I|},2^{|O|}\})$.  In school choice problems the number $|I|$ of students is typically large enough to make $2^{|I|}$ prohibitively large, but for problems with a moderate number $|O|$ of schools, $2^{|O|}$ can be small enough that it does not pose an insuperable barrier.  We will argue that the particular properties of school choice actually make it reasonable to hope that our methods can be applied even to problems with hundreds of schools.

The algorithm has been programmed in an application \texttt{gcps} in the software package \emph{GCPS Schools}, which is briefly described in Section \ref{sec:GCPSSchools}.  \emph{GCPS Schools} also contains an application \texttt{make\_ex}, which generates sample school choice problems, and an implementation \texttt{purify} of the algorithm of \cite{bckm13aer} that is described briefly below and more extensively in Section \ref{sec:Implementability}.

An allocation is \emph{integral} if each of its components is an integer.
\cite{bckm13aer} say that an element of $Q$ is \emph{implementable} if it can be realized as the average of a probability distribution over integral allocations.    In particular, when the allocation variables are assignment probabilities, an allocation is implementable  if it can be realized as the average of a probability distribution over deterministic assignments.
An allocation problem of the sort we study is \emph{integral} if the requirements, quotas, and agent-object upper bounds are all integers. Theorem \ref{th:Implementability} of Section \ref{sec:Implementability} asserts that if an allocation problem of the sort we study is integral, then each of its feasible allocations is implementable; this is a special case of Theorem 1 of \cite{bckm13aer}, and in turn  the Birkhoff-von Neumann theorem is a special case of our result.  We describe their proof, as it applies to our model, obtaining an algorithm, with favorable computational complexity, for generating a random integral allocation whose distribution averages to the given allocation.   

Given a strict preference on a finite set of objects $O$, there is a derived stochastic dominance partial ordering of the space $\Delta(O)$ of probability distributions on $O$ in which one distribution is $sd$-better than another if, for any $o \in O$, the probability assigned to elements of $O$ that are at least as good as $o$ is at least as large under the first distribution as under the second.  Given a strict preference on $O$, there are also induced complete orderings of $\Delta(O)$ that correspond to assessing probability distributions lexicographically, prioritizing either maximizing the probability of receiving the best element or minimizing the probability of receiving the worst object.  
In Section \ref{sec:Efficiency} we observe that the result of
\cite{cd16} --- efficiency with respect to these orderings is equivalent to $sd$-efficiency --- extends easily to our setting, and  we show that for the problems we study the allocation produced by the GCPS mechanism is efficient in all these senses.  

In Section \ref{sec:Fairness} we show that that GCPS mechanism, applied to any allocation problem and any profile of preferences, has no justified envy in the sense of \cite{as03aer} and \cite{yilmaz10geb}.

Impossibility results of BM and \citet{yilmaz10geb} imply that the GCPS mechanism cannot be strategy proof; there must be examples in which misreporting results in higher expected utility for some cardinal utility function consistent with the true preference.  In  Section \ref{sec:StrategyProof} we present examples showing that, in the school choice context, a student may be able to achieve a stochastically dominant allocation, either by reporting that some schools are worse than the safe school when they are actually better, or by reordering the schools that are preferred to the safe school.
Nevertheless, we are able to provide two positive results for school choice.  First, reporting that a school is better than the safe school when it is actually worse always gives an allocation that is $sd$-worse.  We also provide a variant of a result of  
\cite{km10jet}, who show that the PS mechanism is effectively strategy proof if the number of objects of each type is large.  These results provide reassurance that for school choice, where there are many students for each school, failures of strategy proofness are uncommon, and do not undermine the practical usefulness of our mechanism.

Section \ref{sec:Conclusion} provides some concluding remarks.  An Appendix contains the proofs of the results of Section \ref{sec:StrategyProof}.


\section{A Generalized Hall Marriage Theorem} \label{sec:GenHall}

In this section we introduce the formal framework, state and prove the generalization of Hall's theorem, and provide useful characterizations of $Q$ and $R$.

A \emph{communal endowment economy} (CEE) is a
quintuple $$E = (I,O,r,q,g)$$ in which $I$ is a nonempty finite set of \emph{agents}, $O$ is a nonempty finite set of \emph{objects}, $r \in \Re_+^I$, $q \in \Re_+^O$, and $g$ is a matrix with entries in $\Re_+$ that are indexed by the elements of $I \times O$.  We say that $r_i$ is
$i$'s \emph{requirement}, that $q_o$ is the \emph{quota} of $o$, and that $g_{io}$ is \emph{$i$'s $o$-max}.  In comparison with most models of random assignment, the matrix $g$ is the main novelty, and we will see that it may represent several things and be used in various ways.  For example, $g_{io} = 0$ occurs both when $i$ is not eligible to consume $o$, and also when $i$ cannot be compelled to consume $o$, perhaps because it is worse than her safe school.

Several types of CEE occur in our discussion.  We say that $E$ is a \emph{Gale supply-demand CEE} if $g_{io} \in \{0,r_i\}$ for all $i \in I$ and $o \in O$.
We say that $E$ is \emph{integral} if $r \in \In_+^I$, $q \in \In_+^O$, and $g \in \In_+^{I \times O}$.
An integral $E$ is a \emph{school choice CEE} if $r_i = 1$ for all $i$, each $q_o$ is a positive integer, and $g_{io} \in \{0,1\}$ for all $i$ and $o$.   In this case elements of $I$ are \emph{students} and elements of $O$ are \emph{schools}. A school choice CEE $E$ is a  \emph{Hall marriage problem} if,  for all $i$ and $o$, $q_o = 1$ and $g_{io} \in \{0,1\}$.   In this case elements of $I$ are \emph{boys} and elements of $O$ are \emph{girls}.
Intuitively a Hall marriage problem is a bipartite graph with an edge connecting boy $i$ to girl $o$ (i.e., $g_{io} = 1$) if $i$ and $o$ are compatible.  

An \emph{allocation} for $I$ and $O$ is a
matrix $p$  with entries in $\Re_+$ that are indexed by the elements of $I \times O$.  A \emph{partial allocation} for $E$ is an allocation $p$ such that $\sum_o p_{io} \le r_i$ for all $i$, $\sum_i p_{io} \le q_o$ for all $o$, and $p_{io} \le g_{io}$ for all $i$ and $o$. A \emph{feasible allocation} is a partial allocation $m$ such that $\sum_o m_{io} = r_i$ for all $i$. 
A partial allocation $p$ is \emph{possible} if there is a feasible allocation $m$ such that $p \le m$.
Let $Q$ be the set of feasible allocations, and let $R$ be the set of possible partial allocations.

For $J \subset I$ and $P \subset O$ let $J^c = I \setminus J$ and $P^c = O \setminus P$ be the complements.  We say that $E$ satisfies the \emph{generalized marriage condition}
(GMC) if,  for every $J \subset I$ and $P \subset O$,
$$\sum_{i \in J} r_i \le \sum_{i \in J} \sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o.$$  We will refer to this relation as the \emph{GMC inequality} for the pair $(J,P)$.  Note that the GMC inequality for  $(\{i\},\emptyset)$ is  $r_i \le \sum_o g_{io}$,  and the GMC inequality for  $(I,O)$ is  $\sum_i r_i \le \sum_o q_o$, which are obvious necessary conditions  for
the existence of a feasible allocation.  More generally, the GMC is obviously necessary for the existence of a feasible allocation: the GMC inequality for $(J,P)$ states that the collective requirement of agents in $J$ is not greater than their total allowed consumption of objects outside of $P$ plus the total endowment of objects in $P$.

Our first main result is:

\begin{thm} \label{th:MultiHall}
  The CEE $E$ has a feasible allocation if and only if it satisfies the GMC.
\end{thm}

\noindent
The \cite{Gal57} supply-demand theorem\footnote{
Although this result is attributed to \cite{Gal57} by \cite{yilmaz10geb}, and perhaps others, this exact formulation does not appear in Gale's paper.  The paper does consider slightly more complicated problems, and it is easy to see that this result can be obtained from Gale's methods in the same manner.
} is the special case of this for a Gale supply-demand CEE.

If $E$ is a Hall marriage problem, the  set of \emph{neighbors} of boy $i$ is $N_g(i) = \{\, o \in O : g_{io} = 1
\,\}$, and for $J \subset I$ we set $N_g(J) = \bigcup_{i \in J}
N_g(i)$.  We say that $E$ satisfies the   \emph{marriage condition} if $$|J| \le |N_g(J)|$$ holds for all $J \subset I$.  
The GMC inequality for $J$ and $P = N_g(J)$ gives this inequality.  Conversely, for a
given $J \subset I$, the contribution of $o \in N_g(J)$ to the right
hand side of the GMC inequality is minimized if $o \in P$, and the
contribution of $o \in N_g(J)^c$ is minimized if $o \in
P^c$, so $|J| \le |N_g(J)|$ for all $J$ implies that the GMC is
satisfied.  Therefore Theorem \ref{th:MultiHall} implies that $E$ has a feasible allocation if and only if the marriage condition is satisfied.

We say that an allocation $p$ is \emph{integral} if, for all $i$ and $o$, $p_{io}$ is an integer. For a Hall marriage problem an integral feasible allocation is called a \emph{matching}.  (Each of the boys has a different partner.)  Hall's marriage theorem asserts that a Hall marriage problem has a matching if
and only if it satisfies the marriage condition.  
To pass from a feasible allocation to a matching one can repeatedly adjust the allocation along paths of fractional allocations that alternate between boys and girls, and either form a loop or pass from one incompletely allocated girl to another.  A more precise and general version of this argument is given in  Section \ref{sec:Implementability}.

If $E$ is a school choice CEE, for $i \in I$ let $$\alpha_i = \{\, o \in O : g_{io} = 1 \,\}$$ be the set of schools that $i$ might attend, and for $P \subset O$ let
$$J_P = \{\, i \in I : \alpha_i \subset P \,\} \;\, \text{and} \;\, J_P^* = \{\, i \in I : |\alpha_i \setminus P| \le 1 \,\}$$
be the set of students who must be given a seat in some school in $P$ and the set of students who are eligible for at most one school outside of $P$.
For a given $P \subset O$ the subsets of $I$ that minimize the difference between the right hand side and the left hand side of the GMC inequality are those $J$ such that
$J_P \subset J \subset J_P^*$.
Since the difference is minimized by setting $J = J_P$,  
$E$ satisfies the GMC if and only if, for all $P \subset O$, $$|J_P| \le \sum_{o \in P} q_o.$$

Our proof of Theorem \ref{th:MultiHall} is a simple application of the method of network flows.  (\cite{AhMaOr93} provides a general introduction and overview.)  We define a directed graph $(N,A)$ in which the set of \emph{nodes} is
$$N = \{s\} \cup I \cup  O \cup \{t\},$$
where $s$ is  the \emph{source} and $t$ is the \emph{sink}.  For $i \in I$ and $o \in O$ let  $a_i = (s,i)$, $a_{io} = (i,o)$, and $a_o = (o,t)$.  Then the set of \emph{arcs} is
$$A = \{\, a_i : i \in I \,\} \cup \{\, a_{io} : i \in I, o \in O \,\} \cup \{\, a_o : o \in O \,\}.$$
 

A \emph{capacity} for $(N,A)$ is a function $c \colon N \times N \to [0,\infty]$ such that $c(n,n') = 0$ whenever $(n,n') \notin A$.  
We introduce a capacity $c_E$ in which 
$$c_E(a_i) = r_i, \quad c_E(a_{io}) = g_{io}, \quad c_E(a_o) = q_o.$$ 
  
For $S \subset N$ let $S^c = N \setminus S$ be the complement.  A \emph{cut} is a set $S \subset N$ such that $s \in S$ and $t \in S^c$.  The \emph{capacity} of $S$ for a capacity $c$ is
$$c(S) = \sum_{(n,n') \in S \times S^c} c(n,n'). \eqno{(*)}$$  For example $c_E(\{s\}) = \sum_i r_i$ and $c_E(\{t\}) = \sum_o q_o$.
  
A \emph{flow} is a function $f \colon N \times N \to \Re$ such that:
\begin{enumerate}
  \item[(a)] for all $n$ and $n'$,  $f(n,n') = - f(n',n)$ and $f(n,n') \le 0$ if $(n,n') \notin A$; 
  \item[(b)] $\sum_{n' \in N} f(n',n) = 0$ for all $n \in N \setminus \{s,t\}$. 
\end{enumerate}
If  neither $(n,n')$ nor $(n',n)$ is in $A$,  then (a) implies that $f(n,n') = 0$.  If $(n',n) \notin A$ whenever $(n,n') \in A$ (as is the case for the particular graph we are studying) then $f(n,n') \ge 0$ whenever $(n,n') \in A$.
In conjunction with the other requirements, (b) can be understood as saying that for each $n$ other than $s$ and $t$,  the total flow into $n$ is equal to the total flow out.  
If $p$ is an allocation, there is a unique flow $f_p$ such that $f_p(a_{io}) = f_p(a_{oi}) = p_{io}$ for all $i$ and $o$ that is given by setting $f_p(a_i) = \sum_o p_{io}$ and $f_p(a_o) = \sum_i p_{io}$. 

The total flow into all nodes (including $s$ and $t$) is equal to the total flow out of all nodes, so the total flow out of $s$ is equal to the total flow into $t$.
This quantity is the \emph{value} of $f$:
$$|f| = \sum_{n \in N} f(s,n) = \sum_{n \in N} f(n,t).$$ 
We claim that if $f$ is a flow and $S$ is a cut, then $$|f| \le \sum_{(n,n') \in S \times S^c} f(n,n'),$$ and the inequality holds strictly if and only if $f(n',n) > 0$ for some $n \in S$ and $n' \in S^c$.
This is easy to see if  $f$ follows a path of arcs from $s$ to $t$ that does not visit any node twice, and the general case follows from the fact that any flow can be decomposed as a sum of flows following such paths.

A flow $f$ is \emph{bounded} by a capacity $c$ if $f(n,n') \le c(n,n')$ for all $(n,n')$.  (This condition holds automatically if $(n,n') \notin A$.) Evidently an allocation $p$ is a partial allocation if and only if $f_p$ is bounded by $c_E$.  If $f$ is bounded by $c$ and $S$ is a cut, then the inequality above implies that $|f| \le c(S)$, so the maximum value of flows bounded by $c$ is not greater than the minimum capacity of a cut for $c$.  In our setting, and more generally, the celebrated max-flow min-cut theorem \citep{FoFu56} asserts that these two quantities are equal. 
  
A consequence of this is that if $f$ is a maximal flow for $c$, then a cut $S$ has minimal capacity if and only if $|f| = \sum_{(n,n') \in S \times S^c} f(n,n') = c(S)$.  Since $c$ bounds $f$, this holds if and only if $f(n,n') = c(n,n')$ for all $(n,n') \in S \times S^c$.  
It is well known \citep{FoFu56,Sha61,Ore62} that the set of minimal cuts is a lattice in the sense that if $S_1$ and $S_2$ are minimal cuts, then so are $S_1 \cup S_2$ and $S_1 \cap S_2$, since
if $n \in S_1 \cup S_2$ and $n' \in (S_1 \cup S_2)^c = S_1^c \cap S_2^c$ 
(or $n \in S_1 \cap S_2$ and $n' \in (S_1 \cap S_2)^c = S_1^c \cup S_2^c$) 
then either $n \in S_1$ and $n' \in S_1^c$ or $n \in S_2$ and $n' \in S_2^c$, and in either case $f(n,n') = c(n,n')$.

For a cut $S$ let $J = S \cap I$ and $P = S \cap O$.  An arc can go from a node in $S$ to a node in $S^c$ by going from the source $s$ to a node in $J^c$, by going from a node in $J$ to a node in $P^c$, and by going from a node in $P$ to the sink $t$, so
$$c_E(S) = \sum_{i \in J^c} r_i + \sum_{i \in J} \sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o.$$
For $J \subset I$ and $P \subset O$ let
$$S_{(J,P)} = \{s\} \cup J \cup P,$$ and observe that  the GMC inequality can be rewritten as $\sum_i r_i \le c_E(S_{(J,P)})$.  The max flow-min cut theorem implies that the maximum value of a flow is the minimum over all cuts $S$ of $c_E(S)$, and every cut is $S_{(J,P)}$ for some $J$ and $P$, so there is a feasible allocation if and only if the minimum value of $c_E(S_{(J,P)})$ is $\sum_i r_i = c_E(S_{(\emptyset,\emptyset)})$.  Thus there is a feasible allocation if and only if $E$ satisfies the GMC.

Hall's marriage theorem, the Gale supply-demand theorem, and the max-flow min-cut theorem are three members of a large and important class of results in combinatorial matching theory that are equivalent in the informal sense that relatively simple arguments (described in detail by \cite{Rei78,Rei85}) allow one to pass from any member of the class to any other.  As yet another member of this class, Theorem \ref{th:MultiHall} does not provide distinctly novel mathematical information.  Its primary significance here, and perhaps more generally, is that the test it provides is in closed form.

 We now give useful characterizations of the set $Q$ of feasible allocations and the set $R$ of possible allocations.
If $p$ is a partial allocation, let $E - p = (I,O,r',q',g')$ be the derived CEE in which: $$r_i' = r_i - \sum_o p_{io}; \quad q'_o = q_o - \sum_i p_{io}; \quad g'_{io} = g_{io} - p_{io}.$$  
If $p$ is a partial allocation, $m$ is an allocation, and $p \le m$, then $m$ is a feasible allocation for $E$ if and only if $m - p$ is a feasible allocation for $E - p$.  Thus a partial allocation $p$ is possible if and only if $E - p$ has a feasible allocation, which of course is the case if and only if $E - p$ satisfies the GMC.  Substituting the definitions above into the GMC inequality for $E - p$ and $(J,P)$, then simplifying, gives
$$\sum_{i \in J^c}\sum_{o \in P} p_{io} \le -\sum_i r_i + \sum_{i \in J}\sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o. \eqno{(*)}$$

\begin{prop}
  An allocation $p$ such that $p_{io} \le g_{io}$ and $\sum_o p_{io} \le r_i$ for all $i$ and $o$ is possible if and only if ($*$) holds for all $J \subset I$ and $P \subset O$.
\end{prop}

Now consider $m \in \Re^{I \times O}_+$ such that $m_{io} \le g_{io}$ and $\sum_o m_{io} = r_i$ for all $i$ and $o$, and let $E_m = (I,O,r,q,m)$ be the CEE obtained by replacing $g$ with $m$.  If $m$ is a feasible allocation for $E$, then it is a feasible allocation for $E_m$, so $E_m$ satisfies the GMC.  Conversely, if $E_m$ satisfies the GMC, then it has a feasible allocation $m'$, but since $m' \le m$ and $r_i = \sum_o m_{io}' = \sum_o m_{io}$ for all $i$, the only possibility is $m' = m$, so $m$ is a feasible allocation for $E_m$ and thus also for $E$.  Thus $m$ is a feasible allocation if and only if $E_m$ satisfies the GMC.  Since $r_i = \sum_{o \in P} m_{io} + \sum_{o \in P^c} m_{io}$ for each $i$, we arrive at:

\begin{prop} \label{prop:mFeasible}
  $Q$ is the set of $m \in \Re^{I \times O}_+$ such that $m_{io} \le g_{io}$ and $\sum_o m_{io} = r_i$ for all $i$ and $o$ and, for all $J \subset I$ and $P \subset O$,
  $$\sum_{i \in J} \sum_{o \in P} m_{io} \le \sum_{o \in P} q_o.$$
\end{prop}



\section{Critical Pairs} \label{sec:Critical}

In this section we work with a given CEE $E$ that satisfies the GMC.
For $J \subset I$ and $P \subset O$ we say that the pair $(J,P)$ is \emph{critical} for $E$ if it satisfies the GMC inequality for $(J,P)$ with equality:
$$\sum_{i \in J} r_i = \sum_{i \in J} \sum_{o
  \in P^c} g_{io} + \sum_{o \in P} q_o.$$   
We refer to this condition as the \emph{GMC equality} for $(J,P)$. Our goal here is to understand the relationship between critical pairs and feasible allocations, and how the various critical pairs for $E$ are related.  Evidently:

\begin{lem}
  A pair $(J,P)$ is critical for $E$ if and only if any feasible allocation $m$ gives the agents in $J$ all of the endowment of objects in $P$ and also as much of the objects in $P^c$ as $g$ allows: $\sum_{i \in J} m_{io} = q_o$ for all $o \in P$ and $m_{io} = g_{io}$ for all $i \in J$ and $o \in P^c$.
\end{lem}

If $(J,P)$ is critical for $E$, then we let $$E_{(J,P)} = (J,O,r|_J,q',g|_{J \times O})$$ where $q'_o = q_o$ if $o \in P$  and $q'_o = \sum_{i \in J} g_{io}$ if $o \in P^c$, and we let  $$E^{(J,P)} = (J^c, P^c, r|_{J^c},q'',g|_{J^c \times P^c})$$ where $q'' \colon P^c \to \Re_+$ is the function $q''_o = q_o - \sum_{i \in J} g_{io}$. 
 Any feasible allocation for $E$ is the sum of a feasible  allocation for $E_{(J,P)}$ and a feasible allocation  for  $E^{(J,P)}$, so $E_{(J,P)}$ and  $E^{(J,P)}$ satisfy the GMC.  Conversely, any sum of a feasible allocation for $E_{(J,P)}$ and a feasible allocation for $E^{(J,P)}$ is a feasible allocation for $E$. Thus a critical pair splits the given allocation problem into two smaller problems \emph{of the same type}.

We say that $E$ is \emph{simple} if there are no critical pairs $(J,P)$ with $\emptyset \ne J \ne I$.  We say that $E$ is \emph{critical} if $(I,O)$ itself is a critical pair, which is the case if $\sum_i r_i = \sum_o q_o$, so that any feasible allocation consumes all of the available resources. 
If $(J,P)$ is a critical pair for $E$, then $E_{(J,P)}$ is critical.  The next result implies that if $(J,P)$ is a minimal critical pair for $E$, then $E_{(J,P)}$ is simple.

\begin{lem} \label{lemma:MinimalSimple} 
  If $(J,P)$ is critical for $E$, $J' \subset J$, and $P' \subset P$, then $(J',P')$ is critical for $E$ if and only if it is critical for $E_{(J,P)}$.
\end{lem}

\begin{proof}
  Any feasible allocation for $E$  gives the agents in $J$ all of the endowment of objects in $P$ and also as much of the objects in $P^c$ as $g$ allows, and its restriction to $J \times O$ is a feasible allocation for $E_{(J,P)}$, so if $(J',P')$ is critical for $E_{(J,P)}$, then its restriction to $J' \times O$ gives the agents in $J'$ all of the endowment of objects in $P'$ and as much of the objects in ${P'}^c$ as $g$ allows.  Thus $(J',P')$ is critical for $E$ if it is critical for $E_{(J,P)}$.
  
  Any feasible allocation for $E$ is the sum of a feasible allocation for $E_{(J,P)}$ and a feasible allocation for $E^{(J,P)}$, and any feasible allocation for $E_{(J,P)}$ can be added to this feasible allocation for $E^{(J,P)}$ to obtain a feasible allocation for $E$.  Therefore if $(J',P')$ is critical for $E$, then any feasible allocation for $E_{(J,P)}$  gives the agents in $J'$ all of the endowment of objects in $P'$ and as much of the objects in ${P'}^c$ as $g$ allows.  Thus $(J',P')$ is critical for $E_{(J,P)}$ if it is critical for $E$.
\end{proof}

A pair $(J,P)$ is critical if and only if $\sum_i r_i = c_E(S_{(J,P)})$, i.e., $S_{(J,P)}$ is a minimal cut for $c_E$.  For any pairs $(J,P)$ and $(J',P')$ the definition of $S_{(J,P)}$ easily implies that $$S_{(J,P)} \cup S_{(J',P')} = S_{(J \cup J',P \cup P')} \quad \text{and} \quad S_{(J,P)} \cap S_{(J',P')} = S_{(J \cap J',P \cap P')}.$$ 
Since the set of minimal cuts for $c_E$ is a lattice we have:

\begin{prop}
The set of critical pairs for $E$ is a lattice in the sense that if  $(J,P)$ and $(J',P')$
are critical pairs, then so are $(J \cup J',P \cup P')$ and $(J \cap J',P \cap P')$.  
\end{prop}

If $m$ is a feasible allocation for $E$, for $J \subset I$ and $P \subset O$ we say that the pair $(J,P)$ is \emph{$m$-critical} for $E$ if:
$$\sum_{i \in J} \sum_{o \in P} m_{io} = \sum_{o \in P} q_o.$$ Proposition \ref{prop:mFeasible} implies that $(J,P)$ is $m$-critical for $E$ if and only if $(J,P)$ is critical for $E_m$.  Thus:

\begin{cor} \label{cor:mCritical}
If $m$ is a feasible allocation for $E$, the set of $m$-critical pairs for $E$ is a lattice.  
\end{cor}

If $(J,P)$ is a critical pair, then any feasible allocation $m$ has $m_{io} = 0$ for all $i \in J^c$ and $o \in P$, and in this sense $g_{io} > 0$ is illusory.  We say that $E$ is \emph{tight} if $g_{io} = 0$ for all critical pairs $(J,P)$ and all $i \in J^c$ and $o \in P$.  If $(J,P)$ is a critical pair for $E$, the \emph{$(J,P)$-tightening of $E$} is the CEE $E' = (I,O,q,r,g')$ where $g'_{io} = 0$ if $i \in J^c$ and $o \in P$, and otherwise $g'_{io} = g_{io}$.  Since $E$ satisfies the GMC, it has a feasible allocation $m$, which necessarily has $m_{io} = 0$ for all $i \in J^c$ and $o \in P$, so it is a feasible allocation for $E'$, and consequently $E'$ satisfies the GMC.

\begin{lem}
    If $E = (I,O,r,q,g)$ and $E' = (I,O,r,q,g')$ are CEE's that satisfy the GMC, $g' \le g$, and $(J,P)$ is a critical pair for $E$, then $(J,P)$ is a critical pair for $E'$.
\end{lem}

\begin{proof}
  By assumption $E'$ satisfies the GMC, and in particular the GMC inequality for $(J,P)$.  On the other hand 
  $$\sum_{i \in J} r_i = \sum_{i \in J_o} \sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o \ge  \sum_{i \in J_o} \sum_{o \in P^c} g_{io}' + \sum_{o \in P} q_o$$ because $(J,P)$ is critical for $E$ and $g \ge g'$.
\end{proof}

A \emph{tightening sequence} for $E$ is a sequence $(J_1,P_1), \ldots, (J_\ell,P_\ell)$ for which there is a sequence $E_0 = E, E_1, \ldots, E_\ell$ of CEE's such that for each $j = 1, \ldots, \ell$, $(J_j,P_j)$ is a critical pair for $E_{j-1}$ and $E_j$ is the $(J_j,P_j)$-tightening of $E_{j-1}$.  By induction each $E_j$ satisfies the GMC.  If $(J_1',P_1'), \ldots, (J_{\ell'}',P_{\ell'}')$ is a second tightening sequence, then, in view of the last result, $(J_1,P_1), \ldots, (J_\ell,P_\ell),(J_1',P_1'), \ldots, (J_{\ell'}',P_{\ell'}')$ is a tightening sequence.  Therefore starting with $E$ and repeatedly tightening with respect to critical pairs, including pairs that become critical as a result of the tightening, until no further tightening is possible, leads to a tight CEE that is independent of the order of tightening, that we call the \emph{tightening of $E$}. 

When $E$ is a tight school choice CEE we can say a bit more.  We say that $P$ is a \emph{critical set of schools} for $E$ if $(J_P,P)$ is a critical pair for $E$.  

\begin{lem}
If $E$ is a tight school choice CEE that satisfies the GMC and $P$ and $P'$ are critical sets of schools for $E$ with  $P \subset P'$, then $(J_{P'} \setminus J_P, P' \setminus P)$ is critical, and $J_{P'} \setminus J_P = J_{P' \setminus P}$, so $P' \setminus P$ is a critical set of schools for $E$.
\end{lem}

\begin{proof}
  An immediate consequence of the definition of $J_P$ is that $J_P \subset J_{P'}$.  The GMC inequality for $(J_{P'} \setminus J_P,P' \setminus P)$ holds by assumption, so criticality of this pair amounts to the opposite inequality:
$$\sum_{i \in J_{P'} \setminus J_P} r_i \ge \sum_{i \in J_{P'} \setminus J_P} \sum_{o
  \in (P' \setminus P)^c} g_{io} + \sum_{o
  \in P' \setminus P} q_o$$
If we subtract the GMC equation for $(J',P')$ from this, then add the GMC equation for $(J,P)$, we find that it boils down to $$\sum_{i \in J_{P'}} \sum_{o
  \in {P'}^c} g_{io} - \sum_{i \in J_P} \sum_{o
  \in P^c} g_{io} \ge \sum_{i \in J_{P'} \setminus J_P} \sum_{o
  \in (P' \setminus P)^c} g_{io}.$$  
  Recognizing that $J_{P'} = J_P \cup (J_{P'} \setminus J_P)$, $P^c =( P' \setminus P) \cup {P'}^c$, and $(P' \setminus P)^c = {P'}^c \cup P$, we can further reduce this inequality to $-\sum_{i \in J_P} \sum_{o \in P' \setminus P} g_{io} \ge \sum_{i \in J_{P'} \setminus J_P} \sum_{o \in P} g_{io}$.  The definition of $J_P$ gives $g_{io} = 0$ for $i \in J$ and $o \in P^c$.
  For $i \in J_{P'} \setminus J_P$ tightness gives $g_{io} = 0$ for $o \in P$.
  
  We have now shown that $(J_{P'} \setminus J_P, P' \setminus P)$ is critical, so $J_{P' \setminus P} \subset J_{P'} \setminus J_P$.  If the containment is strict there is some $i \in J_{P'} \setminus J_P$ who has $g_{io} = 1$ for some $o \in (P' \setminus P)^c$, and the definition of $J_{P'}$ implies that $o \in P'$, so $o \in P$, but this is impossible because $E$ is tight.
\end{proof}

% Thus, when $E$ is a tight school choice CEE that satisfies the GMC, every critical set of schools is a union  of minimal critical sets of schools.
% Recall (Lemma \ref{lemma:MinimalSimple}) that if $(J,P)$ is a critical pair, then $E_{(J,P)}$ is critical and simple.    We have the following decomposition result.

% \begin{prop}
%  If $E$ is a tight school choice CEE that satisfies the GMC, then there is a unique partition  $P_0, P_1, \ldots, P_k$ of $O$ such that $P_1, \ldots, P_k$ are the minimal critical sets of schools and $E_1 = E_{(J_{P_1},P_1)}, \ldots, E_k = E_{(J_{P_k},P_k)}$ are simple and critical.  In addition:
 % \begin{enumerate}
%    \item[(a)] If $E$ is critical, then $P_0$ is a minimal critical set of schools for $E$, and  $E_0 = E_{(J_{P_0},P_0)}$ is simple and critical.
%    \item[(b)] If $E$ is not critical, let $E_0 = (J_0,P_0,r|_{J_0},q',g|_{J_0 \times P_0})$ where $q' \colon P_0 \to \Re_+$ is the function $q'_o = q_o - \sum_{i \in I \setminus J_0} g_{io}$.  Then $E_0$ is simple and not critical.
% \end{enumerate}
% In either case $E_0, \ldots, E_k$ is called the \emph{simple decomposition} of $E$.
% \end{prop}

\section{The Allocation Procedure} \label{sec:Procedure}

We now describe in somewhat more detail how the GCPS mechanism works for a CEE $E = (I,O,r,q,g)$ and a profile $\succ \; = (\succ_i)_{i \in I}$ of strict preferences over $O$.   (As usual, for each $i$ the derived weak preference relation is denoted by $\succeq_i$.)  The mechanism we study here has already been proposed by \cite{yilmaz10geb} for house allocation problems with existing tenants, as defined by \cite{as99jet}.  Since our main concern is to argue that this procedure is practical, we pay particular attention to providing bounds on the worst case running times of the computations, especially when $E$ is a school choice CEE.  

A first point is that the mechanism depends only on the preferences of each agent $i$ over the objects $o$ that are \emph{possible} for $i$, in the sense that $g_{io} > 0$.  In our exposition it is notationally simplest to treat each $\succ_i$ as a complete ordering of $O$, but the computational procedure refers only to preferences over possible objects, so (in contrast to the creation of priorities in deferred acceptance mechanisms for school choice) there is no need to expand the orderings of possible objects to complete orderings of $O$.

We first discuss the computational complexity of computing whether the GMC holds.  For a given $P \subset O$ the 
difference between the two sides of the GMC inequality for $(J,P)$ is minimized if $J$ contains every $i$ such that 
$r_i > \sum_{o \in P^c} g_{io}$ and $J^c$ contains every $i$ such that $r_i < \sum_{o \in P^c} g_{io}$.  Computing the sums $\sum_{o \in P^c} g_{io}$ for all $i$ requires potentially $|I||O|$ additions, which dominates the $|P|$ additional comparisons required to check the inequality.  Thus, for a given $P$, the time required to check whether the GMC inequality holds for $P$ and all $J$ is of order $O(|I||O|)$.
Similarly, for any $J \subset I$ the right hand side of the GMC inequality is minimized if $P$ contains every $o$ such that $q_o < \sum_{i \in J} g_{io}$ and $P^c$ contains every $o$ such that $q_o > \sum_{i \in J} g_{io}$. Again,  the time required to check whether the GMC inequality holds for $J$ and all $P$ is of order $O(|I||O|)$.   Depending on whether $|I|$ or $|O|$ is smaller, we can check, for every $J \subset I$, whether the GMC inequality for $(J,P)$ is satisfied for every $P \subset O$, or we can check, for every $P \subset O$, whether the GMC inequality for $(J,P)$ is satisfied for every $J \subset I$.
Thus we have a crude bound on the worst case complexity of checking the GMC that is of order $O(|I||O|\min\{2^{|I|}, 2^{|O|}\})$.  For school choice problems with a moderate number of schools this computational burden is not prohibitive, which is encouraging.

The computational problems of finding the maximum flow or a minimal cut  for a network $(N,A)$ are very well studied, and many algorithms have been developed.  \cite{GoTa88} list 15 that were known at the time of their work. As \cite{GrMcQuTa12} explain, each of the algorithms in 
\cite{GoTa88}, \cite{GuTa94}, \cite{Hoc08}, \cite{karzanov74smd}, 
\cite{KiRaTa94}, and \cite{Tar84} may be used as the relevant subroutine of a parametric minimum cut algorithm of the sort we describe later.  Each of these, and each in the list of \cite{GoTa88}, has a worst case complexity that is the number $|N|$ of nodes times the number $|A|$ of arcs times a logarithmic or linear factor.  For us this is roughly $|I|^2|O|^2$ times a logarithmic or linear factor.  

In connection with the particular problem we study, it may be possible to improve these bounds.  (For example, in \cite{GoTa88} the bounds depend in part on the maximal length of a simple (no repeated nodes) path from $s$ to $t$, which is $4|O|$ in our case if $|O| \le |I|$, but they allow it to be as large as $|N|$.  On the other hand, this bound restricts their ability to choose a maximal tree size later in their analysis.)  The practical performance of these algorithms, in general, and in application to school choice, is almost certainly much better than the worst case obtained from even a bespoke complexity analysis, and it is entirely possible that, in applications to school choice, approaches based on these algorithms would be as efficient and practical as the algorithms we describe.  At present the main virtue of our algorithms is that their complexity analysis allows us to argue convincingly that there is no computational complexity barrier to the application of the GCPS mechanism to school choice.

In the spirit of BM, we now describe the GCPS mechanism in terms of cake eating, so at each time $t$ each agent who has not already attained her requirement is increasing (at unit speed) her quantity of her favorite object among those that are still available to her, which gives a path $t \to p(t) \in R$.  
We assume that the process begins at a time $t_0 \ge 0$ with a given possible allocation $p(t_0)$.  (The process we describe here may be one stage of a recursive calculation.)   
For each $t \in [t_0,t^*]$ there are the following objects:
\begin{enumerate}
  \item[(a)] $p(t)$ is a possible allocation.
  \item[(b)] $E(t) = (I,O,r(t),q(t),g(t)) = E - p(t)$ is a CEE that satisfies the GMC.
  \item[(c)] For each $i$ such that $r_i(t) > 0$, $\alpha_i(t) = \{\, o : \text{$q_o(t) > 0$ and $g_{io}(t) > 0$} \,\}$ is $i$'s set of available objects.
  \item[(d)] For each $i$ such that $r_i(t) > 0$, $e_i^\succ(t)$ is the $\succ_i$-best element of $\alpha_i(t)$.
\end{enumerate}
We require that $r(t)$, $q(t)$, $g(t)$, and $p(t)$ are continuous and piecewise linear functions of $t$, and that when their derivatives  $\dr(t)$, $\dq(t)$, $\dg(t)$, and $\ddp(t)$ with respect to time  are defined, they satisfy the obvious conditions representing each agent $i$ such that $r_i(t) > 0$ eating $e_i^\succ(t)$ at unit speed:
\begin{enumerate}
  \item[(a)] $\dr_i(t) = -1$ if $r_i(t) > 0$, and otherwise $\dr_i(t) = 0$.
  \item[(b)] $\dq_o(t) = -|\{\, i : \text{$r_i(t) > 0$ and $e_i^\succ(t) = o$} \,\}|$.
  \item[(c)] $\dg_{io}(t) = -1$ if $r_i(t) > 0$ and $e_i^\succ(t) = o$, and otherwise $\dg_{io}(t) = 0$.
  \item[(d)] $\ddp_{io}(t) = 1$ if $r_i(t) > 0$ and $e_i^\succ(t) = o$, and otherwise $\ddp_{io}(t) = 0$.
\end{enumerate}
The process continues until the first time $t^* \ge t_0$ such that either $r(t^*) = 0$ or $E - p(t^*)$ is not simple.   If $r(t^*) = 0$, then $t^* = 1$, and the result of the GCPS mechanism is defined to be the feasible allocation $p(t^*)$.

If $E(t^*)$ is not simple, there are critical pairs $(J_1,P_1), \ldots, (J_k,P_k)$ for it.  
The GCPS mechanism has a recursive definition: the result of applying it to $E$ is \emph{by definition} the sum of $p(t^*)$ and the sum, for any $j = 1, \ldots, k$, of the results of applying it to $E(t^*)_{(J_j,P_j)}$ and $E(t^*)^{(J_j,P_j)}$.  This definition is useful computationally because it allows the computation to be expressed as a recursive descent through a series of problems of the same sort, to which the same algorithm can be applied.  For a definition that is equivalent but does not depend on the choice of $j$ we can observe that for times right after $t^*$ each agent $i$'s set of allowed objects is truncated by removing all elements of $\bigcup_{j: i \notin J_j} P_j$, with the process continuing as described above until the next time that additional pairs become critical.

To analyze the complexity of the process we examine it in finer detail.  It begins by computing the first time $t_1 \ge t_0$ such that one of the following events occurs:
\begin{enumerate}
  \item[(a)] $r_i(t_1) = 0$ for some $i$ such that $r_i(t_0) > 0$.
  \item[(b)] $q_o(t_1) = 0$ for some $o$ such that $q_o(t_0) > 0$. 
  \item[(c)] $g_{io}(t_1) = 0$ for some $i$ and $o$ such that $g_{io}(t_0) > 0$. 
  \item[(d)] $E - p(t_1)$ is not simple.
\end{enumerate}
If at $t_1$ some  of the events of type (a)--(c) occurred, then the $\alpha_i(t_1)$ and $e_i^\succ(t_1)$ are adjusted, and the process resumes following the differential equations above until the first time $t_2 \ge t_1$ such that one of (a)--(c) occurs, and so forth until we reach the time $t^*$. 

The computation of each $t_j \ne t^*$ involves some component of $r$, $q$, or $g$ becoming zero, so the maximal number of such computations is of order $O(|I||O|)$, and for each component of $r$, $q$, or $g$, at each step computing the first time at which the component would vanish if there were no other events is a linear problem of lesser complexity.

The problem of determining whether a GMC inequality holds with equality at some time prior to the first time that (a), (b), or (c) hold is an instance of a \emph{parameterized min cut} problem because the capacities of the arcs in the network associated with $E - p(t)$ change over time.  \cite{GaGrTa89} provided the first algorithm for such problems that took advantage of the similarity of the various min cut problems that arise in the course of solving the larger problem; their algorithm uses the algorithm of \cite{GoTa88} as a subroutine.  Their algorithm is restricted to problems in which the capacities of the arcs leaving $s$ are increasing  and the capacities of the arcs entering $t$ are decreasing (or vice versa) while the capacities of all other arcs are constant.  In addition to providing an overview and introduction to more recent work, \cite{GrMcQuTa12} present somewhat weaker requirements that support the methods of \cite{GaGrTa89}, but even these conditions are not satisfied by our problem.

In general, for a given $P \subset O$, determining the first time such that there is a $J \subset I$ such that the GMC inequality for $(J,P)$ holds with equality, is complicated because for each $i$ the sign of $r_i(t) - \sum_{o \in P^c} g_{io}(t)$ can change at some time.  This quantity is an affine function of $t$, so its sign can change only once, and there are various computational strategies for dealing with this, so that a tractable implementation of the GCPS mechanism is certainly possible when $|I|$ or $|O|$ is sufficiently small.  For us the more important point is that for school choice problems this issue is much simpler.  For each $i$ and $o$, if $g_{io} = 1$ initially, then $g_{io}(t) \ge r_i(t)$ for all subsequent $t$, so an event of type (c) necessarily coincides with an event of type (a).  But in a school choice problem we initially have $r_i = 1$ for all $i$, and the agents are all eating at unit speed at each time, so there are no events of type (a) until $t = 1$, at which point the computation is over.  
Thus $t_1$ is the first time such that (b) or (d) holds.  In addition, for each $i$ we have $r_i(t) - \sum_{o \in P^c} g_{io}(t) \le 0$ for all $t$.
Thus, for each $P \subset O$, determining the first time prior to an event of type (b) such that there is a $J \subset I$ such that the GMC inequality for $(J,P)$ holds with equality is a linear problem whose complexity is of order $O(|I||O|)$, and the problem of finding the first time such that an event of type (b) or (d) occurs has similar complexity.

We have now seen that the GCPS mechanism does not entail an undue computational burden for a school choice problem when the number $2^{|O|}$ is not unreasonably large.  A ``toy'' example with 20 schools, hence over a million sets of schools, runs to completion in about 10 seconds, so we might take 20 as a rough upper bound on the number of schools for which the algorithm in its simplest form is practical.  Actually, however, there are several reasons to expect that it is computationally feasible for much larger districts.

It is possible to run the algorithm with an assumption that certain sets of schools will not be components of minimal critical pairs.  If the computation succeeds, then the result does not depend on what was assumed.  If this assumption is not correct, that fact will eventually be revealed by the observation at some time that a set $P$ of schools is \textit{overallocated}, meaning that it no longer has sufficient aggregate capacity to meet the needs of the students who cannot attend schools outside of $P$.  One can then rerun the algorithm with a different set of assumptions (hopefully informed by the nature of the failure) concerning which sets of schools will be components of minimal critical pairs.  Thus there is considerable scope for methods that use trial and error.

A school district with many schools is necessarily spread across a large geographic area, and one should expect that there will be very few if any students who prefer a distant school without any special features to their much nearer safe school.  
Consider two disjoint sets $P_1, P_2 \subset O$.  Let $P = P_1 \cup P_2$. Let $J_1 = \{\, i : \sum_{o \in P_1^c} g_{io} = 0 \,\}$ be the set of students who must receive a seat at some school in $P_1$, let $J_2 = \{\, i : \sum_{o \in P_2^c} g_{io} = 0 \,\}$, and let $J = \{\, i : \sum_{o \in P^c} g_{io}  = 0\,\}$.   Clearly $J_1 \cup J_2 \subset J$, and if $(J,P)$ is a minimal critical pair, so that neither $(J_1,P_1)$ nor $(J_2,P_2)$ is critical, then $J \setminus (J_1 \cup J_1)$ must be nonempty, so that there is at least one student who must attend a school in $P$ and is able to attend schools in either $P_1$ or $P_2$.  We say that schools $o$ and $p$ are \emph{related} if there is a student $i$ such that $o$ and $p$ are both elements of $\alpha_i$.  Thinking of relatedness as an undirected graph, we see that the search for minimal sets of schools that are either critical or overallocated can be restricted to sets that restrict to connected subgraphs.

\section{GCPS Schools} \label{sec:GCPSSchools}

For the application to school choice a version of the algorithm has been encoded, using the \texttt{C} programming language, as an executable \texttt{gcps}, in the software package \texttt{GCPS Schools}\footnote{To obtain the software, open the url \texttt{https://github.com/Coup3z-pixel/SchoolOfChoice/} in a web browser.  Clicking on the file \texttt{gcps\_schools.tar} opens a page for that file.  Clicking the \texttt{raw} button on the line for the file downloads the file to your browser.  After placing the file in a suitable directory, in a Unix command line terminal at that directory give the command \texttt{tar xvf gcps\_schools.tar}.  In the directory \texttt{gcps\_schools} created by that command the document \emph{GCPS\_Schools\_User\_Guide.pdf} has further instuctions.}.  \texttt{GCPS Schools} also contains two other executables, \texttt{purify} and \texttt{make\_ex}.  The first of these is a straightforward implementation of the algorithm of \cite{bckm13aer} described in Section \ref{sec:Implementability}, which passes from the output of \texttt{gcps} to a random deterministic allocation whose distribution induces the assignment probabilities computed by \texttt{gcps}.  

The executable \texttt{make\_ex} generates random school choice problems of the sort that might occur in large school districts.  The schools and students are distributed uniformly around a circle.  Each student's safe school is the school that is closest to her home.  Each school has a random \emph{valence}, which is normally distributed, for each student-school pair there is a normally distributed \emph{idiosyncratic shock}, and the student's utility for a seat in the school is the sum of these two quantities minus the distance between her home and the school.  The schools that the student is eligible for are those that provide at least as much utility as the safe school, and the student's preference over such schools is the one induced by these utilities.

Applied to an example generated by \texttt{make\_ex} with 100 schools and 900 students, the running time of \texttt{gcps} is a few minutes.  Whether running times remain reasonable as the number of schools increases beyond 100 may depend on the typical size of the largest minimal critical sets that are encountered on the path of the algorithm, since finding such a set requires a search over all sets of the same size that satisfy certain necessary conditions.  
Our initial intuition was that critical pairs with more than (say) four elements would be extremely rare events in practice, but this turns out not to be the case.  An example with 60 schools, each with ten seats, and 9 students per school, already produces minimal critical sets with seven elements.    The running time of \texttt{gcps} seems to be roughly linear in the number of students, and it is strongly affected by the amount of excess capacity, with small excess capacity giving much longer compute times.

In all computational experiments to date the running time of \texttt{purify} is much less than the time it took \texttt{gcps} to generate its input, which strongly suggests that the running time of \texttt{purify} will not be the factor that limits the applicability of the the GCPS mechanism.

It is certainly possible that the algorithm can be further refined, and it appears to be highly parallelizable, but this has not yet been attempted.  With virtually any engineering endeavor, it makes sense to start with the easiest cases in the hope of developing insights that can guide the handling of increasingly complex problems.  Computational experiments with artificial problems often do not anticipate many of the idiosyncratic features of actual applications.
In these senses applications of the GCPS mechanism to the largest school choice problems such as New York City (over 500 schools) are distant prospects, and the feasibility of such applications cannot meaningfully be asserted at present.  But at the same time our current theoretical understanding and computational experience do not preclude such applications.

\section{Implementability} \label{sec:Implementability}

Let $E$ be an integral CEE that satisfies the GMC, and let $Q$ be the set of feasible allocations. When $E$ is a school choice CEE, an element of $Q$ is a matrix of assignment probabilities.   \cite{bckm13aer} say that such a matrix is \emph{implementable} if the assignment probabilities are those resulting from some probability distribution over deterministic assignments. 
(Recently \cite{AkNi20} expanded the scope of this concept by studying a notion of approximate implementation that is appropriate when some constraints need not be satisfied exactly.)  Recalling that the vertices of $Q$ are its extreme points, we see that in order for every element of $Q$ to be implementable, each of its vertices must be a deterministic assignment, which is to say that its entries are elements of $\{0,1\}$.  Conversely, since $Q$ is the set of convex combinations of its vertices, if each vertex is a deterministic assignment, then every element of $Q$ is implementable.

The results of Budish et el.~are more general, and in particular they apply to the set of feasible allocation of a general integral CEE.  As we explain in detail below, their Theorem 1 has the following result as a special case.

\begin{thm} \label{th:Implementability}
  Each vertex of $Q$ is integral.
\end{thm}

The Birkhoff-von Neumann theorem asserts that if $|I| = |O|$, then the set of bistochastic matrices with entries indexed by $I \times O$ is the convex hull of the set of bistochastic matrices with entries in $\{0,1\}$.   Evidently the Birkhoff-von Neumann theorem is a special case of Theorem \ref{th:Implementability}. 

We quickly review the related concepts and results of \cite{bckm13aer}.   A \emph{constraint set} is a nonempty subset of $I \times O$, and a \emph{constraint structure} $\cH$ is a set of constraint sets.  A vector of quotas $\bq = (q_S,q^S)_{S \in \cH}$ is \emph{integral} if $q_S,q^S \in \In$ for all $S$.
An allocation $m$ is feasible under $\bq$ if $q_S \le \sum_{_{io} \in S} m_{io} \le q^S$ for all $S \in \cH$.  Let $\cM_\bq$ be the set of feasible allocations for $\bq$. If $\cH$ contains all singletons, then $\cM_\bq$ is bounded, hence a polytope. The constraint structure $\cH$ is \emph{universally implementable} if, whenever $\bq$ is integral, each vertex of $\cM_\bq$ is integral.  A constraint structure is a \emph{hierarchy} if, for all $S, S' \in \cH$, we have $S \subset S'$ or $S' \subset S$ or $S \cap S' = \emptyset$, and $\cH$ is a \emph{bihierarchy} if there are hierarchies $\cH_1$ and $\cH_2$ such that $\cH_1 \cup \cH_2 = \cH$ and $\cH_1 \cap \cH_2 = \emptyset$.  Theorem 1 of \cite{bckm13aer} (which is also a generalization of the Birkhoff-von Neumann theorem) asserts that if $\cH$ is a bihierarchy, then it is universally implementable.  (Their Theorem 2 is a partial converse, giving conditions under which if $\cH$ is universally implementable, then it is a bihierarchy.)

Let $\cH = \cH^1 \cup \cH^2 \cup \cH^3$ where: 
$$\cH^1 = \{\, \{i\} \times O : i \in I \,\}, \quad \cH^2 = \{\, \{(i,o)\} : (i,o) \in I \times O \,\}, \quad \cH^3 = \{\, I \times \{o\} : o \in O \,\}.$$
We can show that $\cH$ is a bihierarchy either by setting $\cH_1 = \cH^1 \cup \cH^2$ and $\cH_2 = \cH^3$ or by setting $\cH_1 = \cH^1$ and $\cH_2 = \cH^2 \cup \cH^3$, so our Theorem \ref{th:Implementability} follows from their Theorem 1.   

The practical implementation of a random allocation depends not only on the existence of a representation of it as a convex combination of pure allocations, but also on a practical algorithm for generating a random pure allocation with a probability distribution that averages to the given allocation.  To this end we describe the argument in  Appendix B of their Online Appendices, which they attribute to Tomomi Matsui and Akihisa Tamura, as it applies to our setting.

We work with the network $(N,A)$ of Section \ref{sec:GenHall}.  If $m \in Q$, the \emph{nonintegrality set} of $m$ is $C(m) \cup D(m) \subset A$ where
$$C(m) = \{\, (i,o) \in I \times O : m_{io} \notin \In \,\} \quad \text{and} \quad D(m) = \{\, (o,t) \in O \times \{t\} : \sum_i m_{io} \notin \In \,\}.$$
We recall that the \emph{floor} of a real number $x$ is the greatest integer $n$ such that $n \le x$, and the  \emph{ceiling} of $x$ is the least integer $n$ such that $x \le n$.  Note that when $x$ is an integer, it is both the floor and ceiling of itself.  The next result implies that points of $Q$ that are not integral are not extreme points of $Q$, hence not vertices, so Theorem \ref{th:Implementability} follows.

\begin{prop} \label{th:ConvexComb}
  If $E$ is integral, $m \in Q$, and the nonintegrality set of $m$ is nonempty, then there are $m^0, m^1 \in Q \setminus \{m\}$ such that $m$ is a convex combination of $m^0$ and $m^1$, and for both $h = 0,1$:
  \begin{enumerate}
     \item[(a)] For each $i$ and $o$, $m^h_{io}$ is between the floor and the ceiling of $m_{io}$.
     \item[(b)] For each $o$, $\sum_i m^h_{io}$ is between the floor and the ceiling of $\sum_i m_{io}$.
     \item[(c)] The nonintegrality set of $m^h$ is a proper subset of the nonintegrality set of $m$.
  \end{enumerate}
\end{prop}

\begin{proof}
  An \emph{allowed cycle} is a sequence $n_1, \ldots, n_h$ of $h > 2$ distinct nodes in $I \cup O \cup \{t\}$ such that for all $g = 1, \ldots, h$ (the indices are integers mod $h$) either $(n_g,n_{g+1}) \in C(m) \cup D(m)$ (in which case we say that $(n_g,n_{g+1})$ is a \emph{forward arc}) or $(n_{g+1},n_g) \in C(m) \cup D(m)$ (in which case we say that $(n_{g+1},n_g)$ is a \emph{backward arc}).  For each $i$, since $\sum_o m_{io} = r_i \in \In$, if there is an $o \in O$ such that $(i,o) \in C(m)$, then there are at least two such $o$.  For each $o$, if there is exactly one $i$ such that $(i,o) \in C(m)$, then $\sum_i m_{io} \notin \In$ and consequently $(o,t) \in D(m)$.  Since $\sum_o \sum_i m_{io} \in \In$, there cannot be exactly one $o$ such that $(o,t) \in D(m)$.  By hypothesis there are $n_1$ and $n_2$ such that $(n_1,n_2) \in C(m)$.  If we have already chosen distinct $n_1, \ldots, n_g$ satisfying the required condition, then there is $n_{g+1} \ne n_{g-1}$ such that either $(n_g,n_{g+1}) \in C(m) \cup D(m)$ or $(n_{g+1},n_g) \in C(m) \cup D(m)$.  Since $N$ is finite, continuing in this fashion leads eventually to $n_{g+1} \in \{n_1,\ldots,n_{g-2}\}$, so an allowed cycle exists.

  Taking an allowed cycle $n_1, \ldots, n_h$ as given, for $\gamma \in \Re$ let $m^\gamma \in \Re^{I \times O}$ be the matrix with components
  $$m_{io}^\gamma = \begin{cases}
  m_{io} + \gamma, & \text{$(i,o)$ is a forward arc}, \\
  m_{io} - \gamma, & \text{$(i,o)$ is a backward arc}, \\
  m_{io}, & \text{otherwise}. \\
  \end{cases}$$
  For each $i$, if $n_g = i$, then either $(i,n_{g-1})$ is a forward arc and $(i,n_{g+1})$ is a backward arc or vice versa, so $\sum_o m_{io}^\gamma = \sum_o m_{io} = r_i$.  
  Let $\alpha$ be the smallest positive number such that one of the following occurs:
  \begin{enumerate}
    \item[(a)] $m^\alpha_{io} \in \In$ for some $(i,o) \in C(m)$.
    \item[(b)] $\sum_i  m^\alpha_{io} \in \In$ for some $(o,t) \in D(m)$.  
  \end{enumerate}
  Let $\beta$ be the smallest positive number such that $m^{-\beta}$ satisfies one of these conditions.   Let $m^0 = m^\alpha$ and $m^1 = m^{-\beta}$, so that  $m = \tfrac{\beta}{\alpha + \beta}m^0 + \tfrac{\alpha}{\alpha + \beta}m^1$.  Since $E$ is integral, $m^0$ and $m^1$ satisfy the constraints defining $Q$.  It is now easy to see that $m^0$ and $m^1$ satisfy (a)--(c) of the statement.
\end{proof}  

To generate a random integral allocation whose expectation is the given $m$ we repeatedly execute the computation described in this argument, passing to $m^0$ with probability $\tfrac{\beta}{\alpha + \beta}$ and  passing to $m^1$ with probability $\tfrac{\alpha}{\alpha + \beta}$.  The number of times this must be done is bounded by the number of elements of the nonintegrality set of $m$, and the running time of each step is bounded by a constant times the number of elements of the nonintegrality set at that step.  Thus this algorithm has an acceptable worst case complexity.  In the case of school choice, the number of elements of the nonintegrality set will typically be bounded by a small number times the number of students, and allowed cycles will typically be restricted to small geographical regions, leading to improved practical complexity.  Both for school choice and in general, if the random pure allocation is computed at the same time as the allocation itself, then it is possible to apply this procedure only at the lowest level of recursive descent, with the overall random pure allocation being the combination of the pure allocations computed there.


\section{Efficiency} \label{sec:Efficiency}

In this section we work with a fixed CEE $E$ that satisfies the GMC and a fixed profile of preferences $\succ$.  Our objective is to show that the GCPS mechanism applied to $E$ and $\succ$ yields an allocation that is efficient in a strong sense. However, we should first of all mention that mechanisms that are \emph{ordinal} (that is, based on the agents' reports of ordinal preferences) and nondictatorial often allow allocations that are inefficient relative to cardinal utility functions consistent with the ordinal preferences \citep{FeNi08,Mir09,AbChYa11,Tro12,AbChYa15}.

For $i \in I$, an allocation for $i$ is a vector $m_i = (m_{io})_{o \in O} \in \Re^O_+$ such that $m_{io} \le g_{io}$ for all $o$ and 
$\sum_o m_{io} = r_i$.  The \emph{stochastic dominance relation} ${sd}(\succ_i)$ on allocations for $i$ derived from $\succ_i$ is defined by $m_i' \, {sd}(\succ_i) \, m_i$ if $\sum_{p \succeq_i o} m_{ip}' \ge \sum_{p \succeq_i o} m_{ip}$ for all $o \in O$.  Usually in applications of this concept the components of $m_i$ are probabilities, but the concept makes perfect sense in our more general context.  We have $m_i' \, {sd}(\succ_i) \, m_i$ if and only if $\sum_o m_{io}' u_i(o) \ge \sum_o m_{io} u_i(o)$ for any cardinal utility function $u_i : O \to \Re$ such that for all $o,o' \in O$, $u_i(o) \ge u_i(o')$ if and only if $o \succeq_i o'$.  This is well known when the components of $m_i$ and $m_i'$ are probabilities, but the generalization of the result, and its proof, are straightforward.  We say that a feasible allocation $m$ is \emph{$sd$-efficient} if there does not exist a feasible allocation $m'$ such that $m_i' \, {sd}(\succ_i) \, m_i$ for all $i$ and $m_i' \ne m_i$ for at least one $i$.

Two other well-studied extensions of a given preference to preferences over lotteries relate to lexicographic preferences (\citealp{cho16geb}; \citealp{sv15wp}; \citealp{cd16}; \citealp{ss14jme}; \citealp{cho18scw}). The first extension, which is called the \emph{downward lexicographic} extension ($dl$-extension) compares two $i$-allocations as follows. One of the $i$-allocations is preferred if it assigns a higher amount of the most preferred object than the other. If the two $i$-allocations assign the same amount of the most preferred object, then the one that is preferred is the one that assigns the greater amount of the second most preferred object. If the two amounts are equal again, then the $i$-allocation that assigns a greater amount of the third most preferred object is preferred, and so on.
The second extension, which is called the \emph{upward lexicographic} extension ($ul$-extension) is a dual of the $dl$-extension. It lexicographically minimizes amounts of less preferred objects, starting from the least preferred object.  The $dl$- and $ul$-extensions yield preferences that represent the limits of standard vNM utility functions with extreme risk loving and risk aversion, respectively. 

Formally, the \emph{downward lexicographic relation} ${dl}(\succ_i)$ on allocations for $i$ derived from $\succ_i$ is defined by specifying that $m_i' \, {dl}(\succ_i) \, m_i$ if  either $m_i' = m_i$ or there is an $o \in O$ such that $\sum_{p \succeq_i o'} m_{ip}' = \sum_{p \succeq_i o'} m_{ip}$ for all $o' \in O$ such that $o' \succ_i o$ and $\sum_{p \succeq_i o} m_{ip}' > \sum_{p \succeq_i o} m_{ip}$.   The \emph{upward lexicographic relation} ${ul}(\succ_i)$ on allocations for $i$ derived from $\succ_i$ is defined by specifying that $m_i' \, {ul}(\succ_i) \, m_i$ if  either $m_i' = m_i$ or there is an $o \in O$ such that $\sum_{o' \succeq_i p} m_{ip}' = \sum_{o' \succeq_i p} m_{ip}$ for all $o' \in O$ such that $o \succ_i o'$ and $\sum_{o \succeq_i p} m_{ip}' < \sum_{o \succeq_i p} m_{ip}$.

For $e \in \{sd,dl,ul\}$, a feasible allocation $m'$ \emph{$e$-dominates} another feasible allocation $m$ if $m_i' \, e(\succ_i) \, m_i$ for all $i$ and there is some $i$ such that $m_i' \ne m_i$.  A feasible allocation $m$ is \emph{$e$-efficient} if there is no feasible allocation that $e$-dominates it.  This section's main result is:

\begin{thm}\label{th:axiom_topdown}
For $e \in \{sd,dl,ul\}$, the GCPS allocation for $E$ and $\succ$ is \emph{$e$-efficient}.  
\end{thm}

A feasible allocation $m$ is wasteful if there are an agent $i$ and objects $o,o'$ such that $o \succ_i o'$, it would be possible for $i$ to consume more $o$, but $i$ consumes a positive amount of $o'$.  Formally, $m$ is \emph{wasteful}  if there are $i$ and $o,o'$ such that $o \succ_i o'$, $m_{io} < g_{io}$,  $\sum_{j \in I} m_{jo} < q_o$, and $m_{io'} > 0$. 

Given a preference profile $\succ$ and a feasible allocation $m$, we define a binary relation $\lhd_m$ on $O$ by specifying that $o \lhd_m p$ means that there is an $i$ who is consuming a positive amount of $o$, prefers $p$ to $o$, and could consume more $p$.  
Formally, $o \lhd_m p$ if there is an $i$ such that $m_{io} > 0$, $p \succ_i o$, and $m_{ip} < g_{ip}$.
The binary relation $\lhd_m$ is \emph{cyclic} if there is a cycle $$o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0,$$ and otherwise it is \emph{acyclic}.  Given such a cycle, if, for each $l$, $i_l$ is an agent such that  $m_{i_lo_l} > 0$, $o_{l+1} \succ_{i_l} o_l$, and $m_{i_lo_{l+1}} < g_{i_lo_{l+1}}$, then
for sufficiently small $\delta > 0$ the matrix $m(\delta)$ defined by 
$$
m_{io}(\delta) =
\begin{cases}
m_{io} - \delta, &\text{if}~(i,o) \in \left\{(i_0,o_0),\hdots,(i_{h-1},o_{h-1}),(i_h,o_h)\right\}, \\
m_{io} + \delta, &\text{if}~(i,o) \in \left\{(i_0,o_1),\hdots,(i_{h-1},o_h),(i_h,o_0)\right\}, \\
m_{io}, &\text{otherwise}, 
\end{cases}
$$
is a feasible allocation that $e$-dominates $m$. The following result is essentially due to \cite{cd16}.  (Lemma 3 of BM is a precursor.)  We provide no proof because it is easy to see that their proof works essentially without any modification in our more general setting.

\begin{lem}\label{lem:cyclic} 
Let $e \in \{sd,dl,ul\}$.  An allocation $m$ is $e$-efficient if and only if $m$ is not wasteful and $\rhd_m$ is acyclic. In particular,  $sd$-efficiency, $dl$-efficiency, and $ul$-efficiency are equivalent. 
\end{lem}

\begin{proof}[Proof of Theorem \ref{th:axiom_topdown}]
Let $m$ be the allocation produced by the GCPS mechanism, applied to $E$ and $\succ$.  We will show that $m$ is not wasteful and $\lhd_m$ is acyclic.  Suppose $t^*$ is the first time such that $E(t^*)$ is not simple, and $E_0 = E_{(I_0,O_0)}, E_1 = E_{(I_1,O_1)}, \ldots, E_0 = E_{(I_k,O_k)}$ is the simple decomposition of the tightening of $E(t^*)$. 

Consider an agent $i$ and a pair $o,o'$ of objects such that $o \succ_i o'$, $m_{io} < g_{io}$, and $\sum_j m_{jo} < q_o$.  So long as $o$ is available to $i$, $i$ will not consume $o'$, so $i$ does not consume any $o'$ prior to $t^*$.   Since $E_1, \ldots, E_k$ are critical and $m$ does not consume all of $q_o$, $o \in O_0$, and since $\sum_o m_{io} < \sum_o g_{io}$, $i \in I_0$.  Therefore $o$ continues to be available to $i$ in $E_0$ after time $t^*$.  By recursion we conclude that $m_{io'} = 0$.  Thus $m$ is not wasteful.

Suppose there is a cycle $o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0$.  For each $l$ let $i_l$ be an agent such that  $m_{i_lo_l} > 0$, $o_{l+1} \succ_{i_l} o_l$, and $m_{i_lo_{l+1}} < g_{i_lo_{l+1}}$, and 
for sufficiently small $\delta > 0$ let $m(\delta)$ be the allocation defined above.  

If there is a time $t_0 < t^*$ at which $i_0$ is consuming $o_0$, at $t_0$ the quota of $o_1$ must have been exhausted, so the first time $t_1$ such that $i_1$ is consuming $o_1$ must be before $t_0$. At $t_1$ the quota of $o_2$ must have been exhausted, so the first time $t_2$ such that $i_2$ is consuming $o_2$ must be before $t_1$. Continuing this argument gives $t_0 < t_1 < \cdots < t_h < t_0$, which is impossible.  (This argument appeared already in BM.)

If, for each $l = 1, \ldots, h$, $i_l$ is not consuming $o_l$ prior to $t^*$, and $\delta < \min \{m_{i_1o_1},\ldots,m_{i_ho_h}\}$, then $m - p(t^*)$ and $m(\delta) - p(t^*)$ are feasible allocations for $E(t^*)$.  Since $E_1, \ldots, E_k$ are critical, the only way that this can happen is if there is some $l$ such that $i_0, \ldots, i_h \in I_l$ and $o_1, \ldots, o_h \in O_l$, but then the same argument can be applied to  the restriction of $m - p(t^*)$ to $E_l$ , so the claim follows from recursive descent.
\end{proof}

\section{Fairness for School Choice} \label{sec:Fairness}

We now briefly consider fairness properties of the GCPS mechanism applied to a CEE $E$ and a profile of preferences $\succ$.  It is obvious from the definition that the mechanism satisfies  anonymity (the outcomes do not depend on the ordering of the agents, or their ``names") and equal treatment of equals (the GCPS gives the same allocations to $i$ and $j$ if $r_i = r_j$, $g_i = g_j$, and $\succ_i \; = \; \succ_j$).

The other fairness property considered by BM is envy-freeness.  They show that the PS mechanism is envy-free in the strong sense that if $m_i$ and $m_j$ are the allocations of the PS mechanism for $\succ$, then $m_i \, sd(\succ_i) \, m_j$.  It is not reasonable to expect this if the two agents have different opportunities, and in recognition of this \cite{as03aer} introduced a notion of no justified envy.  This concept takes on different meanings depending on the setting (for a recent discussion see \cite{RoRoSh20}).  We follow \cite{yilmaz10geb} in the context of school choice.  If $E$ is a school choice CEE, we say that $m \in Q$ \emph{has no justified envy} if, for all $i,j \in I$, if $\alpha_i \subset \alpha_j$ and $o_i \succ_i o_j$ for all $o_i \in \alpha_i$ and $o_j \in \alpha_j \setminus \alpha_i$, then $m_i \, sd(\succ_i) \, m_j$.  Intuitively, $i$'s envy of $j$ is not justified if $i$ is not eligible to attend a desirable element of $\alpha_j$, or if $j$ cannot be required to accept a seat in some element of $\alpha_i$.

\begin{prop}
  If $E$ is a school choice CEE, then $GCPS(E,\succ)$ has no justified envy.
\end{prop}

\begin{proof}
  Suppose that $i,j \in I$, $\alpha_i \subset \alpha_j$, and $o_i \succ_i o_j$ for all $o_i \in \alpha_i$ and $o_j \in \alpha_j \setminus \alpha_i$.
  At each time during the allocation process, if there is a critical set of schools $P$ such that the only remaining schools that $i$ can consume are contained in $P$, but $j$ has some remaining school outside of $P$, then $j$ is consuming some element of $\alpha_j \setminus \alpha_i$.  On the other hand, if at that time, for every critical $P$, either all the remaining schools for $j$ are contained in $P$ or there is some remaining school for $i$ that is outside $P$, then the set of remaining schools for $j$ that are contained in $\alpha_i$ is the set of remaining schools for $i$.  In either case $i$ is consuming a school that she weakly prefers to the school that $j$ is consuming.  Since this is true at all times during the allocation process, $GCPS_i(E,\succ) \, sd(\succ_i) \, GCPS_j(E,\succ)$.
\end{proof}

\section{Strategy Proofness for School Choice} \label{sec:StrategyProof}

With the exception of some of the material towards the end of Section \ref{sec:Procedure}, and the result in the last section, up to this point our results have concerned the general GCPS mechanism.  In this section we examine the extent to which the GCPS mechanism, applied specifically to school choice with safe schools, is resistant to manipulation.  We fix a school choice problem given by a school choice CEE $E$ that satisfies the GMC and a profile $\succ$ of preferences over $O$.   For each student $j$ the safe school is the $\succ_j$-worst element of $\alpha_j$.  We also fix a particular student $i \in I$ whose possible deviations from truthful reporting we will study.

BM (p.~310) show that there is no probabilistic allocation mechanism for object allocation that is ex post efficient, strategy proof, and envy free.  Theorem 4 of \citet{yilmaz10geb} states that for house allocation problems with existing tenants, there is no mechanism that is individually rational, strategy proof, and has no justified envy.
Their settings are special cases of ours, so we cannot hope that the GCPS mechanism is fully strategy proof: there necessarily exist situations in which, for some vNM utility function consistent with the true ordinal preferences, expected utility can be increased by reporting a false preference. Nevertheless we will argue that for school choice the failures of strategy proofness are minor when each school has many students, and do not significantly impair its usefulness.

There are three different ways a student might try to manipulate: a) reporting that some of the schools that are actually worse than the safe school are better than it;  b) reporting that some of the schools that are better than the safe school are worse; c) reordering of the schools that are better than the safe school.
A manipulation attempt of type a) will be called an \emph{augmentation}; following \cite{RoRo99ecma}, a manipulation attempt of type b) will be called a \emph{truncation}; a  manipulation attempt of type c) will be called a \emph{reordering}.  We discuss these in turn. 

Manipulation by augmentation is unambiguously unsuccessful:

\begin{thm} \label{th:Augmentation}
  Let $\alpha_i' = \alpha_i \cup \{o^*\}$, where $o^*$ is an element of $O \setminus \alpha_i$, and let $\succ_i'$ be a preference over $O$ that has $\alpha_i'$ as the set of schools weakly preferred to the safe school, and that  agrees with $\succ_i$ on $\alpha_i$.  Let $\succ' \; = (\succ_i',\succ_{-i})$.  Then 
$$GCPS_i(\succ) \, sd(\succ_i) \, GCPS_i(\succ').$$
\end{thm}

\noindent As a matter of logic, this result does not rule out the possibility that other forms of manipulation might become successful, or more successful, if supplemented with an augmentation, but this possibility seems to have slight practical importance.

\cite{yilmaz10geb} (Example 5) presents the following example of an unambiguously successful truncation manipulation for a house allocation problem with existing tenants\footnote{Theorem 3 of \citet{cho18scw} asserts that the PS mechanism is $dl$-strategy proof, which means that manipulation never results in a $dl$-better allocation.  This example shows that Cho's result does not extend to house allocation problems with existing tenants.}.  There are three homeowners and three houses, with  $1$ endowed with $a$, $2$ endowed with $b$, and $3$ endowed with $c$, and preferences $b \succ_1 c \succ_1 a$, $a \succ_2 b$, and $b \succ_3 a \succ_3 c$.  In the GCPS process $P = \{a\}$ becomes critical at time $\tfrac12$, with $J_P = \{2\}$, so the GCPS mechanism gives $\tfrac12 b + \tfrac12 c \to 1$,  $a \to 2$, and  $\tfrac12 b + \tfrac12 c \to 3$.  If $1$ reports the preference  $b \succ_1' a$  (i.e., $b \succ_1' a \succ_1' c$) then $P = \{a,b\}$ is critical at time $0$, and the allocation is $b \to 1$, $a \to 2$, and $c \to 3$.  As Yilmaz points out, this manipulation continues to be possible in any of the problems obtained by replacing each homeowner-current house pair with any number of copies.  For example, if there are five copies of agent $1$, three copies of agent $2$, and two copies of agent $3$, and one of the copies of agent $1$ reports  $b \succ_1' a$, then $P = \{a,b\}$ is critical at time $\tfrac23$, and the allocation gives $b$ to the deviator, $a$ to the agents of type $2$, and $\tfrac23 b + \tfrac13 c$ to nondeviant agents of type $1$ and agents of type $3$.

\cite{ab19res} introduce a notion of asymptotic strategy proofness in large economies: a mechanism is \emph{strategy proof in the large} if, along any sequence of increasingly large economies in which each agent's belief concerning the types of the other agents is given by i.i.d.~draws from a fixed distribution over the set of possible types, the maximal gains from manipulation vanish in the limit.  They show that if a mechanism is envy-free, then it is strategy proof in the large.  The intuition is that the gain from reporting an incorrect type is the sum of the gain from getting that type's allocation, which is nonpositive by envy-freeness, plus the gain from changing the overall allocation, which diminishes as the agent's importance in the economy shrinks. 
Because the example above is robust with respect to the numbers of the three types, it shows that the GCPS mechanism is not strategy proof in the large, but neverthless the intuition still has at least an informal applicability, which is reflected in Theorem \ref{th:StrategyProof} below.

In general, in order for a truncation manipulation to succeed, the manipulation must induce a critical set of schools $P$ at some time during the allocation process that includes the manipulating student's safe school and a school or schools that that student wishes to consume, and that does not include the school or schools that the student falsely reports to be worse than her safe school, so that students who can consume those schools are outside of $J_P$ and thus prevented from consuming the schools the manipulator desires.  The manipulator's safe school must be in high enough demand that the manipulator does not end up simply consuming more of that school, and the schools that the manipulator desires must also be in high demand, since otherwise the manipulator can get what she wants simply by ranking her favorite of those schools highly, in which case the manipulation does not gain anything.  

This set of requirements is rather lengthy and specific, but this type of manipulation does not seem to have a knife-edge quality, and one can easily imagine successful truncation manipulations in quite complex settings.  In addition, it does not seem that the student needs highly specific information in order to know that the manipulation is likely to succeed or at least do no harm.  In particular, if the student believes that her safe school is so popular that there is no chance that a truncation manipulation attempt will result in her consuming more of her safe school, then such an attempt can (roughly) weakly dominate truthful revelation.

To what extent does this type of manipulation impair the usefulness of the GCPS mechanism for school choice?  As we explain below, reordering manipulations are quite difficult, so a student whose safe school is not highly popular is (with minor exceptions) incentivized to reveal truthfully, independent of the extent to which others are attempting truncation manipulations.  Thus the Nash equilibria of the mechanism are not drastically different from the naive understanding of it obtained by assuming truthful revelation.  The outcome of the mechanism when there are successful truncation manipulations is $sd$-efficient for the true preferences.  Indeed, truncation manipulations seem to be mainly an annoyance from the point of view of fairness: a student with a highly desired safe school may have an opportunity (possibly at some risk) to amplify their good fortune at others' expense.

In the remainder of this section we consider reordering manipulations.  Proposition 1 of BM asserts (among other things) that the PS mechanism is weakly strategy proof: if reporting a false preference gives an allocation that is weakly  $sd$-preferred to the allocation resulting from truthful revelation, then the two allocations are the same. \cite{kojima09mss} shows, by means of the following example, that weak strategy proofness does not extend to the allocation of $r \ge 2$ objects per agent.  Let there by two agents $1$ and $2$ and four objects $a$, $b$, $c$, and $d$, so $r = 2$.  Let the true preferences be $a \succ_1 b \succ_1 c \succ_1 d$ and $b \succ_2 c \succ_2 a \succ_2 d$.  If the agents report these preferences, then the PS mechanism gives $(1,0,\tfrac12,\tfrac12)$ to agent 1 and $(0,1,\tfrac12,\tfrac12)$ to agent 2.  On the other hand, if agent 1 reports $\succ_1'$, where $b \succ_1' a \succ_1' c \succ_1' d$, and agent 2 reports $\succ_2$, then  the PS mechanism gives $(1,\tfrac12,0,\tfrac12)$ to agent 1 and $(0,\tfrac12,1,\tfrac12)$ to agent 2.  Thus, when agent 1 reports the truth she receives the probability distribution  over pairs $\tfrac12 (a,c) + \tfrac12 (a,d)$, while misrepresenting yields $\tfrac12 (a,b) + \tfrac12 (a,d)$, which stochastically dominates (in an obvious sense) the allocation resulting from truthful reporting. 

A key idea of BM's proof of their Proposition 1 is that once other agents begin eating an object, they continue until that object is exhausted.  Consequently, in order to obtain the same amount of her favorite object as in the allocation resulting from truthful revelation, an agent must report that it is her favorite.  In order to get the maximal amount of her best among the objects that are still available after her favorite has been fully allocated, she cannot report a preference that ranks it below some other object that is still available, and so forth inductively.  In the example above, consumption of a school by other students can cease before the school is fully allocated, which allows student $1$ to advantageously defer its consumption.

Since students do not consume multiple seats, one might hope that the GCPS mechanism is weakly strategy proof for school choice, but the following example shows that this is not the case.  There are five schools with $q_a = q_b = q_c = q_d = 1$ and $q_e \ge 4$.  There are eight students, with preferences $a \succ_1 b \succ_1 c \succ_1 d$, $a \succ_2 e$,  $a \succ_3 e$,  $b \succ_4 e$,   $b \succ_5 e$,   $c \succ_6 e$,  $d \succ_7 e$, and  $c \succ_8 d$.  (For each student the lowest ranked school is the safe school.)  Up until time $\tfrac13$ each student consumes her favorite school.  At time $\tfrac13$ school $a$ is exhausted, and the set $\{b,c,d\}$ also becomes critical, with remaining capacity $\tfrac13 b + \tfrac13 c + \tfrac23 d$ that is just sufficient to serve the needs of students $1$ and $8$, who cannot attend $e$.  If student $1$ reports truthfully she receives $\tfrac13 a + \tfrac13 b + \tfrac13 d$ because student $8$ consumes what remains of school $c$ between time $\tfrac13$ and time $\tfrac23$.  If instead she reports that her preference is $a \succ_1' c \succ_1' b \succ_1' d$, then she and student $8$ divide what is left of school $c$ between time $\tfrac13$ and time $\tfrac12$, so she receives $\tfrac13 a + \tfrac13 b + \tfrac16 c + \tfrac16 d$.  In this example consumption of school $b$ by other students ceases before the school is fully allocated, which allows student $1$ to defer its consumption.

We now consider a different example illustrating how strategy proofness can fail.  Suppose that $a$ and $b$ are the agent's first and second favorite object, with $q_a = q_b = 1$, and there are $A-1$ other people who have $a$ as their favorite and $B - 1$ other people who have $b$ as their favorite, where  $1 < A < B$.  Further, assume that no one outside the set of agents  who have $a$ as their favorite will ever consume any $a$ and no one outside the set of agents  who have $b$ as their favorite will ever consume any $b$.  If the agent reports the truth she will receive $\tfrac{1}{A}$ units of $a$ and none of $b$.  If she reports that $b$ is her favorite and $a$ is her second favorite, then she will consume $b$ between time $0$ and time $\tfrac{1}{B}$ while $\tfrac{A-1}{B}$ units of $A$ are being consumed by others, and then she will
receive $\tfrac{1}{A}(1 - \tfrac{A-1}{B})$ units of $a$, so her total consumption of $a$ and $b$ will be $\tfrac{1}{A}(1 + \tfrac{1}{B})$.  This can be an improvement if the utility difference between $a$ and the agent's third favorite object is more than $A$ times the utility difference between $a$ and $b$.

This example suggests that, in general, the benefit of manipulatively consuming an inferior object (to change the later availability schedule of other objects) will be small in comparison with the amount of manipulation if there are many agents competing for the objects. In the special case of our general model in which $E$ is integral and $g_{io} = r_i$ (in effect) for all $i$ and $o$,  \cite{km10jet} (henceforth KM) establish an exact result along these lines: for a given utility function $u_i$ consistent with a preference $\succ_i$, if $\min_o q_o/r_i$ is sufficiently large, then agent $i$ will not be able to increase the expected utility from the probabilistic serial mechanism by reporting a different preference $\succ_i'$.

Following KM we present a result that shows that for a given vNM utility function, if, for each student, the number of students with the same preferences and opportunities is large, relative to the ratio of the largest utility difference to the smallest utility difference, then truthful reporting is a weakly dominant strategy.

\begin{thm} \label{th:StrategyProof}
Let $E$ be a school choice CEE that satisfies the GMC, and let $\succ \; = (\succ_i)_{i \in I}$ be a preference profile.  Let $\succ_i'$ be an alternative preferences for some $i \in I$,  and let $\succ' = (\succ_i',\succ_{I \setminus \{i\}})$.  Let $u_i \colon A \to \Re$ be a cardinal utility function consistent with $\succ_i$, and let $$d_i = \min_{o \, \succ_i \, p} u_i(o) - u_i(p) \quad \text{and} \quad D_i = \max_{o \, \succ_i \, p} u_i(o) - u_i(p).$$  Let
$N_0 =  |\{\, j \in I : \text{$\alpha_j = \alpha_i$ and $\succ_j \; = \; \succ_i$} \,\}|$.
If
$$\big(1 + \frac{d_i}{D_i}\big)^{1/|O|} \ge  \frac{N_0 + 1}{N_0},$$ then $u_i(GCPS(\succ)) \ge u_i(GCPS(\succ'))$.
\end{thm}

The proof of this result has two phases.  In the first it is shown that the effect of the manipulation by a student $i$ on the overall allocation is bounded by the amount that $i$'s own consumption differs between the eating schedule induced by the true preference and eating schedule induced by the reported preference.  

The second phase bounds the benefits of the periods of time during which the student can eat from a school that would not be available if the student reported her true preference.  The additional amount of the school that the student consumes during such a period is the amount that is available at the beginning of the period divided by the number of students eating from this school.  In the KM setting the set of agents eating an object type is weakly increasing while the object type is available, so having a large number of objects of each type implies that if an object type is fully consumed, then the final rate of consumption is high.  In our setting the number of agents eating from a school can decrease when sets of schools become critical, so we need an additional assumption to insure that the number of agents competing for each school is high.  The simplest way to insure this is to assume that there are many students with the same opportunities and preferences as the manipulator.

We regard Theorem \ref{th:StrategyProof}, and especially its proof, as illustrative of the difficulties of manipulation, rather than as a complete explanation of them.  In particular, a key point is that in order to manipulate successfully, the manipulator must believe that during the time when a school is available due to the manipulation, there will be scant competition.  While this is certainly not the case under our assumption, there are many other reasons that competition for the school might be expected.   It will be evident that noticing an opportunity to manipulate typically requires much more information than a student is likely to possess. 

We have seen that manipulation by augmentation is impossible.  Manipulation by truncation is sometimes possible, and less frequently entails little risk, but it does little to change the incentives of other students, so (in contrast with the Boston mechanism) it does not lead to Nash equilibria that are drastically different from truthful revelation.  Manipulation by reordering has large costs and low rewards when there are many agents for each object, which is typically the case for school choice.  On the whole, failures of strategy proofness are minor and do little to impair the practical applicability of the GCPS mechanism to school choice.

\section{Concluding Remarks} \label{sec:Conclusion}

We have provided a school choice mechanism that is a specialization of the GCPS mechanism of \cite{balbuzanov22jet}, which is in turn a generalization of the PS mechanism of BM.  This mechanism guarantees each student a seat in a school that is at least as desirable as any of the schools she is legally entitled to attend.  When there are many students for each school, it is effectively strategy proof.  It is $sd$-efficient, which (as BM stress) is a stronger condition than ex post efficiency.  In contrast, bilateral matching mechanisms based on randomly generated priorities for the schools are (at least in their most basic forms) not even ex post efficient.  It is implementable: the assignment probabilities it generates can be obtained from a randomization over pure assignments.  It satisfies anonymity, equal treatment of equals, and a natural generalization of the envy-freeness condition satisfied by the PS mechanism.
Using a novel generalization of Hall's marriage theorem, we have described a computational implementation of this mechanism that seems to be tractable even for quite large school choice problems. 

A possibility we intend to explore in subsequent research is that instead of consuming probability of desirable objects, the agents may discard probability of undesirable objects.  In the case of $n$ agents and $n$ objects, each agent is endowed with one unit of each object, and at each time during the interval $[0,n-1]$ she discards probability of the least desirable object that she has not fully discarded for which discarding is still allowed.  Discarding of an object is disallowed when the agents' total remaining endowment of it is one, but it may also be disallowed for some agents in the event that the process reaches a facet of $R$.  The characterization of the PS mechanism given by \cite{bh12} implies that the discarding mechanism is certainly different from the probabilistic serial mechanism, but otherwise its properties await investigation.  It seems appropriate for problems, perhaps such as chore assignment, in which the agents' main concern is to avoid the objects that are most noxious for them.

A possibility stressed by BM, \cite{cho18scw}, and \cite{balbuzanov22jet} (perhaps among others) is that the mechanism can be varied by making the eating speeds depend on various things.  This seems unmotivated in school choice, but in other domains it may be quite interesting.    In particular, in chore assignment some agents may be unqualified to receive certain objects, and one may recognize this by taking away their endowments of such objects at the outset, but this seems unfair insofar it amounts to giving them a head start.  Giving such agents slower discarding speeds is one way this issue could be addressed. 

Although we have emphasized the school choice application, we expect that the underlying idea of our procedure, the application of the GCPS mechanism to a CEE, is potentially of interest in many other domains, with many variations.  


\begin{appendix}


\section{Proofs of Theorems \ref{th:Augmentation} and \ref{th:StrategyProof}} \label{app:StrategyProof}

We fix a school choice problem given by a school choice CEE $E = (I,O,r,q,g)$ that satisfies the GMC and a profile $\succ \; = (\succ_j)_{j \in I}$ of preferences over $O$.   We also fix a particular student $i \in I$ whose possible deviations from truthful reporting we will study.

For $\bart \in (0,1]$ and $j \in I$, an \emph{eating schedule} on $[0,\bart]$ is a function $e_j \colon [0,\bart] \to O$ 
that is  piecewise constant (i.e., changes objects finitely many times)  and right continuous: for any $t \in [0,\bart)$ there is an $\varep > 0$ such that $e_j(t') = e_j(t)$ for all $t' \in [t, t+\varep)$.  
For such an $e_j$ and $t \in [0,\bart]$ let
$$p_{jo}(e_j,t) = \int_0^t \bone_{e_j(s) = o} \, ds.$$

An \emph{eating function} on $[0,\bart]$ is a vector $e = (e_j)_{j \in I}$ of eating schedules.
For such an $e$ and $t \in [0,\bart]$ let $p(e,t) \in \Re_+^{I \times O}$ be the allocation with components $p_{jo}(e_j,t)$. For $P \subset O$ let $$s_P = \sum_{o \in P} q_o - \sum_{i \in J_P} r_i$$ be the total amount of seats in schools in $P$ that agents in $J_P^c$ might consume, let 
$$\sigma_P(e,t) = s_P  -  \sum_{j \in J_P^c} \sum_{o \in P} p_{jo}(e_j,t)$$ be the amount that remains at time $t$,
and let $$\tau_P(e) = \sup \{\, t \in [0,\bart] : \sigma_P(e,t) > 0 \,\}$$ be the time at which $P$ becomes critical.
For $j \in I$ and $t \in [0,\bart]$ let
$$\alpha_j(e,t) = \alpha_j  \setminus \bigcup_{P \subset O \, : \, \text{$j \in J_P^c$ and $\sigma_P(e,t) \le 0$}} P$$
be the set of schools at which $j$ can eat at time $t$.   Note that $\alpha_j(\cdot,t)$ is right continuous.
If $\alpha_j(e,t) \ne \emptyset$, let $e^{\succ_j}_j(e,t)$ be its $\succ_j$-best element.  We say that $e_j$ is \emph{$\succ_j$-myopic} during an interval $[t_0,t_1] \subset [0,\bart]$ if 
$e_j(t) = e^{\succ_j}_j(e,t)$ for all $t \in [t_0,t_1]$.

\begin{lem} \label{lemma:ExtendEat}
  For any eating schedule $e_i \colon [0,1] \to O$ for $i$ there is a unique $\bart(e_i) \in [0,1]$ and a unique eating function $e = (e_i,e_{-i})$ on $[0,\bart(e_i)]$ such that for each $j \ne i$, $e_j$ is myopic on $[0,\bart(e_i)]$.  If $\bart(e_i) < 1$, then $\bart(e_i)$ is the first time $t$ such that $e_i(t) \notin \alpha_i(e,t)$.
\end{lem}

\begin{proof}
  For any $t$, if there is a  a unique eating function $e = (e_i,e_{-i})$ on $[0,t)$ such that for each $j \ne i$, $e_j$ is myopic, then it extends uniquely to $[0,t]$ by setting $e_j(t) = e^{\succ_j}_j(e,t)$.  For any $t$, if there is a  a unique eating function $e = (e_i,e_{-i})$ on $[0,t]$ such that for each $j \ne i$, $e_j$ is myopic, and $e_i(t) \in \alpha_i(e,t)$, then for sufficiently small $\varep > 0$ there is a unique extension to $[0,t+\varep)$ defined by setting  $e_j(t') = e_j(t)$ if $t < t' < t + \varep$.
\end{proof}

In this circumstance we say that $e_{-i}$ is \emph{induced} by $e_i$.  An eating schedule $e_i \colon [0,1] \to O$ for $i$ is \emph{feasible} if $\bart(e_i) = 1$.  

\begin{lem} \label{lemma:ExtendEatTwo}
  If $e_i$ is an eating schedule on $[0,1]$ such that the partial allocation $p$ with components $p_{io}(e_i,1)$ and $p_{jo} = 0$ for all $j \ne i$ and $o \in O$ is possible, then $e_i$ is feasible.
\end{lem}

\begin{proof}
  For the eating function $e$ given by the last result, $p(e,t)$ is possible for all $t$, so $\bart(e_i) < 1$ is impossible.
\end{proof}

\subsection{Proof of Theorem \ref{th:Augmentation}}

For the given $i$, let $o^*$ be an element of $O \setminus \alpha_i$, let $\alpha_i' = \alpha_i \cup \{o^*\}$, and let $\succ_i'$ be a preference over $O$ that has $\alpha_i'$ as the set of schools weakly preferred to the safe school, and that
agrees with $\succ_i$ on $\alpha_i$.  We wish to show that the augmentation manipulation of reporting $\succ_i'$ rather than $\succ_i$ results in an allocation for $i$ that is weakly $sd(\succ_i)$ worse. 
Our method of analysis is to study how $i$'s allocation changes as  the parameter $\rho = g_{io^*}$ varies continuously between $0$ and $1$.  For $\rho \in [0,1]$ let $e^\rho$ be the eating function of the GCPS mechanism when $g_{io^*} = \rho$.  We will show that for each $o \in \alpha_i$, the probability that $i$ receives a seat in a school that is at least as good as $o$ is a piecewise linear function of $\rho$ whose derivative is everywhere nonpositive.

The quantities appearing in the GMC inequalities are linear functions of all continuous parameters, so the induced eating functions $e^\rho_j(t)$, the consumptions $p_{jo}(e^\rho,t)$, and the functions $\sigma_P(e^\rho,t)$ are piecewise linear functions of $(\rho,t)$.  The interval $[0,1]$ of possible values of $\rho = g_{io^*}$ is partitioned into finitely many nongeneric values and finitely many open intervals in which each of these functions is affine.
It suffices to show that on each of these intervals the derivative of the total consumption of schools that are weakly $\succ_i$-better than $o$ is nonpositive.  Therefore we focus  on values of $\rho$ lying in a small interval $(\rho_0 - \varep,\rho_0 + \varep)$ contained in one of the finitely many generic intervals.  We may assume that the restriction of each $\sigma_P(e^\rho,t)$ to the set of $(\rho,t)$ lying in $(\rho_0 - \varep,\rho_0 + \varep) \times [0,1]$ is linear, so there are affine functions $$t_0, t_1, \ldots, t_K \colon (\rho_0 - \varep,\rho_0 + \varep) \to [0,1]$$ with $0 \equiv t_0 < t_1 < \cdots < t_K \equiv 1$ such for each $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$ and each $k = 1, \ldots, K-1$, $t_k(\rho) = \tau_P(e^\rho)$ for one or more $P \subset O$,  and for each $k = 1, \ldots, K$ there are no $P \subset O$ such that $t_{k-1}(\rho) < \tau_P(e^\rho) < t_k(\rho)$. Since each $t_k$ is affine, there are numbers $\sigma_0, \ldots, \sigma_K$ such that 
$$t_k(\rho) = t_k(\rho_0) + \sigma_k \cdot (\rho - \rho_0)$$ for all $k$ and $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$.

For $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$ it may be the case that $i$ is excluded from consuming $o^*$ before $i$ has finished consuming $g_{io^*}$ units.  Possibly $i$ has not finished consuming all $g_{io^*}$ units at time $1$.  In both these cases small variations of $g_{io^*}$ do not change the allocation. Therefore we may assume that there is an affine function $$t^* \colon (\rho_0 - \varep,\rho_0 + \varep) \to [0,1]$$ such that for all $\rho$, $p_{io^*}(e^\rho,t^*(\rho)) = \rho = g_{io^*}$ and $p_{io^*}(e^\rho,t) < \rho$ for all $t < t^*(\rho)$, and there is a $k_1$ such that either $t^*(\rho) = t_{k_1}(\rho)$ for all $\rho$ or $t_{k_1}(\rho) < t^*(\rho) < t_{k_1+1}(\rho)$ for all $\rho$.  Since $t^*$ is affine there is a number $\sigma^*$ such that 
$$t^*(\rho) = t_k(\rho_0) + \sigma^* \cdot (\rho - \rho_0)$$ for all $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$.

For each $j \in I \setminus \{i\}$ there are $o_{j1}, \ldots, o_{jK}$ such that  $e_j^\rho(t) = o_{jk}$ for all $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$, $k = 1, \ldots, K$, and $t \in [t_{k-1}(\rho),t_k(\rho))$.  For $k \ne k_1$ there is an $o_{ik}$ such that $e_i^\rho(t) = o_{ik}$ for all $t \in [t_{k-1}(\rho),t_k(\rho))$.  There is also an $o_{ik_1}$ such that $e_i^\rho(t) = o_{ik_1}$ for all $t \in [t^*(\rho),t_{k_1 + 1}(\rho))$, and $e_i^\rho(t) = o^*$ for all $t \in [t_{k_1}(\rho), t^*(\rho))$.  For $j \in I$ and $k = 1, \ldots, K$ such that $(j,k) \ne (i,k_1)$ there is a number $\kappa_{j,k-1}$ such that
$$p_{jo_{jk}}(e^\rho,t) = p_{jo_{jk}}(e^{\rho_0},t) + \kappa_{j,k-1} \cdot (\rho - \rho_0)$$
for all $\rho$ and $t \in [t_{k-1}(\rho),t_k(\rho)) \cap [t_{k-1}(\rho_0),t_k(\rho_0))$.  There is also a number $\kappa_{ik_1}$ such that
$$p_{io_{i,k_1+1}}(e^\rho,t) = p_{io_{i,k_1+1}}(e^{\rho_0},t) + \kappa_{ik_1} \cdot (\rho - \rho_0)$$
for all $\rho$ and $t \in [t^*(\rho),t_{k_1+1}(\rho)) \cap [t^*(\rho_0),t_{k_1+1}(\rho_0))$.

By continuity, for each $k = 1, \ldots, K-1$ the set $\cP_k$ of $P \subset O$ such that $\tau_P(e^\rho) = t_k(\rho)$ is the same for all $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$. 
For $k = 1, \ldots, K-1$ and $P \in \cP_k$ let $$L_{kP} = \{\, j \in I : \text{$o_{jk} \in P$ and $j \in J_P^c$} \,\}$$
be the set of students who are required to discontinue consumption of a school in $P$.  

Consider $k$ and $P \in \cP_k$ such that $i \notin L_{kP}$.  For each $j \in L_{kP}$ we have
$$p_{jo_{jk}}(e^\rho,t_k(\rho)) - p_{jo_{jk}}(e^{\rho_0},t_k(\rho_0)) = t_k(\rho) - t_k(\rho_0) + \kappa_{j,k-1} \cdot (\rho - \rho_0) = (\sigma_k + \kappa_{j,k-1}) \cdot (\rho - \rho_0).$$
We have
$$\sum_{j \in L_{kP}} p_{jo_{jk}}(e^\rho,t_k(\rho)) = \sum_{j \in L_{kP}} p_{jo_{jk}}(e^{\rho_0},t_k(\rho_0)),$$  
so we conclude that
$$\sigma_k = -\sum_{j \in L_{kP}} \kappa_{j,k-1}/|L_{kP}|.$$
Evidently
$\kappa_{jk} = -\sigma_k$ for all $j \in L_{kP}$, and $\kappa_{jk} = \kappa_{j,k-1}$ for all $j$ such that $o_{j,k+1} = o_{jk}$.


Let $k_2$ be the smallest $k \ge k_1$ such that $i \in L_{kP}$ for some $P \in \cP_k$.  If $i \in L_{kP}$ the analysis is unaffected unless $k = k_2$.  For $k < k_2$ induction using the equations above gives $\sigma_k = 0$ and $\kappa_{jk} = 0$, and $\kappa_{j,k_2 - 1} = 0$ for all $j \ne i$.  Evidently $\kappa_{i,k_2 - 1} = -1$, so the path of analysis followed above now yields
$$\sigma_{k_2} = 1/|L_{k_2P}|.$$
Again,
$\kappa_{jk_2} = -\sigma_{k_2}$ for all $j \in L_{k_2P}$.

Since the critical sets form a lattice, for each $k \ge k_2$ there is a partition of $O$ consisting of the minimal elements of $\cP_k$ and the complement of the union of these sets.  Applying the formulas above inductively, we conclude that $\kappa_{jk} \ge 0$ for all $j$ and $\sum_j \kappa_{jk} = 1$, so that $0 \le \sigma_k \le 1$.  For any $o \in \alpha_i$, the final time that objects weakly preferred to $o$ are consumed is some $t_k(\rho)$, so increasing $g_{io^*}$ increases the total consumption of schools that are weakly $\succ_i'$-better than $o$ by no more than the increase in $g_{io^*}$, so the total consumption of schools that are weakly $\succ_i$-better than $o$ is weakly reduced.  The proof of Theorem \ref{th:Augmentation} is complete.

\subsection{Proof of Theorem \ref{th:StrategyProof}}

Our argument is an adaptation of the proof in KM.  We introduce an artificial object $\emptyset$ that is not an element of $O$, and that is available in unlimited supply, and we let $\hO = O \cup \{\emptyset\}$.  Below we consider eating schedules $e_i \colon [0,1] \to \hO$ for $i$, while the other agents eat only from $O$.  In the first phase of the analysis we begin with a feasible eating schedule $e_i^0$, consider an open interval $(\rho_0 - \varep,\rho_0 + \varep)$ such that $e_i^0$ is constant on this interval with value $o^* \in O$, and for each $\rho$ in this interval we let $e_i^\rho$ be the eating schedule that is constant on $(\rho_0 - \varep,\rho)$ with value $\emptyset$ and agrees with $e_i^0$ elsewhere.    Note that Lemma \ref{lemma:ExtendEatTwo} implies that each $e^\rho_i$ is feasible.   Let  $e^\rho_{-i}$ be the profile of eating schedules induced by $e_i^\rho$, and let $e^\rho = (e_i^\rho,e_{-i}^\rho)$.

We assume that $\rho_0$ is generic and that $\varep$ is small enough that there are affine functions $$t_0, t_1, \ldots, t_K \colon (\rho_0 - \varep,\rho_0 + \varep) \to [0,1]$$ with $0 \equiv t_0 < t_1 < \cdots < t_K \equiv 1$ such for each $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$ and each $k = 1, \ldots, K-1$, $t_k(\rho) = \tau_P(e^\rho)$ for one or more $P \subset O$,  and for each $k = 1, \ldots, K$ there are no $P \subset O$ such that $t_{k-1}(\rho) < \tau_P(e^\rho) < t_k(\rho)$. 
Let $\sigma_0, \ldots, \sigma_K$ be the numbers such that 
$$t_k(\rho) = t_k(\rho_0) + \sigma_k \cdot (\rho - \rho_0) \eqno{\text{B}(k)}$$ for all $k$ and $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$.
Similarly, for each $k = 1, \ldots, K$ and $j$ there is a number $\kappa_{j,k-1}$ such that $$p_{jo_{jk}}(e_j^\rho,t) = p_{jo_{jk}}(e_j^{\rho_0},t) +  \kappa_{j,k-1} \cdot (\rho - \rho_0), \eqno{\text{A}(k)}$$  for all $t$ such that
  $t_{k-1}(\rho) \le t \le t_k(\rho)$,

By continuity, for each $k = 1, \ldots, K-1$ the set $\cP_k$ of $P \subset O$ such that $\tau_P(e^\rho) = t_k(\rho)$ is the same for all $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$.  For $j \ne i$ and $k = 0, \ldots, K-1$ let $o_{jk} = e^{\rho_0}_j(t_{k-1}(\rho_0))$.  By continuity and $\succ_j$-maximization, $e^{\rho}_j(t) = o_{jk}$ for all $\rho$ and $t \in [t_{k-1}(\rho),t_k(\rho))$.  For $k = 1, \ldots, K$ and $P \in \cP_k$ let $$L_{kP} = \{\, j \ne i : \text{$o_{jk} \in P$ and $j \in J_P^c$} \,\}.$$  The same analysis as in the proof of Theorem \ref{th:Augmentation} gives 
  $$\sigma_k = - \sum_{j \in L_{kP}} \kappa_{j,k-1}/|L_{kP}|$$ for  all $k = 0, \ldots, K-1$.    As in the proof of Theorem \ref{th:Augmentation}, $\kappa_{jk} = -\sigma_k$ for all $j \in L_{kP}$, and $\kappa_{jk} = \kappa_{j,k-1}$ for all $j$ such that $o_{j,k+1} = o_{jk}$.

Assume that for some $k_0$ there is a $P \in \cP_{k_0}$ such that $o^* \in P$ and $i \in J_P^c$.  By induction, using the formulas above, for all $k < k_0-1$ we have $\sigma_k = 0$ and $\kappa_{jk} = 0$ for all $j$, and $\kappa_{j,k_0-1} = 0$ for all $j \ne i$.  By construction $\kappa_{i,k_0-1} = -1$.  Therefore $\sigma_{k_0} = 1/|L_{k_0P}|$, and $\kappa_{j,k_0} = -1/|L_{k_0P}|$ for all $j \in L_{k_0P}$.  As in the proof of Theorem \ref{th:Augmentation}, we have $\sum_j \kappa_{j,k-1} = \sum_j \kappa_{jk}$ for all $k > k_0$, so by induction $\sum_j \kappa_{jk} = -1$ for all such $k$.  Induction also gives  $\sigma_k \in [0,1]$ and $\kappa_{jk} \in [-1,0]$ for all $j$ and $k$.

  
\begin{lem} \label{lemma:FeasibleNew}
  Suppose that $e_i \colon [0,1] \to O$ and $\bare_i \colon [0,1] \to \hO$ are eating schedules for $i$ such that $\{\, t : e_i(t) \ne \bare_i(t) \,\} = \bare_i^{-1}(\emptyset)$.  Let $e_{-i}$ and $\bare_{-i}$ be the profiles of eating schedules induced by $e_i$ and $\bare_i$, and let $e = (e_i,e_{-i})$ and $\bare = (\bare_i,\bare_{-i})$.  For $t \in [0,1]$ let
  $$\delta(t) = \int_0^t \bone_{\bare_i(s) \ne e_i(s)} ds.$$
  If $e$ is feasible, then $\bare$ is feasible, and for all $P \subset O$ and $t \in [0,1]$, 
  $$0 \le \tau_P(\bare) - \tau_P(e) \le \delta(\tau_P(\bare)) \quad \text{and} \quad s_P(\bare,t) \ge s_P(e,t) \ge s_P(\bare,t) - \delta(t).$$
\end{lem}

\begin{proof}
  In the obvious way we can create a path $\rho \mapsto e_i^\rho$ from $[0,\delta(1)]$ to the space of eating schedules, with $e_i^0 = e_i$ and $e_i^{\delta(1)} = \bare_i$, that traverses each of the finitely many intervals in $[0,1]$ along which the value of $e_i$ is some $o^* \in O$ and the value of $\bare_i$ is $\emptyset$. Due to the piecewise linear nature of the problem, each of these intervals is a finite union of closed intervals such that the hypotheses of the discussion above are satisfied on the interiors of these integrals.  
  The asserted inequalities are attained from $\sigma_k \in [0,1]$ by integrating, then summing over the intervals. The 
  analysis above implies that $\bart(e^\rho) = 1$ for all $\rho$.  
  (More formally, for each $\varep > 0$ the function 
  $\rho \mapsto \bart(e^\rho)$ cannot leave the interval $(1 - \varep,1]$.)  Therefore $\bare_i$ is feasible.
\end{proof}

We now introduce a preferences $\succ_i$ and  $\succ_i'$ over $O$ for $i$, and we let $\succ = (\succ_i,\succ_{-i})$ and $\succ' = (\succ_i',\succ_{-i})$.  There are unique eating functions $e^\succ$ and  $e^{\succ'}$ that are  generated by the GCPS procedure when agents report these preferences.  Since $E$ satisfies the GMC, these eating functions are feasible.
Let $\bare_i$ be the eating schedule
$$\bare_i(t) = 
\begin{cases}
  e_i^\succ(t) & \text{if $e_i^\succ(t) = e_i^{\succ'}(t)$,} \\
  \emptyset & \text{otherwise},
\end{cases}$$
let $\bare_{-i}$ be the profile of eating schedules induced by $\bare_i$, and let $\bare = (\bare_i,\bare_{-i})$.  Lemma \ref{lemma:FeasibleNew} implies that $\bare$ is feasible.

Let $\beta(t)$, $\gamma(t)$, and $\delta(t)$ denote the sums of the lengths of time intervals, before time $t$, on which agent $i$'s consumption in the eating algorithm is $\succ_i$-preferred, $\succ_i$-less preferred, and different, respectively, when the reported preferences change from $\succ$ to $\succ'$.  Formally,
$$\beta(t) = \int_0^t \bone_{e_i^{\succ'}(s) \succ_i e_i^\succ(s)} ds \quad \text{and} \quad \gamma(t) = \int_0^t \bone_{e_i^{\succ}(s) \succ_i e_i^{\succ'}(s)} ds,$$ so that $\delta(t) = \beta(t) + \gamma(t)$.

Let
$$\{o_1, o_2, \ldots, o_{\ell}\} = \{\, o \in O : \text{$o = e_i^{\succ'}(t) \succ_i e_i^\succ(t)$ for some $t \in [0,1)$} \,\}$$
be the set of objects $o$ such that for some time $t$, $o = e_i^{\succ'}(t)$ is $\succ_i$-preferred to $e_i^\succ(t)$.  
These objects are indexed so that 
$o_1 \succ_i' o_2 \succ_i' \cdots \succ_i' o_{\ell}$.  For $l = 1, \ldots, \ell$ let
$$T_l = \inf \{\, t : o_l = e_i^{\succ'}(t) \succ_i e_i^\succ(t) \,\}$$ 
be the first time $t$ when $o_l = e_i^{\succ'}(t)$ is $\succ_i$-preferred to $e_i^\succ(t)$.  For each $l$ let 
$$T_l' = \sup \{\, t : o_l = e_i^{\succ'}(t) \,\}$$ 
Clearly, $0 < T_1 < T_1' \le T_2 < \cdots < T_{\ell - 1}' \le T_{\ell} < T_{\ell}' \le1$.  Let $T_0= 0$ and $T_{\ell + 1} = 1$.



\begin{lem} \label{lemma:KM5New}
  For all $l = 1, \ldots, \ell$, 
  $$T_l' - T_l \le \frac{\delta(T_l)}{N_0}.$$
\end{lem}

\begin{proof}
  After time $T_l$ the object $o_l$ is not available to $i$ under the eating function $e^\succ$, so there is a $P_l$ such that $o_l \in P_l$, $i \in J_{P_l}^c$, and $\tau_{P_l}(e^\succ) = T_l$. Since $s_{P_l}(T_l,e^{\succ}) = 0$, Lemma \ref{lemma:FeasibleNew} gives
  $$s_{P_l}(T_l,e^{\succ'}) = (s_{P_l}(T_l,e^{\succ'}) - s_{P_l}(T_l,\bare)) - (s_{P_l}(T_l,e^{\succ}) - s_{P_l}(T_l,\bare)) \le \delta(T_l).$$
  By assumption $i$ is one of at least $N_0$ students $j \in J_{P_l}^c$ such that $e^{\succ'}_j(t) = o_l$ for all $t \in [T_l, T_l')$, so $T_l' \le \tau_{P_l}(e^{\succ'}) \le \tau_{P_l}(e^\succ) + \delta(T_l)/N_0$.  
\end{proof}

Let $\lambda = 1 + 1/N_0$.

\begin{lem} \label{lemma:KM6}
  For all $l = 1, \ldots, \ell$,
  $T_l' - T_l \le \gamma(1)(\lambda - 1)\lambda^{l-1}$.
\end{lem}

\begin{proof}
  We prove the lemma by induction on $l$.  We have $\delta(T_1) = \gamma(T_1) \le \gamma(1) \le 1$, so Lemma \ref{lemma:KM5New} implies that $T_1' - T_1 \le \delta(T_1) /N_0 \le \gamma(1)(\lambda - 1)$. 
  Suppose that $l \ge 2$ and the induction hypothesis holds for $1, \ldots, l - 1$.  Then
  $$\delta(T_l) = \gamma(T_l) + \beta(T_l) \le \gamma(1) + \sum_{g = 1}^{l-1} \beta(T_{g+1}) - \beta(T_g) = \gamma(1) + \sum_{g = 1}^{l-1} T_g' - T_g$$
  $$\le \gamma(1)\Big(1 + (\lambda - 1)\sum_{g = 0}^{l-2}\lambda^g\Big) = \gamma(1)\lambda^{l-1}.$$
  Applying Lemma \ref{lemma:KM5New} again gives
  \begin{equation*}
  T_l' - T_l \le \delta(T_l)/N_0 \le \gamma(1)(\lambda - 1)\lambda^{l-1}. \qedhere
  \end{equation*}
\end{proof}

\begin{proof}[Proof of Theorem \ref{th:StrategyProof}.]
  We have
  $$u_i(GCPS(\succ)) - u_i(GCPS(\succ')) = \int_0^1 u_i(e_i^\succ(s)) - u_i(e_i^{\succ'}(s)) \, ds \ge d_i\gamma(1) - D_i\beta(1).$$
  Since $\beta(T_1) = 0$, adding up the inequalities from Lemma \ref{lemma:KM6} for gives
  $$\beta(1) = \sum_{g = 1}^{\ell} \beta(T_{g+1}) - \beta(T_g) = \sum_{g = 1}^{\ell} T_g' - T_g \le \gamma(1)(\lambda - 1)
  \sum_{g = 1}^{\ell}\lambda^{g-1} = \gamma(1)(\lambda^{\ell} - 1).$$ 
  Therefore
  $$u_i(GCPS(\succ)) - u_i(GCPS(\succ')) \ge \gamma(1)\big(d_i - D_i(\lambda^{\ell} - 1)\big),$$
  and since $\ell \le |O|$, this is nonnegative if
  \begin{equation*}
  \big(1 + \frac{d_i}{D_i}\big)^{1/|O|} \ge \lambda = 1 + 1/N_0. \qedhere
  \end{equation*}
\end{proof}

\end{appendix}

%%%------------------------------------------------------------------------------------
%%%------------------------------------------------------------------------------------
\bibliographystyle{agsm}
\bibliography{pa_ref}
\end{document}

\section{Little Proof}

\begin{lem}
  For all $k$, $\sum_{j \in I} \kappa_{jk} = 0$.
\end{lem}

\begin{proof}
  Evidently $\sum_j \kappa_{jk} = 0$ for all $k \le k_2$.  We claim that $\sum_j \kappa_{jk} = \sum_j \kappa_{j,k-1}$ for all $k > k_2$, which implies (f) by induction.  By (ii) of (e) we have $\kappa_{jk} = \kappa_{j,k-1}$ if $j \in I \setminus \bigcup_{P \in \cP_k} J_{kP}$.  By (i) of (e) we have $\sum_{j \in J_{kP}} \kappa_{jk} = \sum_{j \in J_{kP}} \kappa_{j,k-1}$ for each $P \in \cP_k$.  Recalling that the set of critical pairs is a lattice, if $P, P' \in \cP_k$, then $P \cap P' \in \cP_k$ and $J_{P \cap P'} = J_P \cap J_{P'}$, hence $J_{k,P \cap P'} = J_{kP} \cap J_{kP'}$. Therefore $\sum_{j \in J_{kP} \cap J_{kP'}} \kappa_{jk} = \sum_{j \in J_{kP} \cap J_{kP'}} \kappa_{j,k-1}$ and 
  $$\sum_{j \in J_{kP} \setminus J_{kP'}} \kappa_{jk} = \sum_{j \in J_{kP} \setminus J_{kP'}} \kappa_{j,k-1}.$$  
  Therefore the set of $J \subset I$ such that $\sum_{j \in J} \kappa_{jk} = \sum_{j \in J} \kappa_{j,k-1}$ includes the algebra generated by the sets $J_{kP}$, which contains a partition of $I$, and the claim follows.
\end{proof}


\section{Proof of Theorem \ref{th:StrategyProof}} \label{app:OldStrategyProof}

Fix a school choice CEE $E = (I,O,r,q,g)$ that satisfies the GMC. It will be convenient to introduce a \emph{null object}, which we denote by $\emptyset$.  Let $\hO = O \cup \{\emptyset\}$.  
An \emph{eating function} $e = (e_j)_{j \in I}$ is a vector of eating schedules $e_j \colon [0,1] \to \hO$ that are  piecewise constant  and right continuous: for all $t < 1$ there is $\varep > 0$ such that $e_j(t') = e_j(t)$ for all $t' \in [t, t+\varep)$.
For such an $e$ and $t \in [0,1]$ let $p(e,t) \in \Re_+^{I \times O}$ be the allocation given by
$p_{jo}(e,t) = \int_0^t \bone_{e_j(s) = o} \, ds$. For $P \subset O$ recall that $s_P = \sum_{o \in P} q_o - \sum_{i \in J_P} r_i$, let 
$$\sigma_P(e,t) = s_P  -  \sum_{j \in J_P^c} \sum_{o \in P} p_{jo}(e,t),$$
and let $\tau_P(e) = \sup \{\, t \in [0,1] : \sigma_P(e,t) > 0 \,\}$.
Let
$$\bart(e) = \sup \{\, t \in [0,1] : \text{$\sigma_P(e,t) \ge 0$ for all $P \subset O$} \,\}.$$
An eating function $e$ is \emph{feasible} if $\bart(e) = 1$.

For $j \in I$ let
$$\alpha_j(e,t) = \alpha_j  \setminus \bigcup_{P \subset O \, : \, \text{$j \in J_P^c$ and $\sigma_P(e,t) \le 0$}} P$$
be the set of schools at which $j$ can eat at time $t$.   Note that $\alpha_j(\cdot,t)$ is right continuous.
We now fix a profile $\succ \; = (\succ_j)_{j \in I}$ of preferences over $\hO$ such that for each $j$, $\emptyset$ is the $\succ_j$-worst element of $\hO$.   If $\alpha_j(e,t) \ne \emptyset$, let $e^{\succ_j}_j(e,t)$ be its $\succ_j$-best element.  

We now fix a particular $i \in I$.  An eating function $e$ is \emph{$\succ_{-i}$-maximizing} if 
$e_j(t) = e^{\succ_j}_j(e,t)$ for all $j \ne i$ and all $t \le \bart(e)$. For a given $e_i$ that is piecewise constant  (changes object finitely many times) and right continuous, an $e_{-i}$ such that $e = (e_i,e_{-i})$ is $\succ_{-i}$-maximizing can be constructed inductively. Furthemore, this $e_{-i}$ is the unique profile such that  $e = (e_i,e_{-i})$ is $\succ_{-i}$-maximizing:   if $e_{-i}'$ is a second such profile and $t_0$ is the supremum of the set of $t$ such that $e_{-i}|_{[0,t]} = e_{-i}'|_{[0,t]}$, then right continuity implies that, for some $\varep > 0$, $e_{-i}$ and $e_{-i}'$ also agree on $[t_0,t_0+\varep)$, so $t_0= 1$.  We call $e_{-i}$ the \emph{profile of eating schedules induced by $e_i$}.

A (piecewise constant right continuous) eating schedule $e_i \colon [0,1] \to \hO$ for $i$ is \emph{feasible} if
$\bart(e) = 1$, where $e = (e_i,e_{-i})$  and $e_{-i}$ the profile of eating schedules induced by $e_i$.  If $e_i$ is a feasible eating schedule for $i$ and $\bare_i$ is another eating schedule for $i$ such that $\{\, t : e_i(t) \ne \bare_i(t) \,\} \subset \bare_i^{-1}(\emptyset)$, it may seem obvious that $\bare_i$ is also feasible, but proving this turns out to be quite technical.

We now consider a feasible eating schedule $e_i^0$ for $i$, a time $\rho_0 < \bart(e^0)$  where $e^0 = (e_i^0,e_{-i}^0)$  and $e_{-i}^0$ is the profile of eating schedules induced by $e_i^0$, and an $\varep > 0$ such that for some $o^* \in O$, $e_i^0$ is constant on $(\rho_0 - \varep,\rho_0)$ with value $\emptyset$ and constant on $[\rho_0,\rho_0 + \varep)$ with value $o^*$.  For $\rho \in (\rho_0 - \varep,\rho_0 + \varep)$ let $e_i^\rho$ be the eating function for $i$ that  is constant on $(\rho_0 - \varep,\rho)$ with value $\emptyset$, constant on $[\rho,e + \varep)$ with value $o^*$, and agrees with $e_i^0$ elsewhere.  Let  $e^\rho_{-i}$ be the profile of eating schedules induced by $e_i^\rho$, and let $e^\rho = (e_i^\rho,e_{-i}^\rho)$.

\begin{lem} \label{lemma:MonotoneCutoff} 
 The function $\rho \mapsto \bart(e^\rho)$ from $(\rho_0 - \varep,\rho_0 + \varep)$ to $[0,1]$ is piecewise linear.  For each $P \subset O$, $\sigma_P(e^\rho,t)$ is a piecewise linear function of those $(\rho,t)$ such that $t \le \bart(e^\rho)$, and $\tau_P(e^\rho)$ is a piecewise linear function of $\rho$.
 Suppose that, for some $\delta \in (0,\varep]$, there are affine functions $t_0, t_1, \ldots, t_K \colon (\rho_0 - \delta,\rho_0 + \delta) \to [0,1]$ with $0 \equiv t_0 < t_1 < \cdots < t_K$ such for each $\rho \in (\rho_0 - \delta,\rho_0 + \delta)$,  $t_K(\rho) = \bart(e^\rho)$ and, for each $k = 1, \ldots, K-1$, $t_k(\rho) = \tau_P(e^\rho)$ for one or more $P \subset O$ and there are no $P \subset O$ such that $t_{k-1}(\rho) < \tau_P(e^\rho) < t_k(\rho)$. Then for all $\rho \in (\rho_0 - \delta,\rho_0 + \delta)$, $P \subset O$, and  $t \in [0,1]$, the partial of $\sigma_P(e^\rho,t)$ with respect to $\rho$ is defined and lies in $[0,1]$, 
 the derivative of $\tau_P(e^\rho)$ with respect to $\rho$ is a constant that lies in $[0,1]$, and the derivative of $\bart(e^\rho)$ with respect to $\rho$ is a constant that lies in $[0,1]$.
\end{lem}

\begin{proof}
  It is clear from the definition that the functions $p_{jo}(e^\rho,t)$ are piecewise linear functions of $(\rho,t)$.  The piecewise linearity of $\bart(e^\rho)$,  $\sigma_P(e^\rho,t)$, and $\tau_P(e^\rho)$ follows from this.
  
  By continuity, for each $0 < k < K$ the set $\cP_k$ of $P \subset O$ such that $\tau_P(e^\rho) = t_k(\rho)$ is the same for all $\rho \in (\rho_0 - \delta,\rho_0 + \delta)$.  For $j \ne i$ and $k = 1, \ldots, K$ let $o_{jk} = e^{\rho_0}_j(t_{k-1}(\rho_0))$.  For $k = 1, \ldots, K$ and $P \in \cP_k$ let $J_{kP} = \{\, j \ne i : o_{jk} \in J_P^c \,\}$.
  
  We inductively define numbers $\kappa_{jk}$ for $j \in I$ and $k = 0, \ldots, K$, beginning by setting $\kappa_{i0} = 1$ and $\kappa_{j0} = 0$ for all $j \ne i$. Supposing that $k > 0$ and the numbers $\kappa_{j,k-1}$ have already been defined, there are several cases:
  \begin{enumerate}
    \item[(a)] If $\kappa_{i,k-1} = 1$ and there is no $P \in \cP_k$ such that $o^* \in P$ and $i \in J_P^c$, then $\kappa_{ik} = 1$ and $\kappa_{jk} = 0$ for all $j \ne i$.  
    \item[(b)] If $\kappa_{i,k-1} = 1$ and there is a $P \in \cP_k$ such that $o^* \in P$ and $i \in J_P^c$, then $\kappa_{jk} = 1/(|J_{kP}| + 1)$ for all $j \in J_{kP}$, and $\kappa_{jk} = 0$ for all other $j$ including $i$.  
    \item[(c)] If $\kappa_{i,k-1} = 0$, then $\kappa_{i,k} = 0$.  In addition: 
      \begin{enumerate}
        \item[(i)] If $P \in \cP_k$ and $j \in J_{kP}$, then $\kappa_{jk} = \sum_{j' \in J_{kP}} \kappa_{j',k-1}/|J_{kP}|$.
        \item[(ii)] If $j \ne i$ and there is no $P \in \cP_k$ such that $j \in J_{kP}$, then $\kappa_{jk} = \kappa_{j,k-1}$.  
      \end{enumerate}
  \end{enumerate}
  Below we will show that these numbers are well defined in spite of potential ambiguities arising from the sets $\cP_k$ having multiple members.

  To begin with consider the first $k$ such that there is a $P \in \cP_{k_0}$ such that $o^* \in P$ and $i \in J_P^c$.  For $\rho \in (\rho_0 - \delta, \rho_0 + \delta)$ we have   
  $$p_{io^*}(e^\rho,t_{k_0}(\rho)) + \sum_{j \in J_{k_0P}} p_{jo_{jk_0}}(e^\rho,t_{k_0}(\rho)) = p_{io^*}(e^{\rho_0},t_{k_0}(\rho_0)) + \sum_{j \in J_{k_0P}} p_{jo_{jk_0}}(e^{\rho_0},t_{k_0}(\rho_0)),$$  
  which reduces to
  $$-(\rho - \rho_0) + (|J_{k_0P}| + 1) \cdot (t_{k_0}(\rho) - t_{k_0}(\rho_0)) = 0$$
  and thus $t_{k_0}(\rho) = t_{k_0}(\rho_0) + (\rho - \rho_0)/(|J_{k_0P}| + 1)$.  This is true for \emph{all} $P \in \cP_{k_0}$ such that $o^* \in P$ and $i \in J_P^c$, but if $P'$ is a second such set, then $P \cap P'$ is also such a set, and we conclude that $J_P = J_{P \cap P'} = J_{P'}$, so the definition of the numbers $\kappa_{jk_0}$ is unambiguous.

  We claim that if $k > k_0$, $j \ne i$, and  $t_{k-1}(\rho) \le t \le t_k(\rho)$, then $$p_{jo_{jk}}(e^\rho,t) = p_{jo_{jk}}(e^0,t) - (\rho - \rho_0) \cdot  \kappa_{j,k-1}, \eqno{(*)}$$ and if $\rho \in (\rho_0 - \delta, \rho_0 + \delta)$, then
  $$t_k(\rho) = t_k(\rho_0) + (\rho - \rho_0) \cdot \sum_{j \in J_{kP}} \kappa_{j,k-1}/|J_{kP}|. \eqno{(**)}$$
  Clearly ($*$) holds when $k = k_0 + 1$.  If it holds for $k$ and $P \in \cP_k$, then    
  $$\sum_{j \in J_{kP}} p_{jo_{jk}}(e^\rho,t_k(\rho)) = \sum_{j \in J_{kP}} p_{jo_{jk}}(e^{\rho_0},t_k(\rho_0)),$$ 
  which reduces to
  $$(t_k(\rho) - t_k(\rho_0)) \cdot |J_{kP}| - (\rho - \rho_0) \cdot \sum_{j \in J_{kP}} \kappa_{j,k-1} = 0,$$
  and thus ($**$).  Clearly ($**$) implies ($*$) with $k+1$ in place of $k$.

  We claim that $\sum_j \kappa_{jk} = \sum_j \kappa_{j,k-1}$ for all $k > k_0$.  By definition we have $\kappa_{jk} = \kappa_{j,k-1}$ if $j \in I \setminus \bigcup_{P \in \cP_k} J_P$.  By (i) of (c) we have $\sum_{j \in J_{kP}} \kappa_{jk} = \sum_{j \in J_{kP}} \kappa_{j,k-1}$ for each $P \in \cP_k$.  Recalling that the set of critical pairs is a lattice, if $P, P' \in \cP_k$, then $P \cap P' \in \cP_k$ and $J_{P \cap P'} = J_P \cap J_{P'}$, hence $J_{k,P \cap P'} = J_{kP} \cap J_{kP'}$. Therefore $\sum_{j \in J_{kP} \cap J_{kP'}} \kappa_{jk} = \sum_{j \in J_{kP} \cap J_{kP'}} \kappa_{j,k-1}$ and 
  $$\sum_{j \in J_{kP} \setminus J_{kP'}} \kappa_{jk} = \sum_{j \in J_{kP} \setminus J_{kP'}} \kappa_{j,k-1}.$$  
  Therefore the set of $J \subset I$ such that $\sum_{j \in J} \kappa_{jk} = \sum_{j \in J} \kappa_{j,k-1}$ includes the algebra generated by the sets $J_{kP}$, which contains a partition of $I$, and the claim follows.

  The claim concerning the partial of $\sigma_P$ with respect to $\rho$ now follows from summation of ($*$) over those $j$ such that $o_{jk} \in P$.  The claim concerning the derivative of $\tau_P(e^\rho)$ with respect to $\rho$ follows from ($**$), and the claim concerning the derivative of $\bart(e^\rho)$ with respect to $\rho$ is a special case of this.
\end{proof}

\begin{lem} \label{lemma:Feasible}
  Suppose that $e_i$ and $\bare_i$ are eating schedules for $i$ such that $e_i$ is feasible and $$\{\, t : e_i(t) \ne \bare_i(t) \,\} \subset \bare_i^{-1}(\emptyset).$$  Then $\bare_i$ is feasible.  For $t \in [0,1]$ let
  $$\delta(t) = \int_0^t \bone_{\bare_i(s) \ne e_i(s)} ds.$$
  Let $e_{-i}$ and $\bare_{-i}$ be the profiles of eating schedules induced by $e_i$ and $\bare_i$, and let $e = (e_i,e_{-i})$ and $\bare = (\bare_i,\bare_{-i})$.  For all $P \subset O$ and $t \in [0,1]$, $$0 \le \tau_P(\bare) - \tau_P(e) \le \delta(\tau_P(\bare)) \quad \text{and} \quad \sigma_P(\bare,t) \ge \sigma_P(e,t) \ge \sigma_P(\bare,t) - \delta(t).$$
\end{lem}

\begin{proof}
  In the obvious way we can create a path $\rho \mapsto e_i^\rho$ from $[0,\delta(1)]$ to the space of eating schedules, with $e_i^0 = e_i$ and $e_i^{\delta(1)} = \bare_i$, that traverses each of the finitely many intervals in $[0,1]$ along which the value of $e_i$ is some $o^* \in O$ and the value of $\bare_i$ is $\emptyset$, in the manner described in the hypotheses of the last result.  There are finitely many endpoints of such intervals, and there are finitely many $\rho$ such that there are $P, P' \subset O$ such that $\tau_P(e^\rho) = \tau_{P'}(e^\rho)$ but $\tau_P(e^{\rho'}) \ne \tau_{P'}(e^{\rho'})$ for nearby $\rho'$.  Therefore the asserted inequalities can be obtained by integrating the inequalities of the last result.  The final assertion of the last result implies that $\bart(e^\rho) = 1$ for all $\rho$.  (More formally, for each $\varep > 0$ the function $\rho \mapsto \bart(e^\rho)$ cannot leave the interval $(1 - \varep,1]$.)  Therefore $\bare_i$ is feasible.
\end{proof}

We now introduce a preferences $\succ_i$ and  $\succ_i'$ over $\hO$ for $i$, and we let $\succ = (\succ_i,\succ_{-i})$ and $\succ' = (\succ_i',\succ_{-i})$.  There are unique eating functions $e^\succ$ and  $e^{\succ'}$ that are  generated by the GCPS procedure when agents report these preferences.  Since $E$ satisfies the GMC, these eating functions are feasible.
Let $\bare_i$ be the eating schedule
$$\bare_i(t) = 
\begin{cases}
  e_i^\succ(t) & \text{if $e_i^\succ(t) = e_i^{\succ'}(t)$,} \\
  \emptyset & \text{otherwise},
\end{cases}$$
let $\bare_{-i}$ be the profile of eating schedules induced by $\bare_i$, and let $\bare = (\bare_i,\bare_{-i})$.  Lemma \ref{lemma:Feasible} implies that $\bare$ is feasible.

Let $\beta(t)$, $\gamma(t)$, and $\delta(t)$ denote the sums of the lengths of time intervals, before time $t$, on which agent $i$'s consumption in the eating algorithm is $\succ_i$-preferred, $\succ_i$-less preferred, and different, respectively, when the reported preferences change from $\succ$ to $\succ'$.  Formally,
$$\beta(t) = \int_0^t \bone_{e_i^{\succ'}(s) \succ_i e_i^\succ(s)} ds \quad \text{and} \quad \gamma(t) = \int_0^t \bone_{e_i^{\succ}(s) \succ_i e_i^{\succ'}(s)} ds,$$ so that $\delta(t) = \beta(t) + \gamma(t)$.

Let
$$\{o_1, o_2, \ldots, o_{\ell}\} = \{\, o \in O : \text{$o = e_i^{\succ'}(t) \succ_i e_i^\succ(t)$ for some $t \in [0,1)$} \,\}$$
be the set of objects $o$ such that for some time $t$, $o = e_i^{\succ'}(t)$ is $\succ_i$-preferred to $e_i^\succ(t)$.  
These objects are indexed so that 
$o_1 \succ_i' o_2 \succ_i' \cdots \succ_i' o_{\ell}$.  For $l = 1, \ldots, \ell$ let
$$T_l = \inf \{\, t : o_l = e_i^{\succ'}(t) \succ_i e_i^\succ(t) \,\}$$ 
be the first time $t$ when $o_l = e_i^{\succ'}(t)$ is $\succ_i$-preferred to $e_i^\succ(t)$.  For each $l$ let 
$$T_l' = \sup \{\, t : o_l = e_i^{\succ'}(t) \,\}$$ 
Clearly, $0 < T_1 < T_1' \le T_2 < \cdots < T_{\ell - 1}' \le T_{\ell} < T_{\ell}' \le1$.  Let $T_0= 0$ and $T_{\ell + 1} = 1$.



\begin{lem} \label{lemma:KM5new}
  For all $l = 1, \ldots, \ell$, 
  $$T_l' - T_l \le \frac{\delta(T_l)}{N_0}.$$
\end{lem}

\begin{proof}
  After time $T_l$ the object $o_l$ is not available to $i$ under the eating function $e^\succ$, so there is a $P_l$ such that $o_l \in P_l$, $i \in J_{P_l}^c$, and $\tau_{P_l}(e^\succ) = T_l$. Lemma \ref{lemma:Feasible} gives
  $$\sigma_{P_l}(T_l,e^{\succ'}) = (\sigma_{P_l}(T_l,e^{\succ'}) - \sigma_{P_l}(T_l,\bare)) - (\sigma_{P_l}(T_l,e^{\succ}) - \sigma_{P_l}(T_l,\bare)) \le \delta(T_l).$$
  By assumption $i$ is one of at least $N_0$ students $j \in J_{P_l}^c$ such that $e^{\succ'}_j(t) = o_l$ for all $t \in [T_l, T_l')$, so $T_l' \le \tau_{P_l}(e^{\succ'}) \le \tau_{P_l}(e^\succ) + \delta(T_l)/N_0$.  
\end{proof}

Let $\lambda = 1 + 1/N_0$.

\begin{lem} \label{lemma:KM6}
  For all $l = 1, \ldots, \ell$,
  $T_l' - T_l \le \gamma(1)(\lambda - 1)\lambda^{l-1}$.
\end{lem}

\begin{proof}
  We prove the lemma by induction on $l$.  We have $\delta(T_1) = \gamma(T_1) \le \gamma(1) \le 1$, so Lemma \ref{lemma:KM5new} implies that $T_1' - T_1 \le \delta(T_1) /N_0 \le \gamma(1)(\lambda - 1)$. 
  Suppose that $l \ge 2$ and the induction hypothesis holds for $1, \ldots, l - 1$.  Then
  $$\delta(T_l) = \gamma(T_l) + \beta(T_l) \le \gamma(1) + \sum_{g = 1}^{l-1} \beta(T_{g+1}) - \beta(T_g) = \gamma(1) + \sum_{g = 1}^{l-1} T_g' - T_g$$
  $$\le \gamma(1)\Big(1 + (\lambda - 1)\sum_{g = 0}^{l-2}\lambda^g\Big) = \gamma(1)\lambda^{l-1}.$$
  Applying Lemma \ref{lemma:KM5new} again gives
  \begin{equation*}
  T_l' - T_l \le \delta(T_l)/N_0 \le \gamma(1)(\lambda - 1)\lambda^{l-1}. \qedhere
  \end{equation*}
\end{proof}

\begin{proof}[Proof of Theorem \ref{th:StrategyProof}.]
  We have
  $$u_i(GCPS(\succ)) - u_i(GCPS(\succ')) = \int_0^1 u_i(e_i^\succ(s)) - u_i(e_i^{\succ'}(s)) \, ds \ge d_i\gamma(1) - D_i\beta(1).$$
  Since $\beta(T_1) = 0$, adding up the inequalities from Lemma \ref{lemma:KM6} for gives
  $$\beta(1) = \sum_{g = 1}^{\ell} \beta(T_{g+1}) - \beta(T_g) = \sum_{g = 1}^{\ell} T_g' - T_g \le \gamma(1)(\lambda - 1)
  \sum_{g = 1}^{\ell}\lambda^{g-1} = \gamma(1)(\lambda^{\ell} - 1).$$ 
  Therefore
  $$u_i(GCPS(\succ)) - u_i(GCPS(\succ')) \ge \gamma(1)\big(d_i - D_i(\lambda^{\ell} - 1)\big),$$
  and since $\ell \le |O|$, this is nonnegative if
  \begin{equation*}
  \big(1 + \frac{d_i}{D_i}\big)^{1/|O|} \ge \lambda = 1 + 1/N_0. \qedhere
  \end{equation*}
\end{proof}

% \section{Proof of Lemma \ref{lem:cyclic}} \label{app:Cyclic}

% The argument below simply adapts the proof of Theorem 1 of \cite{cd16} to our setting.
 
% Suppose that $m$ is wasteful, so there is an agent $i$ and a pair $o,o'$ of objects such that $o \succ_i o'$, $m_{io} < g_{io}$, $m_{io'} > 0$, and $\sum_j m_{jo} < q_o$. For sufficiently small $\delta > 0$, setting $m'_{io} = m_{io}+\delta$,  $m'_{io'} = m_{io'} - \delta$, and $m'_{jp} = m_{jp}$ for all other $(j,p)$ gives an allocation $m'$ such that $m'_i$ $e$-dominates $m_i$ for any $e \in \{sd,dl,ul\}$, $m_i' \ne m_i$, and $m'_j = m_j$ for all $j \ne i$, so $m'$ $e$-dominates $m$. 

%Suppose that there is a cycle $o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0$.
%If $i_0, \ldots, i_k$ and $m(\delta)$ are as above, then, for sufficiently small $\delta >0$, $m(\delta)$ is an allocation, $m_i(\delta)$ $e$-dominates $m_i$  for each $i = 0, \ldots, k$ and $e \in \{sd,dl,ul\}$, and $m'_j = m_j$ for all other $j$, so $m'$ $e$-dominates $m$.

% Now suppose that allocation $m$ is not wasteful and is $e$-dominated by the allocation $m'$.   Fix an agent $i_0$ such that $m'_{i_0} \ne m_{i_0}$. 
% There are two cases, depending on whether $e = dl$ or $e = ul$.  (Either argument can handle the case $e = sd$.)

%First suppose that $e = dl$.  Since $m_i'$ $ul$-dominates $m_i$ there are objects $o_0$ and $o_1$  such that $o_1 \succ_{i_1} o_0$, $m'_{i_0o_0} < m_{i_0o_0}$, and $m'_{i_0o_1} > m_{i_0o_1}$.  These conditions imply that $m_{i_0o_0} > 0$ and $m_{i_0o_1} < g_{i_0o_1}$, so $o_0 \lhd_m o_1$. 
% If $m'_{jo_1} \ge m_{jo_1}$ for all $j \ne i_0$, then $\sum_j m_{jo_1} < \sum_j m'_{jo_1} \le q_{o_1}$ and $m_{i_0o_0} > 0$, contradicting nonwastefulness of $m$.  Therefore there is some $i_1 \ne i_0$ such that $m'_{i_1o_1} < m_{i_1o_1}$.  Since $m'_{i_1}$ $dl$-dominates $m_{i_1}$, there is some $o_2$ such that $o_2 \succ_{i_1} o_1$ and $m'_{i_1o_2} > m_{i_1o_2}$.  We have $m_{i_1o_1} > 0$ and $m_{i_1o_2} < g_{i_1o_2}$, so $o_1 \lhd o_2$.
% Since $O$ is finite, repeating this argument leads eventually to a cycle $o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0$.

% Now suppose that $e = ul$. Since $m_i'$ $dl$-dominates $m_i$ there are objects $o_0$ and $o_1$  such that $o_0 \succ_{i_1} o_1$, $m'_{i_0o_0} > m_{i_0o_0}$, and $m'_{i_0o_1} < m_{i_0o_1}$, so that $m_{i_0o_1} > 0$ and $o_1 \lhd o_0$. 

% Aiming at a contradiction, suppose that $m_{jo_1} \ge m'_{jo_1}$ for all $j \ne i_0$, so that $q_{o_1} \ge \sum_j m_{jo_1} > \sum_j m'_{jo_1}$.  Since $\sum_{j,p} m_{jp} = \sum_{j,p} m'_{jp} = \sum_j r_j$, there is a $p_1$ such that $\sum_j m_{jp_1} < \sum_j m'_{jp_1}$ and a $j_1$ such that $m_{j_1p_1} < m'_{j_1p_1}$. Since $m'_{j_1} \ne m_{j_1}$ and $m'_{j_1}$ $ul$-dominates $m_{j_1}$, there is a $p_2$ such that $p_1 \succ_{j_1} p_2$ and $m_{j_1,p_2} > m'_{j_1,p_2}$.  
% In particular, $m_{j_1,p_2} > 0$.  Together with $q_{p_1} \ge \sum_j m'_{jp_1} > \sum_j m_{jp_1}$, this contradicts the assumption that $m$ is not wasteful.

% Therefore there is some $i_1 \ne i_0$ such that $m_{i_1o_1} < m'_{i_1o_1}$.  Since $m'_{i_1} \ne m_{i_1}$ and $m'_{i_1}$ $ul$-dominates $m_{i_1}$ there is some $o_2$ such that $o_1 \succ_{i_1} o_2$ and $m_{i_1o_2} > m'_{i_1o_2}$.  In particular, $m_{i_1o_2} > 0$, so $o_2 \lhd o_1$.  
% Since $O$ is finite, repeating this argument leads eventually to a cycle $o_0 \lhd_m o_h \lhd_m \cdots \lhd_m o_1 \lhd_m o_0$.


\section{Proof of Theorem \ref{th:WeakStrategyProof}} \label{app:WeakStrategyProof}

Let $E = (I,O,r,q)$ be a uniform unrestricted eligibility CEE.  We assume that $E$ satisfies the GMC: $r|I| \le \sum_o q_0$.  As we stated in Section \ref{sec:StrategyProof}, we wish to prove something stronger than Theorem \ref{th:WeakStrategyProof}, namely that there is no eating strategy for an agent that results in an allocation that strictly stochastically dominates the GCPS allocation.  We now fix an agent $i$.  We need to explain the consequences of $i$ following a particular eating function.

We imagine that the process begins at time $0$, and we specify how it continues until the time $r$ when all agents have fulfilled their requirement.  We assume that agent $i$'s behavior is described by an eating function $e_i \colon [0,r] \to O$ that is piecewise constant, and that is \emph{feasible} in the sense that process described below is well defined.
For each $t \in [0,r]$ there are the following objects:
\begin{enumerate}
  \item[(a)] $p^{e_i}(t)$ is a partial allocation.
  \item[(b)] $\alpha^{e_i}(t) = \{\, o : q^{e_i}_o(t) > 0 \,\}$ is the set of available objects.
  \item[(c)] For each $j \ne i$, $e^{e_i}_j(t)$ is the $\succ_j$-best element of $\alpha^{e_i}(t)$.
  \item[(d)] $e^{e_i}_i(t) = e_i(t) \in \alpha^{e_i}_i(t)$.
\end{enumerate}
We assume that $p^{e_i}(0) = 0$.  We require that $q^{e_i}(t)$ and $p^{e_i}(t)$ are continuous and piecewise linear functions of $t$, and that when their derivatives  $\dq^{e_i}(t)$ and $\ddp^{e_i}(t)$ with respect to time  are defined, for all $j$ they satisfy:
\begin{enumerate}
  \item[(a)] $\dq^{e_i}_o(t) = -|\{\, j : e^{e_i}_j(t) = o \,\}|$.
  \item[(b)] $\ddp^{e_i}_{jo}(t) = 1$ if $e^{e_i}_j(t) = o$, and otherwise $\ddp^{e_i}_{jo}(t) = 0$.
\end{enumerate}
The allocation for $e_i$ is $p^{e_i}(r)$.

Let $\cE_i$ be the set of feasible eating functions for $i$ that change objects at most $|O|^2$ times.   This is a compact set with respect to the metric $d(e_i,e_i') = \int_{t = 0}^{r_i} 1 - \delta_{e_i(t),e_i'(t)} \, dt$ (Kronecker $\delta$) and the set of feasible elements is a closed subset.  We say that two feasible eating functions are \emph{equivalent} if they have the same total consumption of each object during any interval between two times at which objects are exhausted, in which case the two functions give the same allocation to $i$.  Clearly any feasible eating schedule is equivalent to an element of $\cE_i$.  
Let $a$ be $i$'s favorite element of $\{\, o : g_{io} = r_i \,\}$.  It is easy to see that the map from feasible elements of $\cE_i$ to $i$'s allocation of $a$ is continuous.  Therefore there is a feasible $e_i \in \cE_i$ that maximizes the overall allocation of $a$ for $i$.

Let $t_1$ be the time at which $a$ becomes unavailable to $i$ under $e_i$, either because $t_1 = r$ or $q_a^{e_i}(t_1) = 0$, so $q_a^{e_i}(t) > 0$ for all $t < t_1$.  Aiming at a contradiction, suppose that there are  times prior to $t_1$ at which $i$ eats something other than $a$, and let $t_0$ be the least upper bound of the set of such times.  Since $e_i$ switches objects finitely many times, optimality implies that $t_0 < t_1$.  Let $\delta > 0$ be the largest number such that $i$ does not eat $a$ during the interval $(t_0 - \delta,t_0)$.
Let $e_i'$ be an eating function that agrees with $e_i$ on $[0,t_0 - \delta]$ and eats only $a$ from $t_0 - \delta$ until the time $t_1'$ when it ceases to be available because  $q_a^{e_i'}(t_1') = 0$.  We have $t_1 - t_1' - \delta \ge 0$ because this is the difference between the consumption of $a$ by $i$ under $e_i$ and the consumption of $a$ by $i$ under $e_i'$.  In particular $t_1' < t_1$.

During the interval $[t_0,t_1']$ the events that change the availability of objects are exhaustion of objects.
Aiming at a contradiction, suppose that there is a  $t \in [t_0,t_1']$ such that there is some $o \in O(t) \setminus \{a\}$ such that $o$ is available under $e_i$ but not under $e_i'$, and let $t^*$ be the greatest lower bound of the set of such $t$.
For each $t \in [t_0,t^*]$, $j \ne i$, and $o \ne a$,  if $j$ was consumes $o$ at time $t$ under $e_i'$, and $o$ is available to $j$ at time $t$ under $e_i$, then $j$ is consuming $o$ at time $t$ under $e_i$ because the set of things in $O \setminus \{a\}$ that are available at time $t$ under $e_i$ is a subset of the set of things  in $O \setminus \{a\}$ that are available at time $t$ under $e_i'$.  Therefore, for $t \in [t_0,t^*]$, $j \ne i$, and $o \ne a$, the total consumption of $o$ by $j$ is weakly greater under $e_i$ than under $e_i'$ because $j$ is eating $o$ under $e_i$ at each time when it has not been fully allocated under $e_i'$ and is being eaten by $j$ under $e_i'$.  It follows that an object that is fully allocated at or before $t^*$ under $e_i'$ is also  fully allocated at or before $t^*$ under $e_i$.  Therefore, for times near $t^*$ (on both sides if $t^* < t_1'$) for every $o \in O(t) \setminus \{a\}$ such that $o$ is available under $e_i$,  $o$ is also available under $e_i'$, contradicting the definition of $t^*$.

We have shown that for all  $t \in [t_0,t_1']$, all $j \in I \setminus \{i\}$, and all $o \in O \setminus \{a\}$, if $o$ is not available to $j$ at $t$ under $e_i'$, then it is not available to $j$ at $t$ under $e_i$. It follows that  for all  $t \in [t_0,t_1']$ the set of $j$ eating $a$ at $t$ under $e_i$ is a superset of the set of $j$ eating $a$ at $t$ under $e_i'$.  In particular, the amount of $a$ that remains uneaten at $t_1'$ under $e_1$ is not more than $\delta$, and in order to have $t_1 - t_1' - \delta \ge 0$ it must be the case that the amount that remains uneaten is $\delta$ and $i$ is the only agent eating $a$ during the interval $[t_1',t_1]$.  Since all agents are allowed to eat all objects, and they all have the same requirement, once an agent starts to eat $a$, she will continue to do so until it is exhausted or time $r$, so it must be the case that no agent other than $i$ was eating $a$ at any time.
Even if all this is the case, the consumption of $a$ by $i$ under $e_i'$ is as large as the the consumption of $a$ by $i$ under $e_i$, so $e_i'$ is  also a feasible element of $\cE_i$ that maximizes the overall allocation of $a$ for $i$.  The argument can now be repeated with $e_i'$ in place of $e_i$, and after finitely many repetitions we arrive at the conclusion that there is an optimal eating function that eats $a$ from time $0$ until time $r$ or $a$ is exhausted without anyone else ever eating $a$.  Since $r < q_a$, the unique such eating plan is to eat $a$ at all times.

Let $b$ be $i$'s second favorite element of $O$.  With obvious modifications, the argument above easily extends to show that among the eating functions for $i$ that maximize the overall allocation of $a$ for $i$, those that maximize the overall allocation of $b$ for $i$ have $i$ eating $b$ at every time when $a$ is not available and $b$ is.  The intuition is the same: if $i$ faces competition for $b$, the amount of $b$ consumed is maximized by eating $b$ from the time when $a$ becomes unavailable, and if there is no competition for $b$, then the unique optimal eating plan is to eat $b$  from the time when $a$ becomes unavailable to time $r$.  Extending this inductively, if an eating function for $i$ results in an allocation for $i$ that stochastically dominates the allocation resulting from the GCPS mechanism, then it agrees with the eating function $e^{\succ_i}$ of the GCPS mechanism, and therefore the resulting allocation is the GCPS allocation, which is the assertion of Theorem \ref{th:WeakStrategyProof}.

\norev
 
This result opens up an interesting possibility.  Suppose that, pursuing a suggestion of \cite{as03aer}, for affirmative action purposes a school has been divided into three parts, one with 30\% of the seats that is reserved for minority students, one with 30\% of the seats that is reserved for majority students, and one with 40\% of the seats that accepts all students.   After the procedure has been run the results may be disappointing if, for example, one of the three schools is severely underenrolled.  Alternatively, it may happen that an elite school is either underenrolled or has admitted many less qualified students while students with superb test scores failed to get in, due to the luck of the draw.  In both of these cases one might wish to rerun the process with adjusted parameters, changing the seat assignments of the three schools or the test score cutoff of the elite school.  

In their most basic forms school choice mechanisms based on bilateral matching mechanisms require that the schools have priorities that are strict preference orderings of the students.  These may refine legally mandated priorities, but in some cases the additional preferences of the schools do not represent actual social desiderata, and may interfere with efficiency.  But it is also possible that it is socially desirable that the preferences of the highest priority students are given greatest consideration.  In the matching resulting from deferred acceptance each school has a priority cutoff such that the proposals of students with higher priority are certainly accepted and those with lower priority are certainly rejected.  To approximate this with the GCPS mechanism one may run it repeatedly, gradually increasing the priority cutoffs of schools that are overdemanded (as manifested by many students receiving assignment probabilities far below one) until there is approximate balance of supply and demand at each school.

In many mechanism design contexts running a mechanism repeatedly with adjusted parameters would be regarded as cheating, since the putative mechanism (a single run of the GCPS mechanism) has been replaced by a much more complicated iterative process.  However, from the the point of view of the final run it is still best to report one's true preference, so the only way that misreporting might possibly be beneficial is if the manipulator managed to maneuver the iterative adjustment process to a different endpoint, and of course it is implausible that anyone could be that foresightful.  Thus it seems to reasonable to regard the procedure as strategy proof even if there are the sorts of ex post adjustments we have described.
