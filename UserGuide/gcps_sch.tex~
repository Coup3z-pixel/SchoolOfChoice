\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{amsthm}
\makeatletter
\usepackage{graphicx,epsf}
\usepackage{times,float}
\usepackage{enumerate}
\usepackage[round,comma]{natbib}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}
\usepackage{bm}
\usepackage{multirow}
%\usepackage{blkarray}
\usepackage{rotating}

\setlength{\textwidth}{6.4in} \setlength{\textheight}{8.5in}
\setlength{\topmargin}{-.2in} \setlength{\oddsidemargin}{.1in}
\renewcommand{\baselinestretch}{1.3}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem*{thm*}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{rem}{Remark}
\newtheorem{ex}{Example}
\newtheorem{fact}{Fact}
\newtheorem*{fact*}{Fact}
\newtheorem{remark}{Remark}


\newcommand{\rR}{\mathrel{R}}
\newcommand{\rP}{\mathrel{P}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\norev}{\medskip \centerline{\textbf{No Revisions Below}} \medskip}
\renewcommand{\Re}{\mathbb{R}}
\newcommand{\In}{\mathbb{Z}}

\newcommand{\bare}{\overline{e}}
\newcommand{\barl}{\overline{l}}

\newcommand{\bq}{\mathbf{q}}

\newcommand{\cE}{\mathcal{E}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cX}{\mathcal{X}}

\newcommand{\dr}{{\dot r}}
\newcommand{\dq}{{\dot q}}
\newcommand{\dg}{{\dot g}}
\newcommand{\ddp}{{\dot p}}

\newcommand{\hA}{{\hat A}}
\newcommand{\hO}{{\hat O}}

\newcommand{\halpha}{{\hat \alpha}}

\newcommand{\ta}{{\tilde a}}
\newcommand{\te}{{\tilde e}}
\newcommand{\tn}{{\tilde n}}

\newcommand{\tB}{{\tilde B}}

\newcommand{\bark}{{\overline k}}
\newcommand{\bart}{{\overline t}}

\newcommand{\varep}{\varepsilon}

\newcommand{\bone}{\mathbf{1}}

\begin{document}

\title{An Efficient School Choice Mechanism Based on a Generalization of Hall's Marriage Theorem}

\author{Andrew McLennan\footnote{School of Economics, University of
    Queensland, {\tt a.mclennan@economics.uq.edu.au}} \and  Shino
Takayama\footnote{School of Economics, University of
  Queensland, {\tt s.takayama1@uq.edu.au}} \and Yuki Tamura\footnote{Center for Behavioral Institutional Design, NYU Abu Dhabi; {\tt yuki.tamura@nyu.edu}}}

\date{\today}

\maketitle

\begin{abstract}
We prove a generalization, for continuous variables, of Hall's marriage theorem for bipartite graphs.  Using this, we describe an implementation of the Generalized Constrained Probabilistic Serial (GCPS) mechanism of \cite{balbuzanov22jet}, which is an extension of the probabilistic serial rule of \cite{bm01}, to problems with various constraints.  This mechanism is efficient in a strong sense.  When the inputs are integral, the resulting probabilities are implementable in the sense that they can be realized as lotteries of pure outcomes.  When there are either a small number of agents or a small number of objects, this mechanism is computationally tractable.  Because school choice problems typically have a small number of schools, the GCPS can be applied in that domain.  We extend the result of \cite{km10jet} showing that the mechanism is strategy proof when the number of agents consuming each object is large.
\end{abstract}

Key Words: School Choice, Object Allocation, Efficiency, Fairness,  Probabilistic Serial Rule.

% \pagebreak

\section{Introduction}

We propose a new school choice mechanism that is a specialization of the generalized constrained probabilistic serial (GCPS) mechanism of \cite{balbuzanov22jet}, which is in turn a generalization of the probabilistic serial mechanism of \cite{bm01} (henceforth BM).  Each student  has a ``safe school'' (perhaps the school in her walk zone) and is guaranteed to receive an assignment that is at least as good.  She submits a ranking of schools that she weakly prefers to the safe school and for which she is eligible.  Unlike mechanisms based on bilateral matching, our mechanism does not endow the schools with priorities (i.e., preferences over students) but schools may have eligibility criteria based, for example, on test scores or other measures of academic ability and achievement, gender, or minority status.

As in the BM ``eating'' algorithm, during the unit interval of time students are assigned probability of receiving a seat in their favorite school, at unit speed, until some constraint is encountered.  The constraint may be that some school's seats are fully allocated, in which case each students who was receiving probability of a seat in that school switches to receiving probability of a seat in her favorite school that she is still eligible for and that is not yet full.  A second type of constraint is encountered when a set of schools has only enough remaining capacity to serve the students whose safe schools are in the set and who do not prefer any schools outside the set to the safe school.  In this case students with safe schools outside the set, and students who prefer schools outside the set to safe schools in the set, lose eligibility for additional probability of a seat at schools in the set. For a student who prefers a school outside the set to a safe school in the set, the new safe school is the least preferred school among those she is still eligible for.  In effect the process splits into two subprocesses, one related to schools in the set and another related to schools outside the set.  In this sense the process has a recursive character.

At time 1 there is a matrix of assignment probabilities that gives each student a probability distribution over schools.  A result of \cite{bckm13aer} implies that these assignment probabilities are induced by a probability distribution over pure assignments.  In contrast with matching based school choice mechanisms, which produce assignments that are ex post inefficient (e.g., \cite{apr09aer}) the assignment probabilities produced by our mechanism satisfy BM's notion of sd-efficiency: it is impossible to give each student a probability distribution over schools that is first order stochastically dominant for her ordinal preferences, and strictly dominant for some students.  Our mechanism satisfies equal treatment of equals and various other criteria of fairness.  While our mechanism is not fully strategy proof, we give a result showing that it is very difficult to manipulate, roughly because manipulation by a student changes the allocation only in proportion to the extent that the student consumes probability at inferior (for her true preferences) schools, and the induced opportunities to consume preferred schools are brief when many students are competing for seats in each school.

Perhaps the most surprising aspect of our mechanism is its computational tractability.  For the general GCPS mechanism the computation of the relevant constraints can be burdensome.  Our Theorem \ref{th:MultiHall} is a generalization of Hall's marriage theorem that, for a somewhat larger class of problems, gives the relevant constraints in closed form.  This will allow us to describe an algorithmic implementation of the mechanism whose complexity analysis shows that the mechanism is computationally feasible even for very large school choice problems.

The remainder of this introduction gives a more leisurely description of school choice, some related literature, and additional detail concerning our procedure.


The initial generation of school choice mechanisms was not theoretically well founded, and ran into difficulties.  The most famous is the Boston mechanism, in which the mechanism first tries to place as many students as possible at their top choices, then tries to place as many of the remaining students at their second choices, and so forth.  This mechanism is not strategy proof because, for example, a student who has little chance of being accepted by her favorite school may be able to significantly increase her chance of acceptance at her second favorite by listing it as her favorite.

This problem was quickly observed in practice, and was recognized theoretically by \cite{as03aer}, who suggested mechanisms based on deferred acceptance and top trading cycles, which are bilateral matching mechanisms.  In school choice the schools are not endowed with preferences over students, but instead are often required by law to respect certain priorities.  For example, in Boston the highest priority was to match students to schools with siblings in their walk zone, the second priority was to match students to other schools with a sibling, the third priority was to match other students to the schools in their walk zones, and all other matches of students to schools were a lowest priority equivalence class.  (Note that, since the priorities are ranked, it seems to be expected that they will not be fully honored in some cases. In our mechanism such priorities can be treated as constraints that must be satisfied without fail.) Deferred acceptance and top trading cycles require that both sides of the market have strict preferences, and they can be implemented in the school choice setting by endowing each school with a (perhaps randomly chosen) strict priority over students that is consistent with the legal priority. 
The version of deferred acceptance in which the students propose to the schools is strategy proof for the students and avoids justified envy, which is a circumstance in which a student prefers a different school that is providing a seat to a student with lower priority at that school.  Student proposes deferred acceptance is now widely used in school choice around the world.

\cite{GaSh62} show that the student proposes deferred acceptance algorithm yields the best outcome for each student that can be achieved in any allocation without justified envy for the given priorities.  For college admissions it is, perhaps, appropriate to regard the schools' preferences as worthy of moral consideration in welfare calculations, or at least as given conditions of the problem of finding outcomes that are stable.  (A bilateral matching is stable if there is no student-school pair that each prefer the other to their assigned partner, i.e., there is no justified envy.)  In the school choice setting respecting the schools' ``preferences'' can result in outcomes that are inefficient in the sense that there are reassignments that respect the priorities imposed by law, make each student no worse off, and strictly improve the assignments of some students.   In the simplest instance, if Bob prefers Carol School to Alice School, while Ted prefers Alice School, the mechanism may nevertheless assign Bob to Alice School and Ted to Carol School if Bob has higher priority than Ted at Alice School and Ted has higher priority than Bob at Carol School.

In a study of New York City data \cite{apr09aer} found that the inefficiencies arising in this way are quantitatively significant.  There is less inefficiency if the students are ranked in the same way at all of the schools they are eligible for, but this does not completely eliminate inefficiency. In fact there are theoretical barriers to improving efficiency by manipulating the breaking of ties in the schools' rankings.
Improving on results of \cite{kesten06jet} and \cite{ee08aer}, Theorem 1 of Abdulkadiro{\u{g}}lu et.~al.~asserts that, for any member of a large class of tie breaking rules, there is no mechanism that is both strategy proof for that tie breaking rule and gives outcomes that weakly Pareto dominate those produced by student-proposing deferred acceptance. 

\cite{ee08aer} and \cite{ku15te} propose mechanisms that adjust the outcome produced by deferred acceptance by repeated Pareto improvements, until an efficient outcome is achieved.  These adjustments necessarily violate the given priorities.  Although a student's priorities (beyond those mandated by law) are artificial, they are, in a sense, part of the student's endowment.  \cite{kesten10qje} proposes methods of adjustment that only violate priorities that students voluntarily relinquish, and shows that relinquishing priorities never results in a worse outcome.  Priority based deferred acceptance mechanisms, and the closely related priority based top trading cycles mechanisms (c.f.~\cite{acprt20aeri} and references therein) continue to be active areas of research, and the literature is now far too extensive to survey systematically.

The mechanism proposed here is not based on endowing the schools with artificial strict priorities.  Instead we work with a generalization of the probabilistic serial rule proposed in the seminal paper of \cite{bm01} for the problem of allocating a different object from a given finite set to each of finitely many agents.  The most common mechanism for this problem is random priority: an ordering of the agents is chosen randomly, the first agent chooses her favorite object, and each subsequent agent chooses her favorite object from those that remain after earlier choices.  This mechanism is strategy proof, and it satisfies many criteria of fairness if each ordering of the agents is equally likely.  
However, BM point out that it is inefficient in the sense that it can give a probability distribution over assignments that is Pareto dominated in the strong sense that there is a different probability distribution that gives each agent a probability distribution over the objects that is first order stochastically dominant for her ordinal preference.  

BM provide an intuitive description of the probabilistic serial rule in terms of simultaneous eating.  Each object is regarded as a perfectly divisible cake of unit size.  At the beginning each agent consumes probability of her favorite cake at unit speed, and this continues until some cake is fully allocated.  At that time each agent who was eating such a cake switches to their favorite among those cakes that are not yet fully allocated, and the process continues similarly, with each agent always consuming probability of her favorite among those cakes that are not fully allocated.  Provided that there are at least as many objects as agents, at time 1 each agent has a probability distribution over the objects, and for each object the sum of the assignment probabilities is not greater than one.  The Birkhoff-von Neumann theorem implies that any such assignment of probabilities can be implemented as a probability distribution over deterministic assignments.

Extensions of BM's cake eating procedure have been proposed in (at least) four other papers.  \cite{KaSe06} extend the probabilistic serial mechanism to profiles of preferences that have indifferences.  Using the method of network flows (see Section \ref{sec:GenHall}) they first maximize the amount that every agent can be given of objects in their top indifference class.   Some set of agents is  a maximal ``bottleneck'' for this problem because giving them this quantity fully exhausts the relevant objects.  These objects are allocated to these agents, leaving a residual problem, to which the procedure can be applied, and this is done repeatedly, until each agent has total probability one.  Their mechanism has both the mechanism proposed by BM for strict preferences and the mechanism proposed by \cite{bm04} for matching problems with dichotomous preferences as special cases.

\cite{kojima09mss} studies perhaps the simplest extension of BM in which agents receive multiple objects.  Each agent receives $r \ge 2$ objects, and the number of objects is $r$ times the number of agents.  Each agent has a strict preference ordering of the objects and a cardinal utility function consistent with that preference, and the utility of any bundle of $r$ objects is the sum of the utilities of its elements.  The eating algorithm is defined as in BM: each agent consumes (at unit speed) probability of receiving her favorite object among those that have not already been fully allocated.  The mechanism is shown to be ordinally efficient and envy-free, but not weakly strategy proof, as we explain in more detail in Section \ref{sec:StrategyProof}.

\cite{bckm13aer} study problems in which there are constraints that require that certain sums of probabilities are bounded, either below, in which case the constraint is a \emph{floor constraint}, or above, in which case it is a \emph{ceiling constraint}.  For a problem with only ceiling constraints in which  there is a ``null object'' (being unemployed, unhoused, or unschooled) that is available in infinite supply, and which is not involved in any constraint, they propose a \emph{generalized probabilistic serial} (GPS) mechanism.  As in BM, at each moment in $[0,1]$ each agent increases her probability of receiving her favorite object among those that are available to her.  When a ceiling constraint binds with equality, the sets of available objects are revised by disallowing further consumption of probabilities that would lead to the constraint being violated.  Since the null object is always available, each agent's set of available objects is always nonempty.  Thus at time 1 each agent has total probability one, and the GPS assignment is defined as the probability shares that have been eaten by each agent at time 1.

In \cite{balbuzanov22jet} the set of feasible allocations is a given polytope $Q$ in the nonnegative orthant of the space of matrices of assignment probabilities.    To facilitate the discussion we quickly review some basic results (without proofs) and terminology. A \emph{polytope} may be defined to be the convex hull of a finite set of points, or as an intersection of finitely many closed half spaces that happens to be bounded.  To avoid technical detail we assume that $Q$ is full dimensional, in the sense that its affine hull is the entire Euclidean space of which it is a subset. Among the finite systems of weak linear inequalities that may be used to define $Q$, there is a unique (up to rescaling of inequalities by multiplication by positive scalars) such system that is minimal, and that is contained in any other such system.  Its elements are the \emph{facet inequalities} of $Q$.  For each facet inequality the corresponding \emph{facet} is the subset of $Q$ on which the facet inequality holds with equality.  A subset of $Q$ is a \emph{face} if it is $Q$ itself, the null set, or the intersection of some set of facets.  A polytope $Q$ is the convex hull of a finite set of points, and among the finite sets whose convex hulls are $Q$, there is a unique such set that is minimal in the sense that it is contained in any other such set, whose elements are the \emph{vertices} of $Q$.  The vertices of $Q$ may also be described as its extreme points, where an \emph{extreme point} of $Q$ is a point that cannot be expressed as a convex combination of other points of $Q$.

Balbuzanov's \emph{generalized constrained probabilistic serial} (GCPS) mechanism first constructs the intersection $R$ of the nonnegative orthant with the sum of $Q$ and the nonpositive orthant.  That is, a point in the nonnegative orthant is in  $R$ if and only if it lies below some point of $Q$.  A key result (Proposition 1) is that the facet inequalities of $R$ (other than the nonnegativity conditions) require that weighted sums of probabilities, with nonnegative weights, not exceed certain quantities.
The simplest version of Balbuzanov's procedure begins at the origin and increases each agent's probability of receiving her favorite object at unit speed until one or more of the facet inequalities of $R$ holds with equality.  At this point each agent's set of allowed objects is updated by disallowing further consumption of probabilities that would result in one of these facet inequalities being violated.  The process then continues, with each agent increasing the probability of receiving her favorite allowed object, if an allowed object exists, until additional facet inequalities of $R$ are encountered. Again each agent's set of allowed objects is updated, and so forth.  Any point in $R$ that is not in $Q$ lies below some point of $Q$, so there are some probabilities that can be increased, hence some agents that have nonempty sets of allowed objects, and consequently the process cannot halt at such a point.  For this reason the process necessarily arrives at a point in $Q$.  

One computational implementation of Balbuzanov's procedure first passes to the description of $Q$ as a convex hull of vertices.  To compute $R$ as a convex hull of vertices one adds to this vertex set all the points obtained from vertices of $Q$ by changing some of the components to zero.  After that one can pass to the description of $R$ as an intersection of finitely many half spaces, and this description can be used in the computation of the outcome, as described above.  The computational problem of passing from the description of a polytope as a convex hull of vertices to its description as an intersection of finitely many half spaces, and the reverse computation, are well studied, and efficient software for these tasks is available.  (See Section 3 of \cite{balbuzanov22jet}.)  However, even if the number of bounding inequalities of $Q$ and the number of bounding inequalities of $R$ are small, large data structures can arise at intermediate stages of the computation.  For example, for the problem of assigning $n$ objects to $n$ agents the numbers of bounding inequalities of $Q$ and $R$ are constant multiples of $n$, but $Q$ has $n!$ vertices.

We now briefly describe our formal framework.  A \emph{communal endowment economy} (CEE) is a
quintuple $$E = (I,O,r,q,g)$$ in which $I$ is a nonempty finite set of
\emph{agents}, $O$ is a nonempty finite set of \emph{objects}, $r \in \Re_+^I$, $q \in \Re_+^O$, and $g$ is a matrix with entries in $\Re_+$ that are indexed by the elements of $I \times O$.  We say that $r_i$ is
$i$'s \emph{requirement}, that $q_o$ is the \emph{quota} of $o$, and that $g_{io}$ is \emph{$i$'s $o$-max}.  In comparison with most models of random assignment, the matrix $g$ is the main novelty, and we will see that it may represent several things and be used in various ways.
We say that an integral $E$ is a \emph{school choice CEE} if $r_i = 1$ for all $i$, each $q_o$ is a positive integer, and $g_{io} \in \{0,1\}$ for all $i$ and $o$.  The interpretation is that student $i$ is eligible to attend school $o$, and may be required to attend school $o$, if $g_{io} = 1$, but not otherwise.

An \emph{allocation} for $I$ and $O$ is a
matrix $p$  with entries in $\Re_+$ that are indexed by the elements of $I \times O$.  A \emph{partial allocation} for $E$ is an allocation $p$ such that $\sum_o p_{io} \le r_i$ for all $i$, $\sum_i p_{io} \le q_o$ for all $o$, and $p_{io} \le g_{io}$ for all $i$ and $o$. A \emph{feasible allocation} is a partial allocation $m$ such that $\sum_o m_{io} = r_i$ for all $i$. 
A partial allocation $p$ is \emph{possible} if there is a feasible allocation $m$ such that $p \le m$.
Let $Q$ be the set of feasible allocations, and let $R$ be the set of possible partial allocations.  

Applied to $E$, the GCPS mechanism works as we described above, following an increasing path $t \mapsto p(t) \in R$ in which, at each time, each agent ``eats" her favorite allowed object at unit speed.  When a facet inequality of $R$ is encountered, further eating of objects that would violate it is disallowed, and the process continues as described above, eventually arriving at a point in $Q$.  Perhaps the most important contribution of this paper is to show that for the polytope $R$ derived from a CEE, the facet inequalities of $R$ lie in a certain set that is given in closed form, which has the consequence that the procedure is computationally tractable in many settings, including school choice.

In theory it is possible to ask each student to rank all of the schools for which she is eligible, in which case the GCPS would be effectively strategy proof, in the sense explained in Section \ref{sec:StrategyProof}.  However, the vast majority of school choice mechanisms limit the number of schools each student is allowed to rank, in which case there can be incentives to rank unpopular schools highly, even if they are not actually highly desired, for fear of receiving an abyssmal assignment.  

The GCPS mechanism makes it possible to endow each student  with a ``safe'' school, in the sense that there is guarantee that the student will not receive an assignment that is not at least as good. 
The safe school could be the school in the student's walk zone, or the favorite of that school and a sibling's school.
The assignment of safe schools must allow a feasible allocation. This requirement can be checked, either as described in Section \ref{sec:Procedure}, or by simply producing such an allocation.  Often simply assigning each student to her walk zone school will be such an allocation.

Provided that each student has a safe school, she need only submit a ranking of the schools that she is eligible for and that are weakly preferred to the safe school.  Formally, for each student $i$, $g_{io} = 1$ if $o$ is one of the schools $i$ ranked, and otherwise $g_{io} = 0$.   Since the student is unlikely to prefer a distant school without special features to her walk zone school, typically only a small number of schools will be ranked, and a reasonable upper bound on the number of schools the student is allowed to rank will create perverse incentives only in exceptional cases.  In short, the GCPS mechanism with safe schools provides a strong assurance that students are being given things they actually want, because they are given only things that they say they want, so they have no incentive to misreport.

Providing each student with a secure lower bound is, of course, desirable if it is not very costly, and it is hard to see how much could be gained by not providing such security.  Intuitively, one expects such guarantees to be popular with students and parents for reasons that might be dismissed as ``emotional'' or ``psychological.'' 
However, the moral intuition that such guarantees are desirable seems to involve more than efficiency or welfare considerations, narrowly construed. 

Matching based mechanisms can provide such a guarantee if the schools' priorities insure admission to the walk zone or sibling school.  Whether this happens in practice seems unclear. Actual school choice mechanisms differ greatly in detail, so it is difficult to generalize, but at least in New York City there is a final stage in which students who have not yet received a seat are simply assigned to the nearest school with an available seat \cite[p.~1974]{apr09aer}.  

In addition, most school choice programs restrict the number of schools that students are allowed to rank.  If students prefer more than the allowed number of schools to a school to which admission is guaranteed,  then GCPS, student proposes deferred acceptance, and top trading cycles are no longer strategy proof.  \cite{hk09jet} study the Nash equilibria of matching based mechanisms with such limitations.  \cite{chk10aer} is an experimental study of the effects of constraining the number of schools that can be ranked, for student proposes deferred acceptance and top trading cycles; a main finding is that constraints have a large negative effect on manipulability, and reduce efficiency and stability while increasing segregation.

In matching based mechanisms the schools' priorities can be used to advance certain policy objectives, so we need to see how those objectives can be implemented in our mechanism.  One concern is to direct high quality or sought after resources to students for whom they are appropriate or most beneficial.  In many countries this takes the form of restricting eligibility for elite high schools to students with good grades or high test scores, and this is easily implemented in the matrix $g$.  

In some applications of deferred acceptance the schools' priorities are used not only to break ties between students of otherwise equal priority, but also to influence the allocation of resources.
In China \citep{WaZh20} the student's score on a standardized exam is taken to be her priority, presumably reflecting a policy objective of providing the most highly demanded resources, and the widest range of options, to the most talented students.  Some school systems assign priority points to promote affirmative action goals, or to make it more likely that students will attend schools near their homes.  In effect, deferred acceptance computes a system of eligibility thresholds for the schools.
Within our framework one can try to compute such a system by running the algorithm multiple times (see Section \ref{sec:StrategyProof}) while increasing the eligibility threshold of schools with high demand (as indicated by many students receiving assignment probabilities that are not close to one) until each school's  demand is slightly more than the school's capacity.  

One way to implement affirmative action objectives has been suggested by \cite{as03aer}.  For example, a school may be divided into three subschools, one with 30\% of the seats that is reserved for minority students, one with 30\% of the seats that is reserved for majority students, and one with 40\% of the seats that accepts all students. To maintain maximum flexibility one may refine the stated preferences of the students by requiring that minority students prefer seats in the subschool that only accepts minority students to seats in the subschool that accepts all students, and similarly for majority students.

We will see that our mechanism satisfies the most important requirements and desiderata of school choice mechanisms.  In its application to school choice problems (though not to more general CEE's) it is effectively strategy proof.  It is implementable: the assignment probabilities it generates can be realized by a probability distribution over deterministic assignments.  It is efficient, in a strong sense.  

None of this would be of great interest if the mechanism was not also computationally tractable.
We will give a theorem that implies that the facet inequalities of $R$ are a subset of a finite set of inequalities that is given in closed form.
Our main result also gives a finite system of inequalities that is a necessary and sufficient condition for the existence of a feasible allocation.  Given a partial allocation $p$, is there a feasible allocation $m$ such that $p \le m$?  This turns out to be a problem of the same sort, so our main result gives a necessary and sufficient condition for the existence of such an $m$.  As the eating process follows a path in $R$, what happens when a facet of $R$ is encountered? We will see that the allocation problem divides into a finite collection of subproblems of the same sort, so that the computational process can be described recursively.  The relevant calculations are not unduly complex provided that either the number of elements of $I$ or the number of elements of $O$ is not too large, and for many school choice problems the number of schools is well within the feasible range.  However, we will point out several considerations suggesting that the computations are very likely to be feasible even when there are dozens or more than one hundred schools, so that computational complexity does not preclude application of the GCPS mechanism to even the world's largest school choice problems.

We now describe the structure of the remainder.  In section \ref{sec:GenHall} we state Hall's marriage theorem and our generalization of it, and we introduce a network that is used to prove our generalization by applying the max-flow min-cut theorem of \cite{FoFu56}.  This network is also applied in Appendix \ref{app:Implementability}, and the perspective it provides informs our discussion of related algorithmic literature.   

Section \ref{sec:Procedure} gives a detailed description of the allocation procedure, in general and in application to school choice.  Our main concern is to show that computational complexity considerations do not pose a barrier to the application of this procedure to even very large school choice problems.  Although there is an extensive computational literature related to network flow, we will see that taking advantage of the particular features of our problem gives a more favorable complexity analysis.

Given a strict preference on $O$, there is a derived stochastic dominance partial ordering of the space $\Delta(O)$ of probability measures on $O$ in which one measure is $sd$-better than another if, for any $o \in O$, the probability assigned to elements of $O$ that are at least as good as $o$ is at least as large under the first measure as under the second.  BM say that a matrix of assignment probabilities is \emph{$sd$-efficient} if there is no other matrix that  gives every agent a probability distribution that is $sd$-better, and gives some agents different probability measures, which are necessarily strictly better.  In Section \ref{sec:Efficiency} we show that the outcome of the GCPS mechanism, when applied to a CEE, is $sd$-efficient.  Given a strict preference on $O$, there are also induced partial orderings of $\Delta(O)$ that correspond to assessing probability measures lexicographically, prioritizing either maximizing the probability of receiving the best element or minimizing the probability of receiving the worst object.  It turns out that efficiency with respect to these orderings is equivalent to $sd$-efficiency, so the outcome of the GCPS mechanism, when applied to a CEE and a profile of preferences, is also efficient in these senses.

A CEE is \emph{integral} if the $r_i$, $q_o$, and $g_{io}$ are all integers.  In Section \ref{sec:Implementability} we explain how a result of \cite{bckm13aer} implies that if a CEE is integral, then the vertices of the polytope $Q$ of feasible allocations have integral components.  For a school choice problem this means that the matrix of assignment probabilities produced by the GCPS mechanism can be realized as a probability distribution over pure assignments.

For object assignment, the PS mechanism is not strategy proof, but it is sd-strategy proof: misreporting one's preference never results in an allocation that stricly sd-dominates the allocation resulting from truthful reporting.  In Section \ref{sec:StrategyProof} we provide an extension of this result that shows that, to whatever  extent it fails in the school choice setting, this is related to some students not being eligible for certain schools.  
\cite{km10jet} provide a result that implies that the PS mechanism is effectively strategy proof if the number of objects of each type is large.  Specifically, for any cardinal utility over the object types, if the number of objects of each type is sufficiently large, then reporting the true preference is the unique dominant strategy for the PS mechanism.  We provide a variant of their result for the school choice setting.

In Section \ref{sec:EnvyFreeness} we show that that GCPS mechanism, applied to any CEE and any profile of preferences, is envy-free.

Section \ref{sec:Conclusion} provides some concluding remarks, and Appendices \ref{app:Cyclic}--\ref{app:StrategyProof} contain four of the more technical proofs.

\section{A Generalized Hall Marriage Theorem} \label{sec:GenHall}

In this section we work with a given communal endowment economy $E = (I,O,r,q,g)$.
We say that $E$ is a \emph{Hall marriage problem} if $r_i = 1$ for
all $i$, $q_o = 1$ for all $o$, and $g_{io} \in \{0,1\}$ for all $i$ and $o$. (Intuitively a Hall marriage problem is a bipartite graph with an edge connecting $i$ to $o$ if $g_{io} = 1$.)  We say that an allocation $p$ is \emph{integral} if, for all $i$ and $o$, $p_{io}$ is an integer. For a Hall marriage problem an integral feasible allocation is called a \emph{matching}.  (The elements of $I$ all have different partners in $O$.)
If $E$ is a Hall marriage problem, then for $i \in I$ the set of \emph{neighbors} is $N_g(i) = \{\, o \in O : g_{io} = 1
\,\}$, and for $J \subset I$ we set $N_g(J) = \bigcup_{i \in J}
N_g(i)$.  We say that $E$ satisfies the   \emph{marriage condition} if $|J| \le |N_g(J)|$ holds for all $J \subset I$.  Hall's marriage theorem asserts that a Hall marriage problem has a matching if
and only if it satisfies the marriage condition.  (Of course the `only if' is obvious.)

For $J \subset I$ and $P \subset O$ we let $J^c = I \setminus J$ and $P^c = O \setminus P$ be the complements.  We say that a general CEE $E$ satisfies the \emph{generalized marriage condition}
(GMC) if,  for every $J \subset I$ and $P \subset O$,
$$\sum_{i \in J} r_i \le \sum_{i \in J} \sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o.$$  We will refer to this relation as the \emph{GMC inequality for $J$ and $P$}.  Note that the GMC inequality for  $J = \{i\}$ and $P = \emptyset$ is  $r_i \le \sum_o g_{io}$,  and the GMC inequality for  $J = I$ and $P = O$ is  $\sum_i r_i \le \sum_o q_o$, which are obvious necessary conditions  for
the existence of a feasible allocation.

If $E$ is a student choice CEE then, for a given $P \subset O$, the difference between and the right hand side and the left hand side of the GMC inequality is minimized by having $J$ be the set of $i$ such that $\{\, o : g_{io} = 1 \,\} \subset P$.  Thus $E$ satisfies the GMC if and only if, for each $P \subset O$, the aggregate quota of $P$ suffices to meet the requirements of the students who must be given a seat at some school in $P$.

If $E$ is Hall marriage problem, then the GMC inequality for $J$ and $P = N_g(J)$ gives the marriage condition $|J| \le |N_g(J)|$.  Conversely, for a
given $J \subset I$, the contribution of $o \in N_g(J)$ to the right
hand side of the GMC inequality is minimized if $o \in P$, and the
contribution of $o \in N_g(J)^c$ is minimized if $o \in
P^c$, so $|J| \le |N_g(J)|$ for all $J$ implies that the GMC is
satisfied.  Therefore Hall's theorem is a special case of our first main result.

\begin{thm} \label{th:MultiHall}
  The CEE $E$ has a feasible allocation if and only if it satisfies the GMC.
\end{thm}

Our proof of this is a simple application of the method of network flows.  (\cite{AhMaOr93} provides a general introduction and overview.)  We define a directed graph $(N,A)$ in which the set of \emph{nodes} is
$$N = \{s\} \cup I \cup (I \times O) \cup O \cup \{t\},$$
where $s$ is  the \emph{source} and $t$ is the \emph{sink}, and the set of \emph{arcs} is
$$A = \{\, a_i : i \in I \,\} \cup \{\, a_{io} : i \in I, o \in O \,\} \cup \{\, a_{oi} : i \in I, o \in O \,\} \cup \{\, a_o : o \in O \,\}$$
where $a_i = (s,i)$, $a_{io} = (i, (i,o))$, $a_{oi} = ((i,o),o)$, and $a_o = (o,t)$. 
  
  A \emph{flow} is a function $f \colon N \times N \to \Re$ such that:
  \begin{enumerate}
    \item[(a)] for all $n$ and $n'$,  $f(n,n') = - f(n',n)$ and $f(n,n') \le 0$ if $(n,n') \notin A$; 
    \item[(b)] $\sum_{n' \in N} f(n',n) = 0$ for all $n \in N \setminus \{s,t\}$. 
  \end{enumerate}
  If  neither $(n,n')$ nor $(n',n)$ is in $A$,  then (a) implies that $f(n,n') = 0$.  If $(n',n) \notin A$ whenever $(n,n') \in A$ (as is the case for the particular graph we are studying) then $f(n,n') \ge 0$ whenever $(n,n') \in A$.
  In conjunction with the other requirements, (b) can be understood as saying that the total flow into each $n$ other than $s$ and $t$ is equal to the total flow out.  The total flow into all nodes (including $s$ and $t$) is equal to the total flow out of all nodes, so the total flow out of $s$ is equal to the total flow into $t$.
  This quantity is the \emph{value} of $f$:
  $$|f| = \sum_{n \in N} f(s,n) = \sum_{n \in N} f(n,t).$$ 
  If $p$ is an allocation, there is a unique flow $f_p$ such that $f_p(a_{io}) = f_p(a_{oi}) = p_{io}$ for all $i$ and $o$ that is given by setting $f_p(a_i) = \sum_o p_{io}$ and $f_p(a_o) = \sum_i p_{io}$. 
 

A \emph{capacity} for $(N,A)$ is a function $c \colon N \times N \to [0,\infty]$ such that $c(n,n') = 0$ whenever $(n,n') \notin A$.  A flow $f$ is \emph{bounded} by $c$ if $f(n,n') \le c(n,n')$ for all $(n,n')$.  (This condition holds automatically if $(n,n') \notin A$.) 
We define a capacity $c_E$ by setting $c_E(a_i) = r_i$, $c_E(a_{io}) = c_E(a_{oi}) = g_{io}$,  $c_E(a_o) = q_o$, and $c_E(n,n') = 0$ if $(n,n') \notin A$.  Evidently an allocation $p$ is a partial allocation if and only if $f_p$ is bounded by $c_E$.
  
A \emph{cut} is a partition $(S,T)$ of $N$ such that $s \in S$ and $t \in T$.  The \emph{capacity} of $(S,T)$ for a capacity $c$ is
  $$c(S,T) = \sum_{(n,n') \in (S \times T) \cap A} c(n,n'). \eqno{(*)}$$  For example $c_E(\{s\},N \setminus \{s\}) = \sum_i r_i$ and $c_E(N \setminus \{t\},\{t\}) = \sum_o q_o$.  Clearly the value of a flow bounded by $c$ cannot exceed $c(S,T)$.  In our setting, and more generally, the celebrated max-flow min-cut theorem \citep{FoFu56} asserts that the maximum value of flows bounded by $c$ is equal to the minimum capacity of a cut for $c$.

Let $(S,T)$ be a cut, and let $J = S \cap I$ and $P = S \cap O$.  We have $a_i \in (S \times T) \cap A$ for each $i \in J^c$,  either $a_{io} \in (S \times T) \cap A$ or $a_{oi} \in (S \times T) \cap A$ for each $(i,o) \in J \times P^c$, and  $a_o \in (S \times T) \cap A$ for each $o \in P$.  Applying these facts to ($*$) with $c_E$ in place of $c$ gives
$$c_E(S,T) \ge \sum_{i \in J^c} r_i + \sum_{i \in J} \sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o.$$
This inequality holds with equality if $J \times P \subset S$ and $J^c \times O \subset T$.  Let 
$$S_{(J,P)} = \{s\} \cup J \cup (J \times O) \cup P \quad \text{and} \quad T_{(J,P)} = J^c \cup (J^c \times O) \cup P^c \cup \{t\}.$$ 
These sets satisfy the conditions assumed for $S$ and $T$ in relation to $J$ and $P$, and the conditions under which the inequality above holds with equality, so
$$c_E(S_{(J,P)},T_{(J,P)}) = \sum_{i \in J^c} r_i + \sum_{i \in J} \sum_{o \in P^c} g_{io} + \sum_{o \in P} q_o$$
and thus $c_E(S_{(J,P)},T_{(J,P)}) \le c_E(S,T)$.
Therefore the minimum cut is attained by some cut of the form $(S_{(J,P)},T_{(J,P)})$.
Now observe that $(S_{(\emptyset,\emptyset)},T_{(\emptyset,\emptyset)}) = (\{s\},N \setminus \{s\})$, and the GMC inequality can be rewritten as $\sum_i r_i \le c_E(S_{(J,P)},T_{(J,P)})$, so the max-flow min-cut theorem implies that the maximum flow is $\sum_i r_i = c_E(S_{(\emptyset,\emptyset)},T_{(\emptyset,\emptyset)})$ if and only if this inequality holds for all pairs $(J,P)$, which is the assertion of Theorem \ref{th:MultiHall}.

Hall's marriage theorem and the max-flow min-cut theorem are two members of a large and important class of results in combinatorial matching theory that are equivalent in the informal sense that relatively simple arguments (described in detail by \cite{Rei78,Rei85}) allow one to pass from any member of the class to any other.  As yet another member of this class, Theorem \ref{th:MultiHall} does not provide distinctly novel mathematical information.  Its primary significance here, and perhaps more generally, is that the test it provides is in closed form.

\section{The Allocation Procedure} \label{sec:Procedure}

We now describe in somewhat more detail how the GCPS mechanism works for a problem given by a CEE $E = (I,O,r,q,g)$ and a profile $\succ \; = (\succ_i)_{i \in I}$ of strict preferences over $O$.   Since our main point is that this procedure is practical for school choice problems, we pay particular attention to the computational resources (in particular time) required by the process in this case.

A first point is that the mechanism depends only on the preferences of each agent $i$ over the objects $o$ that are possible for $i$, in the sense that $g_{io} > 0$.  In our exposition it is simplest to treat each $\succ_i$ as a complete ordering of $O$, but the computational procedure refers only to preferences over possible objects, so (in contract to the creation of priorities in deferred acceptance mechanisms for school choice) there is no need to expand the orderings of possible objects to complete orderings of $O$.

We first discuss the computational complexity of computing whether the GMC holds.  For a given $P \subset O$ the 
difference between the two sides of the GMC inequality for $(J,P)$ is minimized if $J$ contains every $i$ such that 
$r_i > \sum_{o \in P^c} g_{io}$ and $J^c$ contains every $i$ such that $r_i < \sum_{o \in P^c} g_{io}$.  Computing the sums $\sum_{o \in P^c} g_{io}$ for all $i$ requires potentially $|I||O|$ additions, which dominates the $|P|$ additional comparisons required to check the inequality.  Thus, for a given $P$, the time required to check whether the GMC inequality holds for $P$ and all $J$ is of order $O(|I||O|)$.
Similarly, for any $J \subset I$ the right hand side of the GMC inequality is minimized if $P$ contains every $o$ such that $q_o < \sum_{i \in J} g_{io}$ and $P^c$ contains every $o$ such that $q_o > \sum_{i \in J} g_{io}$. Again,  the time required to check whether the GMC inequality holds for $J$ and all $P$ is of order $O(|I||O|)$.   Depending on whether $|I|$ or $|O|$ is smaller, we can check, for every $J \subset I$, whether the GMC inequality for $(J,P)$ is satisfied for every $P \subset O$, or we can check, for every $P \subset O$, whether the GMC inequality for $(J,P)$ is satisfied for every $J \subset I$.
Thus we have a crude bound on the worst case complexity of checking the GMC that is of order $O(\min\{2^{|I|}, 2^{|O|}\}|I||O|)$.  For school choice problems with a moderate number of schools this computational burden is not prohibitive, which is encouraging.

The computational problems of finding the maximum flow or a minimal cut  for a network are very well studied, and many algorithms have been developed.  \cite{GoTa88} list 15 that were known at the time of their work. As \cite{GrMcQuTa12} explain, each of the algorithms in 
\cite{GoTa88}, \cite{GuTa94}, \cite{Hoc08}, \cite{karzanov74smd}, 
\cite{KiRaTa94}, and \cite{Tar84} may be used as the relevant subroutine of a parametric minimum cut algorithm of the sort we describe later.  Each of these, and each in the list of \cite{GoTa88}, has a worst case complexity that is the number $|N|$ of nodes times the number $|A|$ of arcs times a logarithmic or linear factor.  For us this is roughly $|I|^2|O|^2$ times a logarithmic or linear factor.  In connection with the particular problem we study, it may be possible to improve these bounds.  (For example, in \cite{GoTa88} the bounds depend in part on the maximal length of a simple (no repeated nodes) path from $s$ to $t$, which is $4|O|$ in our case if $|O| \le |I|$, but they allow it to be as large as $|N|$.  On the other hand, this bound restricts their ability to choose a maximal tree size later in their analysis.)  The practical performance of these algorithms, in general, and in application to school choice, is almost certainly much better than the worst case obtained from even a bespoke complexity analysis, and it is entirely possible that in applications to school choice they would be as efficient and practical as the algorithms we describe.  At the present time the main virtue of our algorithms is that their complexity analysis allows us to argue convincingly that there is no computational complexity barrier to the application of the GCPS mechanism to school choice.

Throughout the remainder of this section we assume that $E$ satisfies the GMC.    For $J \subset I$ and $P \subset O$ we say that the pair $(J,P)$ is \emph{critical} for $E$ if it satisfies the GMC inequality for $(J,P)$ with equality:
$$\sum_{i \in J} r_i = \sum_{i \in J} \sum_{o
  \in P^c} g_{io} + \sum_{o \in P} q_o.$$   
We refer to this condition as the \emph{GMC equality} for $(J,P)$.
Evidently $(J,P)$ is critical if and only if any allocation gives the agents in $J$ all of the endowment of objects in $P$ and also as much of the objects in $P^c$ as $g$ allows.  If $(J,P)$ is a critical pair, we let $$E_{(J,P)} = (J,O,r|_J,q',g|_{J \times O})$$ where $q'_o = q_o$ if $o \in P$  and $q'_o = \sum_{i \in J} g_{io}$ if $o \in P^c$, and we let  $$E^{(J,P)} = (J^c, P^c, r|_{J^c},q'',g|_{J^c \times P^c})$$ where $q'' \colon O \setminus P \to \Re_+$ is the function $q''_o = q_o - \sum_{i \in J} g_{io}$. 
 Any feasible allocation for $E$ is the sum of a feasible  allocation for $E_{(J,P)}$ and a feasible allocation  for  $E^{(J,P)}$.  Conversely, any sum of a feasible allocation for $E_{(J,P)}$ and a feasible allocation for $E^{(J,P)}$ is a feasible allocation for $E$. Thus a critical pair splits the given allocation problem into two smaller problems \emph{of the same type}.

If $(J,P)$ is a critical pair, then any feasible allocation $m$ has $m_{io} = 0$ for all $i \in J^c$ and $o \in P$, and in this sense $g_{io} > 0$ is illusory.  We say that $E$ is \emph{tight} if $g_{io} = 0$ for all critical pairs $(J,P)$ and all $i \in J^c$ and $o \in P$.  If $(J,P)$ is a critical pair for $E$, the \emph{$(J,P)$-tightening of $E$} is the CEE $E' = (I,O,q,r,g')$ where $g'_{io} = 0$ if $i \in J^c$ and $o \in P$, and otherwise $g'_{io} = g_{io}$.  A \emph{tightening sequence} for $E$ is a sequence $(J_1,P_1), \ldots, (J_\ell,P_\ell)$ for which there is a sequence $E_0 = E, E_1, \ldots, E_\ell$ of CEE's such that for each $j = 1, \ldots, \ell$, $(J_j,P_j)$ is a critical pair for $E_{j-1}$ and $E_j$ is the $(J_j,P_j)$-tightening of $E_{j-1}$.  If $(J_1,P_1), \ldots, (J_\ell,P_\ell)$  is a tightening sequence for $E$ and $(J_0,P_0)$ is a critical pair for $E$, then $(J_0,P_0),(J_1,P_1), \ldots, (J_\ell,P_\ell)$ is also a tightening sequence for $E$: let $E_0'$ be the $(J_0,P_0)$ tightening of $E$, and  for each $j = 1, \ldots, \ell$, let $E_j'$ be the $(J_j,P_j)$-tightening of $E_{j-1}'$. (Since $(J_j,P_j)$ is critical for $E_{j-1}$, any feasible allocation assigns all of the endowment of $P_j$ to $J_j$, as well as all the resources in $P_j^c$ allowed by the $g$-component of $E_{j-1}$, and (by construction) the $g$-component of $E_{j-1}'$ is less than or equal to the $g$-component of $E_{j-1}$, so $(J_j,P_j)$ is also critical for $E_{j-1}'$.) Therefore starting with $E$ and repeatedly tightening with respect to critical pairs, including pairs that become critical as a result of the tightening, until no further tightening is possible, leads to a tight CEE that is independent of the order of tightening, that we call the \emph{tightening of $E$}. 

It is well known \citep{FoFu56,Sha61,Ore62} that the set of minimal cuts is a lattice in the sense that if $(S,T)$ and $(S',T')$ are minimal cuts, then so are $(S \cup S',T \cap T')$ and $(S \cap S',T \cup T')$.  For any pairs $(J,P)$ and $(J',P')$ the definition of $S_{(J,P)}$ and $T_{(J,P)}$ easily imply that $$(S_{(J,P)} \cup S_{(J',P')}, T_{(J,P)} \cap T_{(J',P')}) = (S_{(J \cup J',P \cup P')}, T_{(J \cup J',P \cup P')})$$ 
and  $$(S_{(J,P)} \cap S_{(J',P')}, T_{(J,P)} \cup T_{(J',P')}) = (S_{(J \cap J',P \cap P')}, T_{(J \cap J',P \cap P')}),$$ 
so if  $(J,P)$ and $(J',P')$
are critical pairs, then so are $(J \cup J',P \cup P')$ and $(J \cap J',P \cap P')$.  
In addition, if $E$ is tight and $(J,P)$ and $(J',P')$ are critical pairs with $J \subset J'$ and $P \subset P'$, then $(J' \setminus J,P' \setminus P)$ is critical.\footnote{
The GMC inequality for $(J' \setminus J,P' \setminus P)$ holds by assumption, so it suffices to show the opposite inequality.  When we compare  the GMC equation for $(J' \setminus J,P' \setminus P)$ with the difference between the GMC equations for $(J',P')$ and $(J,P)$, this boils down to $\sum_{i \in J' \setminus J} \sum_{o
  \in (P' \setminus P)^c} g_{io} \ge \sum_{i \in J'} \sum_{o
  \in {P'}^c} g_{io} - \sum_{i \in J} \sum_{o
  \in P^c} g_{io}$.  For $i \in J' \setminus J$ tightness gives $g_{io} = 0$ for $o \in P$, so $\sum_{o
  \in (P' \setminus P)^c} g_{io} = \sum_{o
  \in {P'}^c} g_{io}$.  For $i \in J$ we have $\sum_{o
  \in {P'}^c} g_{io} \le \sum_{o
  \in P^c} g_{io}$.
} 
  Thus, when $E$ is tight, every critical pair is a union (in the obvious pairwise sense) of minimal critical pairs, and every union of minimal critical pairs is critical.

We say that $E$ is \emph{simple} if there are no critical pairs $(J,P)$ with $\emptyset \ne J \ne I$.  We say that $E$ is \emph{critical} if $(I,O)$ itself is a critical pair, which is to say that any feasible allocation consumes all of the available resources.   Note that if $(J,P)$ is a critical pair, then $E_{(J,P)}$ is critical.    We have the following decomposition result.

\begin{prop}
 If $E$ is tight, then there are unique partitions $I_0,I_1, \ldots, I_k$ of $I$ and $O_0, O_1, \ldots, O_k$ of $O$ such that:
 \begin{enumerate}
   \item[(a)] If $E$ is critical, then each $(I_j,O_j)$ is a minimal critical pair, and  $E_0 = E_{(I_0,O_0)}, \ldots, E_k = E_{(I_k,O_k)}$ are simple and critical.
   \item[(b)] If $E$ is not critical, then $(I_1,O_1), \ldots , (I_k,O_k)$ are the minimal critical pairs.  Let $$E_0 = (I_0,O_0,r|_{I_0},q',g|_{I_0 \times O_0}),$$ where $q' \colon O_0 \to \Re_+$ is the function $q'_o = q_o - \sum_{i \in I \setminus I_0} g_{io}$.  Then $E_0$ is simple and not critical, and $E_1 = E_{(I_1,O_1)}, \ldots, E_k = E_{(I_k,O_k)}$ are simple and critical.
\end{enumerate}
In either case $E_0, \ldots, E_k$ is called the \emph{simple decomposition} of $E$.
\end{prop}

We have already seen that finding all the critical pairs of $E$ has a worst case complexity of order $O(\min\{2^{|I|}, 2^{|O|}\}|I||O|)$.  This allows the construction of a decomposition $E'_0 = E_{(I'_0,O'_0)}, \ldots, E'_{k'} = E_{(I'_{k'},O'_{k'})}$.  To compute the simple decomposition of $E$ one tightens and then computes the simple decomposition of each $E'_j$, descending recursively.  For this recursive construction, and similar constructions below, it will always be obvious that the sums of the worst case complexities of the pieces is not greater than the worst case complexity of the whole, roughly because for any partitions  $I_0,I_1, \ldots, I_k$ of $I$ and $O_0, O_1, \ldots, O_k$ of $O$ we have
$$\sum_{j=0}^k \min\{2^{|I_j|} , 2^{|O_j|} \}|I_j||P_j| \le \min\{2^{|I|}, 2^{|O|}\}|I||O|.$$

The GCPS mechanism has a recursive definition: the result of applying it to $E$ is \emph{by definition} the sum of the results of applying it to each of the components $E_j$ of the simple decomposition $E_0, \ldots, E_k$ of $E$.  We now assume that $E$ is simple. In the spirit of BM, we describe the GCPS mechanism in terms of cake eating, so at each time $t$ each agent who has not already attained her requirement is increasing (at unit speed) her probability of her favorite object among those that are still available to her.  This gives a path $t \to p(t)$ in the space of possible partial allocations. 
If $p$ is a partial allocation, let $E - p = (I,O,r',q',g')$ denote the derived CEE in which: $$r_i' = r_i - \sum_o p_{io}; \quad q'_o = q_o - \sum_i p_{io}; \quad g'_{io} = g_{io} - p_{io}.$$  
If $p$ is a partial allocation, $m$ is an allocation, and $p \le m$, then $m$ is a feasible allocation for $E$ if and only if $m - p$ is a feasible allocation for $E - p$.  Thus a partial allocation $p$ is possible if and only if $E - p$ has a feasible allocation, which of course is the case if and only if $E - p$ satisfies the GMC.  

It is intuitively natural to imagine the process beginning at time $0$ and continuing as we describe below until the first time $t^*$ such that $E - p(t^*)$ is not simple.  (Possibly $t^* = 0$.) At $t^*$ the simple decomposition of $E - p(t^*)$ is computed, and further eating continues concurrently in the various components, continuing in each until the residual CEE is not simple, at which point we split into components again, and continue recursively.  For the sake of concreteness we describe the process from this perspective.  (Of course the algorithmic implementation may be quite different.)  

Thus we assume that $E$ is simple, the process begins at time $t_0 \ge 0$, and it continues until the first time $t^*$ such that $E - p(t^*)$ is not simple.
For each $t \in [t_0,t^*]$ there are the following objects:
\begin{enumerate}
  \item[(a)] $p(t)$ is a partial allocation.
  \item[(b)] $E(t) = (I,O,r(t),q(t),g(t)) = E - p(t)$ is a CEE that satisfies the GMC.
  \item[(c)] For each $i$, $\alpha_i(t) = \{\, o : \text{$q_o(t) > 0$ and $g_{io}(t) > 0$} \,\}$ is $i$'s set of available objects.
  \item[(d)] For each $i$ such that $r_i(t) > 0$, $e_i^\succ(t)$ is the $\succ_i$-best element of $\alpha_i(t)$.
\end{enumerate}
We assume that $p(t_0)$ is given.  We require that $r(t)$, $q(t)$, $g(t)$, and $p(t)$ are continuous and piecewise linear functions of $t$, and that when their derivatives  $\dr(t)$, $\dq(t)$, $\dg(t)$, and $\ddp(t)$ with respect to time  are defined, they satisfy the obvious conditions representing each agent $i$ such that $r_i(t) > 0$ eating $e_i^\succ(t)$ at unit speed:
\begin{enumerate}
  \item[(a)] $\dr_i(t) = -1$ if $r_i(t) > 0$, and otherwise $\dr_i(t) = 0$.
  \item[(b)] $\dq_o(t) = -|\{\, i : \text{$r_i(t) > 0$ and $e_i^\succ(t) = o$} \,\}|$.
  \item[(c)] $\dg_{io}(t) = -1$ if $r_i(t) > 0$ and $e_i^\succ(t) = o$, and otherwise $\dg_{io}(t) = 0$.
  \item[(d)] $\ddp_{io}(t) = 1$ if $r_i(t) > 0$ and $e_i^\succ(t) = o$, and otherwise $\ddp_{io}(t) = 0$.
\end{enumerate}
We define $t^*$ to be the smallest number greater than $t_0$ such that either $r(t^*) = 0$ or $E(t^*) = E - p(t^*)$ is not simple.
We define the \emph{Generalized Constrained Probabilistic Serial} mechanism for $E$ by setting 
$$GCPS(E) = \begin{cases}p(t^*), & r(t^*) = 0, \\
p(t^*) + \sum_{j=0}^k GCPS(E_j), & \text{$E(t^*)$ is not simple},
\end{cases}$$ where $E_0, \ldots, E_k$ is the simple decomposition of the tightening of $E - p(t^*)$.  This is a recursive definition, which makes sense because each $E_j$ is ``simpler'' than $E$ in an obvious discrete combinatoric sense, so that we may assume that $GCPS(E_j)$ has already been defined.

In finer detail, the process begins by computing the first time $t_1$ such that one of the following events occurs:
\begin{enumerate}
  \item[(a)] $r_i(t_1) = 0$ for some $i$ such that $r_i(t_0) > 0$.
  \item[(b)] $q_o(t_1) = 0$ for some $o$ such that $q_o(t_0) > 0$. 
  \item[(c)] $g_{io}(t_1) = 0$ for some $i$ and $o$ such that $g_{io}(t_0) > 0$. 
  \item[(d)] $E - p(t_1)$ is not simple.
\end{enumerate}
If $E - p(t_1)$ is not simple, then $t^* = t_1$, the simple decomposition $E_0, \ldots, E_k$ of the tightening of $E - p(t^*)$ is computed, and the procedure is applied to each $E_j$.  Otherwise the $\alpha_i(t_1)$ and $e_i^\succ(t_1)$ are adjusted, and then the process computes the first time $t_2 > t_1$ such that one of the four possibilities holds, and so forth.  The computation of each $t_j \ne t^*$ involves some component of $r$, $q$, or $g$ becoming zero, so the maximal number of such computations is of order $O(|I||O|)$.  

The problem of determining whether a GMC inequality holds with equality at some time prior to the first time that (a), (b), or (c) hold is an instance of a \emph{parameterized min cut} problem because the capacities of the arcs in the network associated with $E - p(t)$ change over time.  \cite{GaGrTa89} provided the first algorithm for such problems that took advantage of the similarity of the various min cut problems that arise in the course of solving the larger problem; their algorithm uses the algorithm of \cite{GoTa88} as a subroutine.  Their algorithm is restricted to problems in which the capacities of the arcs leaving $s$ are increasing  and the capacities of the arcs entering $t$ are decreasing (or vice versa) while the capacities of all other arcs are constant.  In addition to providing an overview and introduction to more recent work, \cite{GrMcQuTa12} present somewhat weaker requirements that support the methods of \cite{GaGrTa89}, but even these conditions are not satisfied by our problem.

In general, for a given $P \subset O$, determining the first time such that there is a $J \subset I$ such that the GMC inequality for $(J,P)$ holds with equality, is complicated because for each $i$ the sign of $r_i(t) - \sum_{o \in P^c} g_{io}(t)$ can change at some time.  This quantity is an affine function of $t$, so its sign can change only once, and there are various computational strategies for dealing with this, so that a tractable implementation of the GCPS mechanism is certainly possible when $|I|$ or $|O|$ is sufficiently small.  For us the more important point is that for school choice problems this issue is much simpler.  For each $i$ and $o$, if $g_{io} = 1$ initially, then $g_{io}(t) \ge r_i(t)$ for all subsequent $t$, so an event of type (c) necessarily coincides with an event of type (a).  But in a school choice problem we initially have $r_i = 1$ for all $i$, and the agents are all eating at unit speed at each time, so there are no events of type (a) until $t = 1$, at which point the computation is over.  
Thus $t_1$ is the first time such that (b) or (d) holds.  In addition, for each $i$ we have $r_i(t) - \sum_{o \in P^c} g_{io}(t) \le 0$ for all $t$.
Thus, for each $P \subset O$, determining the first time prior to an event of type (b) such that there is a $J \subset I$ such that the GMC inequality for $(J,P)$ holds with equality is a linear problem whose complexity is of order $O(|I||O|)$.  

We have now seen that the GCPS mechanism does not entail an undue computational burden for a school choice problem when the number $2^{|O|}$ is not unreasonably large.  Actually, however, there are several reasons to expect that it is computationally feasible even for very large districts with dozens or even hundreds of schools.

First, if $q_o \ge \sum_i g_{io}$, so that $o$ has enough capacity to accommodate all students who might conceivably wish to receive a seat there, then $o$ will never be an element of $P$ for a minimal pair $(J,P)$ for which the GMC inequality holds with equality.  In practice we expect that this consideration will remove a large fraction of the schools from the burdensome part of the computation, particularly in districts with declining school age populations. The difference   $q_o(t) - \sum_i g_{io}(t)$ is weakly monotonic increasing, 
as some of the students who might get a seat at $o$ increase their probabilities of getting seats at schools they prefer to $o$.  Correspondingly, the set of schools that might be an element of $P$ for a minimal critical pair $(J,P)$ shrinks over time. 

A school district with many schools is necessarily spread across a large geographic area, and one should expect that there will very few if any students who prefer a distant school without any special features to the much nearer school they are entitled to attend.  
Consider two disjoint sets $P_1, P_2 \subset O$.  Let $P = P_1 \cup P_2$. Let $J_1 = \{\, i : \sum_{o \in O \setminus P_1} g_{io} = 0 \,\}$ be the set of students who must receive a seat at some school in $J_1$, let $J_2 = \{\, i : \sum_{o \in O \setminus P_2} g_{io} = 0 \,\}$, and let $J = \{\, i : \sum_{o \in O \setminus P} g_{io}  = 0\,\}$.   Clearly $J_1 \cup J_2 \subset J$, and if $(J,P)$ is a minimal critical pair, so that neither $(J_1,P_1)$ nor $(J_2,P_2)$ is critical, then $J \setminus (J_1 \cup J_1)$ must be nonempty, so that there is at least one student who must attend a school in $P$ and is able to attend schools in either $P_1$ or $P_2$.  This is unlikely if the schools in $P_1$ are clustered in one part of the school district while the schools in $P_2$ are clustered in distant part of the district.

Finally, it is possible to run the algorithm with an assumption that certain sets of schools will not be components of minimal critical pairs.  If this assumption is not correct, the progress of the algorithm will eventually reveal that there is no continuation leading to a feasible allocation.  One can then rerun the algorithm with a different set of assumptions (hopefully informed by the nature of the failure) concerning which sets of schools will be components of minimal critical pairs.  For example, one may assume that if $(J,P)$ is a minimal critical pair, then $P$ does not contain schools that are more than 10 kilometers apart.  (This is not implied by the argument of the last paragraph because, for example, it does not preclude the possibility of a minimal critical pair $(J,P)$ with $P = \{o_1, \ldots,o_k\}$ where $o_1$ and $o_k$ are distant, but for each $j = 1, \ldots, k-1$ there is at least one student who is willing to attend either $o_j$ or $o_{j+1}$.)  In this way one can hope to bypass the seemingly complex computational problem of efficiently enumerating the sets $P$ that are not eliminated from consideration by the argument of the last paragraph.

Taken together, these considerations suggest that the issue of computational burden does not preclude the GCPS mechanism from being used in even the world's largest school choice problems.  Our argument has been based on a description of the algorithmic implementation of the mechanism that is simplistic and naive.  Needless to say, there are no doubt many ways in which sophisticated software engineering techniques could further reduce the computational burden.


\section{Efficiency} \label{sec:Efficiency}

In this section we work with a fixed CEE $E$ and a fixed profile of preferences $\succ$.  Our objective is to show that GCPS mechanism applied to $E$ and $\succ$ yields an allocation that is $sd$-efficient, and efficient in other closely related senses.

For $i \in I$, an \emph{$i$-allocation} is a vector $m_i = (m_{io})_{o \in O} \in \Re^O_+$ such that $m_{io} \le g_{io}$ for all $o$ and 
$\sum_o m_{io} = r_i$.  The \emph{stochastic dominance relation} $R^{sd}(\succ_i)$ on $i$-allocations derived from $\succ_i$ is defined by $m_i' R^{sd}(\succ_i) m_i$ if $\sum_{p \succeq_i o} m_{ip}' \ge \sum_{p \succeq_i o} m_{ip}$ for all $o \in O$.   It is well known that $m_i' R^{sd}(\succ_i) m_i$ if and only if, for any cardinal utility function on $O$ consistent with $\succ_i$,  $m_i'$ has at least as large an expected utility as $m_i$.  

Two other well-studied extensions relate to lexicographic preferences (\citealp{cho16geb}; \citealp{sv15wp}; \citealp{cd16}; \citealp{ss14jme}; \citealp{cho18scw}). The first extension, which is called the \emph{downward lexicographic} extension ($dl$-extension) compares two $i$-allocations as follows. One of the $i$-allocations is preferred if it assigns a higher amount of the most preferred object than the other. If the two $i$-allocations assign the same amount of the most preferred object, then the one that is preferred is the one that assigns the greater amount of the second most preferred object. If the two amounts are equal again, then the $i$-allocation that assigns a greater amount of the third most preferred object is preferred, and so on.
The second extension, which is called the \emph{upward lexicographic} extension ($ul$-extension) is a dual of $dl$-extension. It lexicographically minimizes amounts of less preferred objects, starting from the least preferred object.  The $dl$- and $ul$-extensions yield preferences that represent the limits of standard vNM utility functions with extreme risk loving and risk aversion, respectively. 

Formally, the \emph{downward lexicographic relation} $R^{dl}(\succ_i)$ on $i$-allocations derived from $\succ_i$ is defined by specifying that $m_i' R^{dl}(\succ_i) m_i$ if  either $m_i' = m_i$ or there is an $o \in O$ such that $\sum_{p \succeq_i o'} m_{ip}' = \sum_{p \succeq_i o'} m_{ip}$ for all $o' \in O$ such that $o' \succ_i o$ and $\sum_{p \succeq_i o} m_{ip}' > \sum_{p \succeq_i o} m_{ip}$.   The \emph{upward lexicographic relation} $R^{ul}(\succ_i)$ on $i$-allocations derived from $\succ_i$ is defined by specifying that $m_i' R^{ul}(\succ_i) m_i$ if  either $m_i' = m_i$ or there is an $o \in O$ such that $\sum_{o' \succeq_i p} m_{ip}' = \sum_{o' \succeq_i p} m_{ip}$ for all $o' \in O$ such that $o \succ_i o'$ and $\sum_{o \succeq_i p} m_{ip}' < \sum_{o \succeq_i p} m_{ip}$.

For $e \in \{sd,dl,ul\}$, a feasible allocation $m'$ \emph{$e$-dominates} another feasible allocation $m$ if $m_i' R^{\text{e}}(\succ_i) m_i$ for all $i$ and there is some $i$ such that $m_i' \ne m_i$.  A feasible allocation $m$ is \emph{$e$-efficient} if there is no feasible allocation that $e$-dominates it.  This section's main result is:

\begin{thm}\label{thm:axiom_topdown}
For $e \in \{sd,dl,ul\}$, the GCPS allocation for $E$ and $\succ$ is \emph{$e$-efficient}.  
\end{thm}

A feasible allocation $m$ is wasteful if there are an agent $i$ and objects $o,o'$ such that $o \succ_i o'$, it would be possible for $i$ to consume more $o$, but $i$ consumes a positive amount of $o'$.  Formally, $m$ is \emph{wasteful}  if there are $i$ and $o,o'$ such that $o \succ_i o'$, $m_{io} < g_{io}$,  $\sum_{j \in I} m_{jo} < q_o$, and $m_{io'} > 0$. 

Given a preference profile $\succ$ and a feasible allocation $m$, we define a binary relation $\lhd_m$ on $O$ by specifying that $o \lhd_m p$ means that there is an $i$ who is consuming a positive amount of $o$, prefers $p$ to $o$, and could consume more $p$.  
Formally, $o \lhd_m p$ if there is an $i$ such that $m_{io} > 0$, $p \succ_i o$, and $m_{ip} < g_{ip}$.
The binary relation $\lhd_m$ is \emph{cyclic} if there is a cycle $$o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0,$$ and otherwise it is \emph{acyclic}.  Given such a cycle, if, for each $l$, $i_l$ is an agent such that  $m_{i_lo_l} > 0$, $o_{l+1} \succ_{i_l} o_l$, and $m_{i_lo_{l+1}} < g_{i_lo_{l+1}}$, then
for sufficiently small $\delta > 0$ the matrix $m(\delta)$ defined by 
$$
m_{io}(\delta) =
\begin{cases}
m_{io} - \delta, &\text{if}~(i,o) \in \left\{(i_0,o_0),\hdots,(i_{h-1},o_{h-1}),(i_h,o_h)\right\}, \\
m_{io} + \delta, &\text{if}~(i,o) \in \left\{(i_0,o_1),\hdots,(i_{h-1},o_h),(i_h,o_0)\right\}, \\
m_{io}, &\text{otherwise}, 
\end{cases}
$$
is a feasible allocation that $e$-dominates $m$. The following result, which is essentially due to \cite{cd16}, is proved in Appendix \ref{app:Cyclic}.

\begin{lem}\label{lem:cyclic} 
Let $e \in \{sd,dl,ul\}$.  An allocation $m$ is $e$-efficient if and only if $m$ is not wasteful and $\rhd_m$ is acyclic. In particular,  $sd$-efficiency, $dl$-efficiency, and $ul$-efficiency are equivalent. 
\end{lem}

\begin{proof}[Proof of Theorem \ref{thm:axiom_topdown}]
Let $m$ be the allocation produced by the GCPS mechanism, applied to $E$ and $\succ$.  We will show that $m$ is not wasteful and $\lhd_m$ is acyclic.  Suppose $t^*$ is the first time such that $E(t^*)$ is not simple, and $E_0 = E_{(I_0,O_0)}, E_1 = E_{(I_1,O_1)}, \ldots, E_0 = E_{(I_k,O_k)}$ is the simple decomposition of the tightening of $E(t^*)$. 

Consider an agent $i$ and a pair $o,o'$ of objects such that $o \succ_i o'$, $m_{io} < g_{io}$, and $\sum_j m_{jo} < q_o$.  So long as $o$ is available to $i$, $i$ will not consume $o'$, so $i$ does not consume any $o'$ prior to $t^*$.   Since $E_1, \ldots, E_k$ are critical and $m$ does not consume all of $q_o$, $o \in O_0$, and since $\sum_o m_{io} < \sum_o g_{io}$, $i \in I_0$.  Therefore $o$ continues to be available to $i$ in $E_0$ after time $t^*$.  By recursion we conclude that $m_{io'} = 0$.  Thus $m$ is not wasteful.

Suppose there is a cycle $o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0$.  For each $l$ let $i_l$ be an agent such that  $m_{i_lo_l} > 0$, $o_{l+1} \succ_{i_l} o_l$, and $m_{i_lo_{l+1}} < g_{i_lo_{l+1}}$, and 
for sufficiently small $\delta > 0$ let $m(\delta)$ be the allocation defined above.  

If there is a time $t_0 < t^*$ at which $i_0$ is consuming $o_0$, at $t_0$ the quota of $o_1$ must have been exhausted, so the first time $t_1$ such that $i_1$ is consuming $o_1$ must be before $t_0$. At $t_1$ the quota of $o_2$ must have been exhausted, so the first time $t_2$ such that $i_2$ is consuming $o_2$ must be before $t_1$. Continuing this argument gives $t_0 < t_1 < \cdots < t_h < t_0$, which is impossible.  (This argument appeared already in BM.)

If, for each $l = 1, \ldots, h$, $i_l$ is not consuming $o_l$ prior to $t^*$, and $\delta < \min \{m_{i_1o_1},\ldots,m_{i_ho_h}\}$, then $m - p(t^*)$ and $m(\delta) - p(t^*)$ are feasible allocations for $E(t^*)$.  Since $E_1, \ldots, E_k$ are critical, the only way that this can happen is if there is some $l$ such that $i_0, \ldots, i_h \in I_l$ and $o_1, \ldots, o_h \in O_l$, but then the same argument can be applied to  the restriction of $m - p(t^*)$ to $E_l$ , so the claim follows from recursive descent.
\end{proof}

\section{Implementability} \label{sec:Implementability}

Let $E$ be a CEE, and let $Q$ be the set of feasible allocations.  Since $Q$ is a bounded set defined by the finite system of equations and inequalities, it is a polytope.  Consequently it is the set of convex combination of its vertices.  The next result implies that when the allocations are assignments of probability, any element of $Q$ is \emph{implementable} in the sense that it can be realized as a lottery of pure assignments.  

\begin{thm} \label{th:Implementability}
  If $E$ is integral, then each vertex of $Q$ is integral.
\end{thm}

The Birkhoff-von Neumann theorem asserts that if $|I| = |O|$, then the set of bistochastic matrices with entries indexed by $I \times O$ is the convex hull of the set of bistochastic matrices with entries in $\{0,1\}$.   Evidently the Birkhoff-von Neumann theorem is a special case of Theorem \ref{th:Implementability}. 

We quickly review the related concepts and results of \cite{bckm13aer}.   A \emph{constraint set} is a nonempty subset of $I \times O$, and a \emph{constraint structure} $\cH$ is a set of constraint sets.  A vector of quotas $\bq = (q_S,q^S)_{S \in \cH}$ is \emph{integral} if $q_S,q^S \in \In$ for all $S$.
An allocation $m$ is feasible under $\bq$ if $q_S \le \sum_{_{io} \in S} m_{io} \le q^S$ for all $S \in \cH$.  Let $\cM_\bq$ be the set of feasible allocations for $\bq$. If $\cH$ contains all singletons, then $\cM_\bq$ is bounded, hence a polytope. The constraint structure $\cH$ is \emph{universally implementable} if, whenever $\bq$ is integral, each vertex of $\cM_\bq$ is integral.  A constraint structure is a \emph{hierarchy} if, for all $S, S' \in \cH$, we have $S \subset S'$ or $S' \subset S$ or $S \cap S' = \emptyset$, and $\cH$ is a \emph{bihierarchy} if there are hierarchies $\cH_1$ and $\cH_2$ such that $\cH_1 \cup \cH_2 = \cH$ and $\cH_1 \cap \cH_2 = \emptyset$.  Theorem 1 of \cite{bckm13aer} asserts that if $\cH$ is a bihierarchy, then it is universally implementable.  (Their Theorem 2 is a partial converse, giving conditions under which if $\cH$ is universally implementable, then it is a bihierarchy.)  To apply this to our problem we simply let $\cH_1 = \{\, \{i\} \times O : i \in I \,\} \cup \{\, \{(i,o)\} : (i,o) \in I \times O \,\}$ and $\cH_2 = \{\, I \times \{o\} : o \in O \,\}$.  Thus Theorem \ref{th:Implementability} follows from Theorem 1 of \cite{bckm13aer}. 

The practical implementation of a random allocation depends not only on the existence of a representation of it as a convex combination of pure allocations, but also on a practical algorithm for generating a random pure allocation with a probability distribution that averages to the given allocation.  The following result provides such a computational process, and in addition has Theorem \ref{th:Implementability} as an immediate consequence.  If $m \in Q$, the \emph{degree of integrality} of $m$ is
$$|\{\, i : \sum_o m_{io} \in \In \,\}| + |\{\, o : \sum_i m_{io} \in \In \,\}| + |\{\, (i,o) : m_{io} \in \In \,\}|.$$
We recall that the \emph{floor} of a real number $t$ is greatest integer $n$ such that $n \le t$, and the  \emph{ceiling} of $t$ is least integer $n$ such that $t \le n$.  Note that when $t$ is an integer, it is both the floor and ceiling of itself.

\begin{thm} \label{th:ConvexComb}
  If $E$ is integral, $m \in Q$, and the degree of integrality of $m$ is less than $|I| + |O| + |I| \cdot |O|$, then there is a polynomial time algorithm that computes $m^0, m^1 \in Q$ such that $m$ is a convex combination of $m^0$ and $m^1$ and for both $h = 0,1$:
  \begin{enumerate}
     \item[(a)] The degree of integrality of $m^h$ is greater than the degree of integrality of $m$.
     \item[(b)] For each $i$, $\sum_o m^h_{io}$ is between the floor and the ceiling of $\sum_o m_{io}$.
     \item[(c)] For each $o$, $\sum_i m^h_{io}$ is between the floor and the ceiling of $\sum_i m_{io}$.
     \item[(d)] For each $i$ and $o$, $m^h_{io}$ is between the floor and the ceiling of $m_{io}$.
  \end{enumerate}
\end{thm}

Appendix \ref{app:Implementability} presents a proof of Theorem \ref{th:ConvexComb} that is a simplified (in the sense of being specific to our less general setting) version of the proof in Appendix B of the Online Appendices of \cite{bckm13aer}, which they attribute to Tomomi Matsui and Akihisa Tamura.

Theorem \ref{th:ConvexComb} describes one step in the overall process of generating a random pure allocation.  Since this step increases the degree of integrality, the number of such steps is bounded by $|I| + |O| + |I| \cdot |O|$, so the overall process is also polynomial time.  We should note that our analysis does not rule out the possibility that the support of the distribution of the random allocation may have as many as $2^s$ elements, where $s$ is the number of steps, so this process does not amount to a polynomial time algorithm for producing a vector of probabilities over the set of vertices of $Q$ that averages to the given allocation.  Caratheodory's theorem states that if $x \in \Re^n$ is an element of the convex hull of $S$, then it a convex combination of a subset of $S$ with at most $n+1$ elements.  If a representation of $m$ as a convex combination of at most $|I||O| + 1$ elements is required, it can be obtained by using linear algebra, at each step, to reduce from a support with as many as $|I||O| + 2$ elements to a support with at most $|I||O| + 1$ elements.  

\section{Strategy Proofness} \label{sec:StrategyProof}

BM show that the PS mechanism is \emph{weakly strategy proof}: reporting a false preference cannot give an agent an outcome that strictly stochastically dominates the outcome resulting from reporting her true preference.  \cite{kojima09mss} shows that this result does not extend to the allocation of $r \ge 2$ objects.  We begin by reviewing the example that is used to demonstrate this.  Let there by two agents $1$ and $2$ and four objects $a$, $b$, $c$, and $d$, so $r = 2$.  Let the true preferences be $a \succ_1 b \succ_1 c \succ_1 d$ and $b \succ_2 c \succ_2 a \succ_2 d$.  If the agents report these preferences, then the PS mechanism gives $(1,0,\tfrac12,\tfrac12)$ to agent 1 and $(0,1,\tfrac12,\tfrac12)$ to agent 2.  On the other hand, if agent 1 reports $\succ_1'$, where $b \succ_1' a \succ_1' c \succ_1' d$, and agent 2 reports $\succ_2$, then  the PS mechanism gives $(1,\tfrac12,0,\tfrac12)$ to agent 1 and $(0,\tfrac12,1,\tfrac12)$ to agent 2.

The key feature driving this example is that, because agent 1 is limited to a single unit of $a$, deferring the consumption of this object does not reduce the total amount that can be consumed.  A \emph{uniform unrestricted CEE} is a tuple $E = (I,O,r,q)$ in which $I$ and $O$ are finite sets of agents and objects, $r \ge 0$, $q \in \Re_+^O$, and $q_o \ge r$ for all $o$.  This is interpreted as a CEE in which $r$ is the common requirement of all agents and the numbers $g_{io}$ are large enough (e.g., $g_{io} = r$) that they impose no restrictions.  Under this interpretation a uniform unrestricted CEE satisfies the GMC if and only if $\sum_i r_i \le \sum_o q_o$.

\begin{thm}  \label{th:WeakStrategyProof}
  If $E$ is an uniform unrestricted CEE that satisfies the GMC, then the GCPS mechanism for $E$ is weakly strategy proof.
\end{thm}

\noindent
This is rather slight generalization of Proposition 1 of BM, but our proof in  Appendix \ref{app:WeakStrategyProof} actually establishes a more powerful result of some independent interest, namely that no eating strategy for an agent (including those not derived from alternative preferences) yields an outcome that stochastically dominates the GCPS outcome.  
In more detail, any eating strategy gives strictly less of the favorite object unless it eats only the favorite object until that object is no longer available, after which the same argument shows that  any continuation of that eating strategy gives strictly less of the second favorite object unless it eats only that object until it is no longer available, and so forth.

We briefly describe methods for constructing examples showing that the assumptions of Theorem \ref{th:WeakStrategyProof} are not easily relaxed.  Fix an agent $i$, and suppose that $a$ and $b$ are her favorite and second favorite object.  Consider a CEE $E$ with $q_o \ge r_j$ and $g_{jo} \ge r_j$ for all $j$ and $o$.  If $a$ is also the favorite of some $j$, other agents do not eat $a$, $r_i = 4$, $r_j = 3$, and $q_a = 6$, then $i$ may successfully manipulate by reporting that $b$ is her favorite and $a$ is her second favorite if doing so would result in $b$ being fully allocated exactly at time $1$, because she will eat 3 units of $a$ so long as she starts eating at some time between 0 and 1.  Now consider a CEE $E$ with $r_j = r$ for all $j$ and $r_j \le q_o$ and $g_{jo} \in \{0,r_j\}$ for all $j$ and $o$.  Suppose that $i \in J \subset I$ and $a \in P \subset O$, that agents in $J$ eat only objects in $P$, that no agent in $J$ other than $i$ ever eats $a$, and that agents in $I^c$ eat only objects in $P^c$, with one exception, namely that there is a $j \in I^c$ whose favorite is also $a$ who will eat a fixed amount that is greater than $q_a - r_i$ and less than $r_i/2$, and that results in the pair $(J,P)$ becoming critical, which prevents $j$ from consuming more.  Again, the amount of $a$ that $i$ can eat is unaffected by when $i$ eats $a$, which creates the possibility of manipulation.

The CEE's of Theorem \ref{th:WeakStrategyProof} are less general than school choice CEE's insofar as school choice allows the possibility that $g_{io} = 0$ because $i$ is not eligible for $o$, rather than because $i$ prefers her safe school to $o$.  Beyond this observation, it is difficult to quantify the extent to which the GCPS mechanism for school choice might fail to be weakly strategy proof.

BM give concrete examples showing that the probabilistic serial rule is not strategy proof: it can happen that reporting a false preference gives a higher expected utility. To illustrate this phenomenon, suppose that $o$ and $p$ are the agent's first and second favorite object, and there are $A-1$ other people who have $o$ as their favorite and $B - 1$ other people who have $p$ as their favorite, where  $1 < A < B$.  Further, assume that no one outside the set of agents  who have $o$ as their favorite will ever consume any $o$ and no one outside the set of agents  who have $p$ as their favorite will ever consume any $p$.  If the agent reports the truth she will receive share $\tfrac{1}{A}$ of $o$ and none of $p$.  If she reports that $p$ is her favorite and $o$ is her second favorite, then she will receive $\frac{1}{B}$ of $p$ and $\tfrac{1}{A}(1 - \tfrac{A-1}{B})$ of $o$, and her total consumption of $o$ and $p$ will be $\tfrac{1}{A}(1 + \tfrac{1}{B})$.  This can be an improvement if the utility difference between $o$ and the agent's third favorite object is more than $A$ times the difference between  the utility of $o$ and the utility of $p$.

This example suggests that, in general, the benefit of manipulatively consuming an inferior object (to change the later availability schedule of other objects) will be small in comparison with the amount of manipulation if there are many people competing for the object that you would be eating if you reported honestly. In the special case of our model in which $E$ is integral and $g_{io} = r_i$ (in effect) for all $i$ and $o$,  \cite{km10jet} establish an exact result along these lines: for a given utility function $u_i$ consistent with a preference $\succ_i$, if $\min_o q_o/r_i$ is sufficiently large, then agent $i$ will not be able to increase the expected utility from the probabilistic serial mechanism by reporting a different preference $\succ_i'$.   \cite{ab19res} develop a closely related concept of approximate strategy proofness when each individual has a small influence on price-like variables.

We now extend the Kojima-Manea result to the school choice setting.  For the remainder of this section  and throughout Appendix \ref{app:StrategyProof} we assume that the given CEE $E = (I,O,r,q,g)$ which is a school choice problem, so $r_i = 1$ for all $i$ and $g_{io} \in \{0,1\}$ for all $i$ and $o$. We refer to elements of $I$ as students and elements of $O$ as schools. For $i \in I$ let $\alpha_i = \{\, o : g_{io} = 1 \,\}$ be the set of schools that $i$ can attend.  For $P \subset O$ let $J_P = \{\, i : \alpha_i \subset P \,\}$ be the set of students who must attend some school in $P$.  If $i \in I \setminus J_P$ and $g_{io} = 1$ for some $o \in O \setminus P$, then $i$ contributes at least as much to the right hand side of any GMC inequality for $P$ as to the left hand side.  Therefore every minimal critical pair has the form $(J_P,P)$, both initially and at each point during the allocation process, and we say that $P \subset O$ is \emph{critical} if $(J_P,P)$ is a critical pair.  For $P \subset O$ let $$s_P = \sum_{o \in P} q_o - |J_P|$$ be the number of students outside of $J_P$ that the schools in $P$ can accommodate.  The pair $(J_P,P)$ becomes critical during the allocation process when $s_P$ (units of probabilities of) seats have been allocated to members of $I \setminus J_P$.

The proof of the next result has two phases.  In the first it is shown that the effect of the manipulation by a student $i$ on the overall allocation is bounded by the amount that $i$'s own consumption differs between the eating schedule induced by the true preference and eating schedule induced by the reported preference.  

The second phase bounds the benefits of the periods of time during which the student can eat from a school that would not be available if the student reported her true preference.  The additional amount of the school that the student consumes during such a period is the amount that is available at the beginning of the period divided by the number of students eating from this school.  In the Kojima-Manea setting the set of agents eating an object type is weakly increasing while the object type is available, so having a large number of objects of each type implies that if an object type is fully consumed, then the final rate of consumption is high.  In our setting the number of agents eating from a school can decrease when pairs become critical, so we need an additional assumption to insure that the number of agents competing for each school is high.
For $o \in O$ let $J_o = \{\, i : \alpha_i = \{o\} \,\}$ be the set of students who must receive a seat in $o$.  In the following result we assume that these sets are large.  This particular assumption can easily fail to hold, but this does not undermine the larger point, which is that although manipulation is a theoretical possibility, in the school choice setting profitable manipulation is very unlikely, and very difficult to foresee.

\begin{thm} \label{thm:StrategyProof}
Let $N_0 > 0$ be a number such that $N_0 \le |J_o|$ for all $o \in O$.  Let $\succ$ be a preference profile, let $\succ_i'$ be an alternative preferences for some $i \in I$,  and let $\succ' = (\succ_i',\succ_{I \setminus \{i\}})$.  Let $u_i \colon A \to \Re$ be a cardinal utility function consistent with $\succ_i$, and let $d_i = \min_{o \, \succ_i \, p} u_i(o) - u_i(p)$ and $D_i = \max_{o \, \succ_i \, p} u_i(o) - u_i(p)$.  If $E$ satisfies the GMC and
$$\big(1 + \frac{d_i}{D_i}\big)^{1/|O|} \ge  \frac{N_0 + 2}{N_0 + 1},$$ then $u_i(GCPS(\succ)) \ge u_i(GCPS(\succ'))$.
\end{thm}
 
This result opens up an interesting possibility.  Suppose that, pursuing a suggestion of \cite{as03aer}, for affirmative action purposes a school has been divided into three parts, one with 30\% of the seats that is reserved for minority students, one with 30\% of the seats that is reserved for majority students, and one with 40\% of the seats that accepts all students.   After the procedure has been run the results may be disappointing if, for example, one of the three schools is severely underenrolled.  Alternatively, it may happen that an elite school is either underenrolled or has admitted many less qualified students while students with superb test scores failed to get in, due to the luck of the draw.  In both of these cases one might wish to rerun the process with adjusted parameters, changing the seat assignments of the three schools or the test score cutoff of the elite school.  

In their most basic forms school choice mechanisms based on bilateral matching mechanisms require that the schools have priorities that are strict preference orderings of the students.  These may refine legally mandated priorities, but in some cases the additional preferences of the schools do not represent actual social desiderata, and may interfere with efficiency.  But it is also possible that it is socially desirable that the preferences of the highest priority students are given greatest consideration.  In the matching resulting from deferred acceptance each school has a priority cutoff such that the proposals of students with higher priority are certainly accepted and those with lower priority are certainly rejected.  To approximate this with the GCPS mechanism one may run it repeatedly, gradually increasing the priority cutoffs of schools that are overdemanded (as manifested by many students receiving assignment probabilities far below one) until there is approximate balance of supply and demand at each school.

In many mechanism design contexts running a mechanism repeatedly with adjusted parameters would be regarded as cheating, since the putative mechanism (a single run of the GCPS mechanism) has been replaced by a much more complicated iterative process.  However, from the the point of view of the final run it is still best to report one's true preference, so the only way that misreporting might possibly be beneficial is if the manipulator managed to maneuver the iterative adjustment process to a different endpoint, and of course it is implausible that anyone could be that foresightful.  Thus it seems to reasonable to regard the procedure as strategy proof even if there are the sorts of ex post adjustments we have described.

\section{Envy-Freeness} \label{sec:EnvyFreeness}

We now consider fairness properties of the GCPS mechanism applied to a CEE $E$ and a profile of preferences $\succ$.  It is obvious from the definition that the mechanism satisfies  anonymity (the outcomes do not depend on the ordering of the agents, or their ``names") and equal treatment of equals (the GCPS gives the same allocations to $i$ and $j$ if $r_i = r_j$, $g_i = g_j$, and $\succ_i \; = \; \succ_j$).

The other fairness property considered by BM is envy-freeness.  They show that the PS mechanism is envy-free in the strong sense that if $m_i$ and $m_j$ are the allocations of the PS mechanism for $\succ$, then $m_i \, sd(\succ_i) \, m_j$.  In our more general context there is no reason to expect this unless $r_i = r_j$ and $g_i = g_j$.  Agent $j$ may receive an allocation that $i$ envies if $g_j$ allows $j$ to consume things that are forbidden for $i$, or because the only feasible consumption for $j$ is desirable for $i$.

\begin{prop}
  If $r_i = r_j$ and $g_i = g_j$, then $$GCPS_i(E,\succ) \, sd(\succ_i) \, GCPS_j(E,\succ).$$
\end{prop}

\begin{proof}
  Let $m_i = GCPS_i(E,\succ)$ and $m_i = GCPS_j(E,\succ)$.  We index the elements of $O$ so that $o_1 \succ_i o_2 \succ_i \cdots$.  The claim is that $\sum_{h = 1}^k m_{io_i} \ge \sum_{h = 1}^k m_{jo_i}$ for all $k$.  Aiming at a contradiction, suppose that $k$ is the smallest integer such that this is false.  Let $t = \sum_{h = 1}^k m_{io_i}$.  Supposedly at time $t$ it is no longer possible for $i$ to eat any of $o_1, \ldots, o_k$ because there are no feasible allocations $m'$ with $p(t) \le m'$ and $m'_{io_h} > m_{io_h}$ for some $h = 1, \ldots, k$.  Choose an $h = 1, \ldots, k$ such that $m_{jo_h} > m_{io_h}$, and choose $g = k+1, k+2, \ldots$ such that $m_{jo_g} < m_{io_g}$.   For sufficiently small $\delta > 0$ the allocation defined by setting $m'_{io_h} = m_{io_h} + \delta$, $m'_{jo_h} = m_{jo_h} - \delta$, $m'_{io_g} = m_{io_g} - \delta$, $m'_{jo_g} = m_{jo_g} + \delta$, and $m'_{i'o'} = m_{i'o'}$ for all other $(i',o')$ is feasible, which contradicts our supposition.
\end{proof}

In the school choice context a stronger notion of envy-freeness is relevant, because the matrix $g$ is, in part, a reflection of the students' preferences.  The proper comparison is between two students, one of whom has all the opportunities that the second has.  If $E$ is a school problem, then $$GCPS_i(E,\succ) \, sd(\succ_i) \, GCPS_j(E,\succ)$$ for all $i,j \in I$ such that for all $o_i \in \{\, o \in O : g_{io} = 1 \,\}$ and $o_j \in \{\, o \in O : g_{jo} = 1 \,\}$, either $g_{io_j} = 1$ or $o_i \succ_i o_j$.  With obvious modifications, the argument above can be used to prove this.

\section{Concluding Remarks} \label{sec:Conclusion}

We have provided a school choice mechanism that is a specialization of the GCPS mechanism of \cite{balbuzanov22jet}, which is in turn a generalization of the PS mechanism of BM.  This mechanism guarantees each student a seat in a school that is at least as desirable as any of the schools she is legally entitled to attend.  When there are many students for each school, it is effectively strategy proof.  It is $sd$-efficient, which (as BM stress) is a stronger condition than ex post efficiency.  In contrast, bilateral matching mechanisms based on randomly generated priorities for the schools are (at least in their most basic forms) not even ex post efficient.  A result of \cite{bckm13aer} implies that it is implementable: the assignment probabilities it generates can be obtained from a randomization over pure assignments.  It satisfies anonymity, equal treatment of equals, and a natural generalization of the envy-freeness condition satisfied by the PS mechanism.
Using a novel generalization of Hall's marriage theorem, we have described a computational implementation of this mechanism that is tractable even for very large school choice problems.  

Although we have emphasized the school choice application, the underlying idea of our procedure, the application of the GCPS mechanism to CEE, is potentially of interest in many other domains, with many variations.  A possibility stressed by BM, \cite{cho18scw}, and \cite{balbuzanov22jet} (perhaps among others) is that the mechanism can be varied by making the eating speeds depend on various things.  This seems unmotivated in school choice, but in other domains it may be quite interesting.

A possibility we intend to explore in subsequent research is that instead of consuming probability of desirable objects, the agents may discard probability of undesirable objects.  In the case of $n$ agents and $n$ objects, each agent is endowed with one unit of each object, and at each time during the interval $[0,n-1]$ she discards probability of the least desirable object that she has not fully discarded for which discarding is still allowed.  Discarding of an object is disallowed when the agents' total remaining endowment of it is one, but it may also be disallowed for some agents in the event that the process reaches a facet of $R$.  The characterization of the PS mechanism given by \cite{bh12} implies that the discarding mechanism is certainly different, but otherwise its properties await investigation.  It seems appropriate for problems, perhaps such as chore assignment, in which the agents' main concern is to avoid the objects that are most noxious for them.  Some agents may be unqualified to receive certain objects, and one may recognize this by taking away their endowments of such objects at the outset, but this seems unfair insofar it amounts to giving them a head start.  Giving such agents slower discarding speeds is one way this issue could be addressed.


\begin{appendix}

\section{Proof of Lemma \ref{lem:cyclic}} \label{app:Cyclic}

 The argument below simply adapts the proof of Theorem 1 of \cite{cd16} to our setting.
 
Suppose that $m$ is wasteful, so there is an agent $i$ and a pair $o,o'$ of objects such that $o \succ_i o'$, $m_{io} < g_{io}$, $m_{io'} > 0$, and $\sum_j m_{jo} < q_o$. For sufficiently small $\delta > 0$, setting $m'_{io} = m_{io}+\delta$,  $m'_{io'} = m_{io'} - \delta$, and $m'_{jp} = m_{jp}$ for all other $(j,p)$ gives an allocation $m'$ such that $m'_i$ $e$-dominates $m_i$ for any $e \in \{sd,dl,ul\}$, $m_i' \ne m_i$, and $m'_j = m_j$ for all $j \ne i$, so $m'$ $e$-dominates $m$. 

Suppose that there is a cycle $o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0$.
If $i_0, \ldots, i_k$ and $m(\delta)$ are as above, then, for sufficiently small $\delta >0$, $m(\delta)$ is an allocation, $m_i(\delta)$ $e$-dominates $m_i$  for each $i = 0, \ldots, k$ and $e \in \{sd,dl,ul\}$, and $m'_j = m_j$ for all other $j$, so $m'$ $e$-dominates $m$.

Now suppose that allocation $m$ is not wasteful and is $e$-dominated by the allocation $m'$.   Fix an agent $i_0$ such that $m'_{i_0} \ne m_{i_0}$. 
There are two cases, depending on whether $e = dl$ or $e = ul$.  (Either argument can handle the case $e = sd$.)

First suppose that $e = dl$.  Since $m_i'$ $ul$-dominates $m_i$ there are objects $o_0$ and $o_1$  such that $o_1 \succ_{i_1} o_0$, $m'_{i_0o_0} < m_{i_0o_0}$, and $m'_{i_0o_1} > m_{i_0o_1}$.  These conditions imply that $m_{i_0o_0} > 0$ and $m_{i_0o_1} < g_{i_0o_1}$, so $o_0 \lhd_m o_1$. 
If $m'_{jo_1} \ge m_{jo_1}$ for all $j \ne i_0$, then $\sum_j m_{jo_1} < \sum_j m'_{jo_1} \le q_{o_1}$ and $m_{i_0o_0} > 0$, contradicting nonwastefulness of $m$.  Therefore there is some $i_1 \ne i_0$ such that $m'_{i_1o_1} < m_{i_1o_1}$.  Since $m'_{i_1}$ $dl$-dominates $m_{i_1}$, there is some $o_2$ such that $o_2 \succ_{i_1} o_1$ and $m'_{i_1o_2} > m_{i_1o_2}$.  We have $m_{i_1o_1} > 0$ and $m_{i_1o_2} < g_{i_1o_2}$, so $o_1 \lhd o_2$.
Since $O$ is finite, repeating this argument leads eventually to a cycle $o_0 \lhd_m o_1 \lhd_m \cdots \lhd_m o_h \lhd_m o_0$.

Now suppose that $e = ul$. Since $m_i'$ $dl$-dominates $m_i$ there are objects $o_0$ and $o_1$  such that $o_0 \succ_{i_1} o_1$, $m'_{i_0o_0} > m_{i_0o_0}$, and $m'_{i_0o_1} < m_{i_0o_1}$, so that $m_{i_0o_1} > 0$ and $o_1 \lhd o_0$. 

Aiming at a contradiction, suppose that $m_{jo_1} \ge m'_{jo_1}$ for all $j \ne i_0$, so that $q_{o_1} \ge \sum_j m_{jo_1} > \sum_j m'_{jo_1}$.  Since $\sum_{j,p} m_{jp} = \sum_{j,p} m'_{jp} = \sum_j r_j$, there is a $p_1$ such that $\sum_j m_{jp_1} < \sum_j m'_{jp_1}$ and a $j_1$ such that $m_{j_1p_1} < m'_{j_1p_1}$. Since $m'_{j_1} \ne m_{j_1}$ and $m'_{j_1}$ $ul$-dominates $m_{j_1}$, there is a $p_2$ such that $p_1 \succ_{j_1} p_2$ and $m_{j_1,p_2} > m'_{j_1,p_2}$.  
In particular, $m_{j_1,p_2} > 0$.  Together with $q_{p_1} \ge \sum_j m'_{jp_1} > \sum_j m_{jp_1}$, this contradicts the assumption that $m$ is not wasteful.

Therefore there is some $i_1 \ne i_0$ such that $m_{i_1o_1} < m'_{i_1o_1}$.  Since $m'_{i_1} \ne m_{i_1}$ and $m'_{i_1}$ $ul$-dominates $m_{i_1}$ there is some $o_2$ such that $o_1 \succ_{i_1} o_2$ and $m_{i_1o_2} > m'_{i_1o_2}$.  In particular, $m_{i_1o_2} > 0$, so $o_2 \lhd o_1$.  
Since $O$ is finite, repeating this argument leads eventually to a cycle $o_0 \lhd_m o_h \lhd_m \cdots \lhd_m o_1 \lhd_m o_0$.


\section{Proof of Theorem \ref{th:ConvexComb}} \label{app:Implementability}

The argument below uses the network $(N,A)$ introduced in Section \ref{sec:GenHall}.

We now assume that $E$ is integral, and that $m$ is a feasible allocation that is not integral.  
  Since $m$ is not integral we can find $\ta_1 = (\tn_1,\tn_2) \in A$ such that $f(\ta_1) \notin \In$.  
  Assume that for some $\kappa \ge 2$ we have already found distinct $\tn_1, \ldots, \tn_\kappa \in N$ and $\ta_1, \ldots, \ta_{\kappa-1} \in A$ such that  for each $\eta = 1, \ldots, \kappa-1$, $f_m(\ta_\eta) \notin \In$ and either $\ta_\eta = (\tn_\eta,\tn_{\eta-1})$  or $\ta_\eta = (\tn_{\eta-1},\tn_\eta)$.  
  There is a $\tn_{\kappa+1} \ne \tn_{\kappa-1}$ such that either $(\tn_\kappa,\tn_{\kappa+1}) \in A$ or $(\tn_{\kappa+1},\tn_\kappa) \in A$ and $f_m(\tn_\kappa,\tn_{\kappa+1}) = - f_m(\tn_{\kappa+1},\tn_\kappa) \notin \In$.  
  (The detailed proof of this has various cases, according to (among other things) whether the total flow into and out of $\tn_\kappa$ is an integer, and it depends on the fact that the total flow out of $s$ and the total flow into $t$ are both $\sum_i r_i$, which is an integer.  The reasoning in the various cases is similar, and obvious in any particular instance, so we leave the details to the reader.) Let $\ta_k$ be whichever of $(\tn_k,\tn_{k+1})$ and $(\tn_{k+1},\tn_k)$ is in $A$.  If $\tn_1, \ldots, \tn_{\kappa + 1}$ are distinct we can repeat this construction.  Since $N$ is finite, we must eventually arrive at a $\kappa$ such that $\tn_\kappa = \tn_\rho$ for some $\rho = 1, \ldots, \kappa - 3$.  We then set $k = \kappa - \rho + 1$, $n_1 = \tn_\rho, \ldots, n_k = \tn_\kappa$, and $a_1 = \ta_\rho, \ldots, a_{k-1} = \ta_{\kappa - 1}$.  Evidently $n_1, \ldots, n_{k-1}$ are distinct, $n_k = n_1$, and for each $h = 1, \ldots, k-1$, $f_m(a_h) \notin \In$ and either $a_h = (n_{h-1},n_h)$ (in which case we say that $a_h$ is \emph{odd}) or $a_h = (n_h,n_{h-1})$ (in which case we say that $a_h$ is \emph{even}).

  For $\gamma \in \Re$ let $f^\gamma \colon A \to \Re$ be the function:
  $$f^\gamma(a) =
  \begin{cases}
    f_m(a) + \gamma, & \text{$a \in \{a_1, \ldots, a_{k-1}\}$ is odd}, \\
    f_m(a) - \gamma, & \text{$a \in \{a_1, \ldots, a_{k-1}\}$ is even}, \\
    f_m(a), & a \notin \{a_1, \ldots, a_{k-1}\}.
  \end{cases}$$
  If $f^\gamma$ is nonnegative valued, then it is a flow: again there are various cases, but in each it is easy to see that for each $n_h$ the total inflow and the total outflow are the same. Let $\alpha$ and $\beta$ be the smallest positive numbers such that $f^\alpha(a_s) \in \In$ for some $s = 1, \ldots, t-1$ and $f^{-\beta}(a_{s'}) \in \In$ for some $s' = 1, \ldots, t-1$, and let $f_0 = f^\alpha$ and $f_1 = f^{-\beta}$.  Clearly $f_0$ and $f_1$ take nonnegative values.    Define $m^0$ and $m^1$ be setting $m^0_{io} = f_0(a_{io})$ and $m^1_{io} = f_1(a_{io})$, so that  $m = \tfrac{\beta}{\alpha + \beta}m^0 + \tfrac{\alpha}{\alpha + \beta}m^1$.  For each $a$, $f_0(a)$ and $f_1(a)$ lie between the floor and ceiling of $f_m(a)$, so (b)--(d) of the assertion hold, and
  $m^0$ and $m^1$ are feasible allocations because $m$ is feasible and $E$ is integral.  The fact that $f_0$ and $f_1$ have fewer nonintegral values than $f_m$ implies that the degrees of integrality of $m^0$ and $m^1$ are greater than the degree of integrality of $m$.  Finally, it is obvious that all of the constructive elements of this argument can be implemented by polynomial time algorithms.


\section{Proof of Theorem \ref{th:WeakStrategyProof}} \label{app:WeakStrategyProof}

Let $E = (I,O,r,q)$ be a uniform unrestricted eligibility CEE.  We assume that $E$ satisfies the GMC: $r|I| \le \sum_o q_0$.  As we stated in Section \ref{sec:StrategyProof}, we wish to prove something stronger than Theorem \ref{th:WeakStrategyProof}, namely that there is no eating strategy for an agent that results in an allocation that strictly stochastically dominates the GCPS allocation.  We now fix an agent $i$.  We need to explain the consequences of $i$ following a particular eating function.

We imagine that the process begins at time $0$, and we specify how it continues until the time $r$ when all agents have fulfilled their requirement.  We assume that agent $i$'s behavior is described by an eating function $e_i \colon [0,r] \to O$ that is piecewise constant, and that is \emph{feasible} in the sense that process described below is well defined.
For each $t \in [0,r]$ there are the following objects:
\begin{enumerate}
  \item[(a)] $p^{e_i}(t)$ is a partial allocation.
  \item[(b)] $\alpha^{e_i}(t) = \{\, o : q^{e_i}_o(t) > 0 \,\}$ is the set of available objects.
  \item[(c)] For each $j \ne i$, $e^{e_i}_j(t)$ is the $\succ_j$-best element of $\alpha^{e_i}(t)$.
  \item[(d)] $e^{e_i}_i(t) = e_i(t) \in \alpha^{e_i}_i(t)$.
\end{enumerate}
We assume that $p^{e_i}(0) = 0$.  We require that $q^{e_i}(t)$ and $p^{e_i}(t)$ are continuous and piecewise linear functions of $t$, and that when their derivatives  $\dq^{e_i}(t)$ and $\ddp^{e_i}(t)$ with respect to time  are defined, for all $j$ they satisfy:
\begin{enumerate}
  \item[(a)] $\dq^{e_i}_o(t) = -|\{\, j : e^{e_i}_j(t) = o \,\}|$.
  \item[(b)] $\ddp^{e_i}_{jo}(t) = 1$ if $e^{e_i}_j(t) = o$, and otherwise $\ddp^{e_i}_{jo}(t) = 0$.
\end{enumerate}
The allocation for $e_i$ is $p^{e_i}(r)$.

Let $\cE_i$ be the set of eating functions for $i$ that change objects at most $|O|^2$ times.   This is a compact set with respect to the metric $d(e_i,e_i') = \int_{t = 0}^{r_i} 1 - \delta_{e_i(t),e_i'(t)} \, dt$ (Kronecker $\delta$) and the set of feasible elements is a closed subset.  We say that two feasible eating functions are \emph{equivalent} if they have the same consumption of each object during any interval between two times at which objects are exhausted, in which case the two functions give the same allocation to $i$.  Clearly any feasible eating schedule is equivalent to an element of $\cE_i$.  
Let $a$ be $i$'s favorite element of $\{\, o : g_{io} = r_i \,\}$.  It is easy to see that the map from feasible elements of $\cE_i$ to $i$'s allocation of $a$ is continuous.  Therefore there is a feasible $e_i \in \cE_i$ that maximizes the overall allocation of $a$ for $i$.

Let $t_1$ be the time at which $a$ becomes unavailable to $i$ under $e_i$, either because $t_1 = r$ or $q_a^{e_i}(t_1) = 0$, so $q_a^{e_i}(t) > 0$ for all $t < t_1$.  Aiming at a contradiction, suppose that there are  times prior to $t_1$ at which $i$ eats something other than $a$, and let $t_0$ be the least upper bound of the set of such times.  Since $e_i$ switches objects finitely many times, optimality implies that $t_0 < t_1$.  Let $\delta > 0$ be the largest number such that $i$ does not eat $a$ during the interval $(t_0 - \delta,t_0)$.
Let $e_i'$ be an eating function that agrees with $e_i$ on $[0,t_0 - \delta]$ and eats only $a$ from $t_0 - \delta$ until the time $t_1'$ when it ceases to be available because  $q_a^{e_i'}(t_1') = 0$.  We have $t_1 - t_1' - \delta \ge 0$ because this is the difference between the consumption of $a$ by $i$ under $e_i$ and the consumption of $a$ by $i$ under $e_i'$.  In particular $t_1' < t_1$.

During the interval $[t_0,t_1']$ the events that change the availability of objects are exhaustion of objects.
Aiming at a contradiction, suppose that there is a  $t \in [t_0,t_1']$ such that there is some $o \in O(t) \setminus \{a\}$ such that $o$ is available under $e_i$ but not under $e_i'$, and let $t^*$ be the greatest lower bound of the set of such $t$.
For each $t \in [t_0,t^*]$, $j \ne i$, and $o \ne a$,  if $j$ was consumes $o$ at time $t$ under $e_i'$, and $o$ is available to $j$ at time $t$ under $e_i$, then $j$ is consuming $o$ at time $t$ under $e_i$ because the set of things in $O \setminus \{a\}$ that are available at time $t$ under $e_i$ is a subset of the set of things  in $O \setminus \{a\}$ that are available at time $t$ under $e_i'$.  Therefore, for $t \in [t_0,t^*]$, $j \ne i$, and $o \ne a$, the total consumption of $o$ by $j$ is weakly greater under $e_i$ than under $e_i'$ because $j$ is eating $o$ under $e_i$ at each time when it has not been fully allocated under $e_i'$ and is being eaten by $j$ under $e_i'$.  It follows that an object that is fully allocated at or before $t^*$ under $e_i'$ is also  fully allocated at or before $t^*$ under $e_i$.  Therefore, for times near $t^*$ (on both sides if $t^* < t_1'$) for every $o \in O(t) \setminus \{a\}$ such that $o$ is available under $e_i$,  $o$ is also available under $e_i'$, contradicting the definition of $t^*$.

We have shown that for all  $t \in [t_0,t_1']$, all $j \in I \setminus \{i\}$, and all $o \in O \setminus \{a\}$, if $o$ is not available to $j$ at $t$ under $e_i'$, then it is not available to $j$ at $t$ under $e_i$. It follows that  for all  $t \in [t_0,t_1']$ the set of $j$ eating $a$ at $t$ under $e_i$ is a superset of the set of $j$ eating $a$ at $t$ under $e_i'$.  In particular, the amount of $a$ that remains uneaten at $t_1'$ under $e_1$ is not more than $\delta$, and in order to have $t_1 - t_1' - \delta \ge 0$ it must be the case that the amount that remains uneaten is $\delta$ and $i$ is the only agent eating $a$ during the interval $[t_1',t_1]$.  Since all agents are allowed to eat all objects, and they all have the same requirement, once an agent starts to eat $a$, she will continue to do so until it is exhausted or time $r$, so it must be the case that no agent other than $i$ was eating $a$ at any time.
Even if all this is the case, the consumption of $a$ by $i$ under $e_i'$ is as large as the the consumption of $a$ by $i$ under $e_i$, so $e_i'$ is  also a feasible element of $\cE_i$ that maximizes the overall allocation of $a$ for $i$.  The argument can now be repeated with $e_i'$ in place of $e_i$, and after finitely many repetitions we arrive at the conclusion that there is an optimal eating function that eats $a$ from time $0$ until time $r$ or $a$ is exhausted without anyone else ever eating $a$.  Since $r < q_a$, the unique such eating plan is to eat $a$ at all times.

Let $b$ be $i$'s second favorite element of $O$.  With obvious modifications, the argument above easily extends to show that among the eating functions for $i$ that maximize the overall allocation of $a$ for $i$, those that maximize the overall allocation of $b$ for $i$ have $i$ eating $b$ at every time when $a$ is not available and $b$ is.  The intuition is the same: if $i$ faces competition for $b$, the amount of $b$ consumed is maximized by eating $b$ from the time when $a$ becomes unavailable, and if there is no competition for $b$, then the unique optimal eating plan is to eat $b$  from the time when $a$ becomes unavailable to time $r$.  Extending this inductively, if an eating function for $i$ results in an allocation for $i$ that stochastically dominates the allocation resulting from the GCPS mechanism, then it agrees with the eating function $e^{\succ_i}$ of the GCPS mechanism, and therefore the resulting allocation is the GCPS allocation, which is the assertion of Theorem \ref{th:WeakStrategyProof}.

\section{Proof of Theorem \ref{thm:StrategyProof}} \label{app:StrategyProof}

This Appendix is devoted to the proof  of Theorem \ref{thm:StrategyProof}.  We retain the notation introduced in the second half of Section \ref{sec:StrategyProof}.  

It will be convenient to introduce a null object, which we denote by $\emptyset$.  Let $\hO = O \cup \{\emptyset\}$.  An \emph{eating function} $e = (e_j)_{j \in I}$ is now a vector of eating schedules $e_j \colon [0,1] \to \hO$ for each agent $j \in I$ that are  piecewise constant and right continuous: for all $t < 1$ there is $\varep > 0$ such that $e_j(t') = e_j(t)$ for all $t' \in [t, t+\varep)$.
For such an $e$ and $t \in [0,1]$ let $p(t,e) \in \Re_+^{I \times \hO}$ be the allocation given by
$p_{jo}(t,e) = \int_0^t \bone_{e_j(s) = o} \, ds$.  
For $P \subset O$ and $t \in [0,1]$ let 
$$\sigma_P(t,e) = s_P  -  \sum_{i \in I \setminus J_P} \sum_{o \in P} p_{io}(t,e)$$
be the number of remaining seats at schools in $P$ that can be assigned to students outside $J_P$.  Let
$$\alpha_j(t,e) = \alpha_j  \setminus \bigcup_{P \subset O \, : \, \text{$j \notin J_P$ and $\sigma_P(t,e) \le 0$}} P$$
be the set of schools at which $j$ can eat at time $t$.   We say that $o$ is \emph{available} to a student $j$ at time $t$ under the eating function $e$ if $o \in \alpha_j(t,e)$.  Note that $\alpha_j(\cdot,e)$ is right continuous.  Let $\halpha_j(t,e) = \alpha_j(t,e) \cup \{\emptyset\}$.

We now fix a profile $\succ \; = (\succ_j)_{j \in I}$ of preferences over $\hO$ such that for all $j$, $\emptyset$ is the $\succ_j$-worst element of $\hO$.  We also fix $i \in I$ and a piecewise constant eating schedule $\bare_i  \colon [0,1] \to \hO$ for $i$.  

\begin{lem} \label{lemma:EatDefined}
  There is a unique profile of eating functions $\bare = (\bare_i,\bare_{-i})$ such that for all $j \ne i$ and $t \in [0,1]$, $\bare_j(t)$ is the $\succ_j$-favorite element of $\halpha_j(t,\bare)$.  For any $t_0 \in [0,1)$, $\bare_j(t)$ is the $\succ_j$-favorite element of $\halpha_j(t_0,\bare)$ for all $t \in [t_0,t_1)$ where $t_1$ is the smallest time such that either $\sigma_P(t_1,\bare) = 0$ for some $P$ such that $\sigma_P(t_0,\bare) > 0$ or $t_1 = 1$.
\end{lem}

\begin{proof}
  For each $t_0$ the characterization of $\bare|_{[t_0,t_1]}$ is clearly a necessary condition.  Starting with $t_0 = 0$, this condition can be used to construct $\bare$ inductively because (since $\bare_i$ is piecewise constant) there  are finitely many possible events of the two types.
\end{proof}

An eating function $e$ is \emph{feasible} on the interval $[0,t]$ if, for all $s \in [0,t]$, $\sigma_P(s,e) \ge 0$ for all $P \subset O$.  By construction this condition is satisfied by the eating function of the last result if $\bare_i(t) \in \halpha_i(t,\bare)$ for all $t$.  In addition, by assumption the given $E$ satisfies the GMC, and the construction keeps the projection of $p(t,\bare)$ onto $\Re_+^{I \times O}$ in the set of possible partial allocations, so no $j \ne i$ is ever forced to eat $\emptyset$.  Thus:

\begin{lem}
  Let $\bare_i$ be an eating function for $i$, and let $\bare$ be the eating function given by Lemma \ref{lemma:EatDefined}.  If, for $t \in [0,1]$ and all $s \in [0,t]$, $\bare_i(t) \in \halpha_i(t,\bare)$, then $\bare$ is feasible on $[0,t]$, and $\bare_j(s) \in O$ for all $j \ne i$ and $s \in [0,t]$.
\end{lem}

For an eating function $e$ and $P \subset O$, let $\tau_P(e)$ be the first time $t$ such that $\sigma_P(t,e) = 0$ or $1$ if no such time exists.   We now consider an eating function $\bare_i^0$ for $i$, a time $\bart$, and an $\varep > 0$ such that $\bare_i^0$ is constant on $(\bart - \varep,\bart)$ with value $o^*$ and constant on $[\bart,\bart + \varep)$ with value $\emptyset$.  For $\rho \in (-\varep,\varep)$ let $\bare_i^\rho$ be the eating function for $i$ that  is constant on $(\bart - \varep,\bart + \rho)$ with value $o^*$, constant on $[\bart + \rho,\bart + \varep)$ with value $\emptyset$, and agrees with $\bare_i^0$ elsewhere, and let $\bare^\rho$ be the eating function given by Lemma \ref{lemma:EatDefined} for $\bare_i^\rho$.  

\begin{lem}
  For each $o \in O$ and $P \subset O$, $\tau_o(\bare^\rho)$ and $\tau_P(\bare^\rho)$ are piecewise linear functions of $\rho$.
\end{lem}

\begin{proof}
  This follows from the inductive characterization of $\bare^\rho$ given in Lemma \ref{lemma:EatDefined}: if $t_0$ and the numbers $q_o(t_0,\bare^\rho)$ and $\sigma_P(t_0,\bare^\rho)$ are piecewise linear functions of $\rho$, then so are  $t_1$ and the numbers $q_o(t_1,\bare^\rho)$ and $\sigma_P(t_1,\bare^\rho)$.
\end{proof}

For $o \in O$ let and $t \in [0,1]$ let $q_o(t,e) = q_o - \sum_i p(_{io}(t,e)$.

\begin{lem} \label{lemma:MonotoneCutoff} 
 For all  $\rho_0 \in (-\varep,\varep)$, $o \in O$, and $P \subset O$, if the derivative of  $\tau_o(\bare^\rho)$ with respect to $\rho$ is defined at $\rho_0$, then it is nonpositive, and if the derivative of $\tau_P(\bare^\rho)$ with respect to $\rho$ is defined at $\rho_0$, then it is nonpositive.  For all $o \in O$, if $o$ is available to $i$ at $t$, then the partial derivative of $q_o(t,\bare^\rho)$ with respect to $\rho$ lies in $[-1,1]$.
\end{lem}

\begin{proof}
  We assume that $E$ is simple.  (Equivalently, we can restrict attention to the component of the simple decomposition of $E$ that contains $i$.)   We also assume that $\rho_0 = 0$.  (Clearly we can bring this about by replacing $\bart$ and $\varep$.)
  
  We may assume that there is $\delta > 0$ such that there are affine functions $t_0, t_1, \ldots, t_K \colon (-\delta,\delta) \to [0,1]$ such that $0\equiv t_0 < t_1 < \cdots < t_K \equiv 1$ and for each $k = 1, \ldots, K-1$ and each $\rho \in (-\delta,\delta)$, $t_k(\rho)$ is the first time in $(t_{k-1}(\rho),1]$ that either $\sigma_P(t_k(\rho),\bare^\rho) = 0$ for one or more $P \subset O$ such that $\sigma_P(t,\bare^\rho) > 0$ for all $t < t_k(\rho)$.
  Since we may restrict to a subinterval of $(-\delta,\delta)$, for $0 < k < K$ we may assume that for all $\rho$ in this interval, the set $T_k$ of minimal $P \subset O$ such that $\sigma_P(t_k(\rho),\bare^\rho) = 0$ and $\sigma_P(t,\bare^\rho) > 0$ for all $t < t_k(\rho)$ is the same.  For $P \in T_k$ let 
  $$L_{kP} = \{\, j \in J_P^c \setminus \{i\} : \bare_j^\rho(t_{k-1}(\rho)) \in P \,\}.$$

  

  Let $k_0$ be the first $k$ (if one exists) such that there is a $P \in T_k$ such that  $o^* \in P$ and $i \in J_P^c$.  Since each $T_{k+1}$ contains a refinement of the partition $T_k$ of $\bigcup_{P \in T_k} P$, for all $k > k_0$ and $P \in T_k$, if $o^* \in P$, then $i \in J_P^c$.
  
  Let $\theta_k$ be the slope of $t_k$.  We now introduce functions that measure the amounts that the agents influence the process.  Suppose that $\bart \in [t_{k_0}(\rho),t_{k_0 + 1}(\rho))$.  
  Let $\iota_{k_0} \colon I \to \Re$ be the function given by $\iota_{k_0}(i) = 1$ and $\iota_{k_0}(j) = 0$ if $j \ne i$.  For $k > k_0$ we define $\iota_k \colon I \to \Re$ inductively by setting $\iota_k(i) = 0$ and, for $j \ne i$, setting $\iota_k(j) = -\theta_k$ if $j$ is an element of some $L_{kP}$, and otherwise setting $\iota_k(j) = \iota_{k-1}(j)$.  Thus $\iota_k(j) \ne \iota_{k-1}(j)$ only when $j$ is an element of some $L_{kP}$, which is the case if and only if $\bare_j^\rho(t_k(\rho)) \ne \bare_j^\rho(t_{k-1}(\rho))$.  In this circumstance $j$ has consumed $\iota_k(j)\rho = -\theta_k\rho$ additional units of $\bare_j^\rho(t_k(\rho))$ (in comparison with her consumption when $\rho = 0$) at times after $t_k(0)$ and before times near $t_{k+1}(0)$.  Since $\iota_{k+1}(j) = \iota_k(j)$ if $\bare_j^\rho(t_{k+1}(\rho)) = \bare_j^\rho(t_k(\rho))$, this difference persists until consumption of $\bare_j^\rho(t_k(\rho))$ ceases.

  We wish to show that $\theta_k \le 0$ and $\iota_k(j) \ge 0$ for all $k$ and $j$.  This holds when $k = k_0$, so, by induction, we may assume that $\iota_{k-1}(j) \ge 0$ for all $j$. For the sake of definiteness suppose that $\rho > 0$.  (The other case is similar.)  
  Suppose that $P \in T_k$.  If it is not the case that $o^* \in P$, then (since $i \in J_P^c$) in order for $t_k(0)$ and $t_k(\rho)$ to be the first times such that $\sigma_P(t_k(0),\bare^0) = 0$ and $\sigma_P(t_k(\rho),\bare^\rho) = 0$, it must be the case that the total amount the students in $L_{kP}$ could eat between $t_k(\rho)$ and $t_k(0)$ is $\sum_{j \in L_{kP}} \iota_{k-1}(j)\rho$.  Therefore
  $$\theta_k = -\frac{\sum_{j \in L_{kP}} \iota_{k-1}(j)}{|L_{kP}|}.$$ If $o^* \in P$, then $i \in J_P^c$, so in order for $t_k(0)$ and $t_k(\rho)$ to be the first times such that $\sigma_P(t_k(0),\bare^0) = 0$ and $\sigma_P(t_k(\rho),\bare^\rho) = 0$, it must be the case that the total amount the students in $L_{kP}$ could eat between $t_k(\rho)$ and $t_k(0)$ is $\rho + \sum_{j \in L_{kP}} \iota_{k-1}(j)\rho$.  Therefore
  $$\theta_k = -\frac{1 + \sum_{j \in L_{kP}} \iota_{k-1}(j)}{|L_{kP}|}.$$
  Evidently $\theta_k \le 0$, and it follows from the definition of $\iota_k$ that $\iota_k(j) \le 0$ for all $j$, so, by induction, these inequalities hold for all $k$ and $j$.  This completes the proof of the first assertion of Lemma \ref{lemma:MonotoneCutoff}.

  Fix an $o \in O$ and $t$ such that $o$ is available to $i$ under $\bare^\rho$ at $t$.   Let $\bark$ be the largest $k$ such that $t_\bark(\rho) < t$. For each $k \le \bark$, if there is $P \subset O$ such that $o \in P$ and $\sigma_P(t_k(\rho),\bare^\rho) = 0$, let $Q_{ko}$ be the smallest such set, and let $J_{ko} = J_{Q_{ko}}$. Otherwise let $$Q_{ko} = O \setminus \bigcup_{P \subset O : \sigma_P(t_k(\rho),\bare^\rho) = 0} P \quad \text{and} \quad J_{ko} = I \setminus \bigcup_{P \subset O : \sigma_P(t_k(\rho),\bare^\rho) = 0} J_P.$$  Since $o$ is available to $i$, $i \in J_{ko}$ and therefore $o^* \notin Q_{ko}$.
  
  We wish to show that $\sum_{j \in J_{ko}} \iota_k(j) \le \sum_{j \in J_{k-1,o}} \iota_{k-1}(j)$.  If $Q_k$ is critical, then this is immediate because $\iota_k(j) = \iota_{k-1}(j)$ for all $j \in J_{ko}$.  Suppose that $Q_k$ is not critical, and let $P^1, \ldots, P^l$ be the elements of $T_k$ that are contained in $Q_k$ and do not contain $o$. We have
  $$\sum_{j \in J_{ko}} \iota_k(j) = \sum_{j \in J_{k-1,o} \setminus \bigcup_h J_{P^g}} \iota_k(j) \le \frac{1}{l} \sum_h \sum_{j \in J_{k-1,o} \setminus J_{P^h}} \iota_k(j).$$
  For each $h$ we have
  $$\sum_{j \in J_{k-1,o} \setminus J_{P^h}} \iota_k(j) = \sum_{j \in J_{k-1,o} \setminus (J_{P^h} \cup L_{k-1,P^h})} \iota_k(j) + \sum_{j \in L_{k-1,P^h}} \iota_k(j)$$
  $$ = \sum_{j \in J_{k-1,o} \setminus (J_{P^h} \cup L_{k-1,P^h})} \iota_{k-1}(j) + |L_{k-1,P^h}| \theta_k$$
  and $|L_{k-1,P^h}| \theta_k = \sum_{j \in L_{k-1,P^h}} \iota_{k-1}(j)$.
    
  For each $k \le \bark$ let $$E_{ko} = \{\, j \in I \setminus \{j\} : \bare_j^\rho(t_k(\rho)) = o \,\}.$$ be the set of students who eat from school $o$ between $t_k(\rho)$ and $t_{k+1}(\rho)$. 
  The second assertion of Lemma \ref{lemma:MonotoneCutoff} follows once we show that 
  $$\sum_{k = k_0}^\bark \sum_{j \in E_{ko} \setminus E_{k-1,o}} \iota_k(j) \le 1 \quad \text{and} \quad \sum_{k = k_0}^\bark \sum_{j \in E_{k-1,o} \setminus E_{ko}} \iota_k(j) < 1$$ because the first sum is the total extent to which commencement of consumption of $o$ is moved earlier per unit increase of $\rho$ and the second  sum is the total extent to which cessation of consumption of $o$ is moved earlier per unit increase of $\rho$.

  Let: $$b_k = \sum_{j \in J_{ko}} \iota_k(j); \quad s_k = \sum_{j \in E_{ko} \cap J_{ko}} \iota_k(j); \quad t_k = \sum_{j \in E_{k-1,o} \cap E_{ko} \cap J_{ko}} \iota_k(j);$$
  $$u_k = \sum_{j \in (J_{ko} \setminus J_{k+1,o}) \setminus E_{ko}} \iota_{k+1}(j).$$  Ideally we would like to show that for all $k = k_0, \ldots, \bark$,
  $$t_{k_0} + \sum_{h = k_0}^k s_k - t_k + \sum_{h = k_0}^{k-1} u_k = 1 - b_k + s_k.$$
  Except for the slippage between $\iota_k$ and $\iota_{k+1}$, this would follow by induction from accounting identities.  This seems to pose the problem very clearly, but the problem has not yet been solved.
  
  
  
  \norev
  
  Provided we can show that $b_k \le \sum_{j \in J_{ko}} \iota_{k-1}(j)$, for $k > k_0$ we have
  $$t_k = \sum_{j \in E_{k-1,o} \cap E_{ko}} \iota_{k-1}(j) = s_{k-1} - \sum_{j \in E_{k-1,o} \setminus J_{ko}} \iota_{k-1}(j) \ge s_{k-1} - \sum_{j \in J_{k-1,o} \setminus J_{ko}} \iota_{k-1}(j)$$
  $$\ge s_{k-1} - b_{k-1} + b_k,$$ so 
  $$\sum_{k = k_0}^\bark s_k - t_k = s_\bark - t_0 + \sum_{k = k_0+1}^\bark s_{k-1} - t_k \le s_\bark + \sum_{k = k_0+1}^\bark b_{k-1} - b_k = s_\bark + 1 - b_\bark \le 1.$$

  \norev

  
  Obviously there is at most one $k_1 \le \bark$ such that $o^* \in S_{k_1}$.  Since $Q_{k+1,o} \subset Q_{ko}$ there is at most one $k_2 \le \bark$ such that $o^* \in Q_{k_2,o} \setminus Q_{k_2+1,o}$.  
  For each $k \le \bark$ let $$E_{ko} = \{\, j \in I \setminus \{i\} : \bare_j^\rho(t_k(\rho)) = o \,\}$$ be the set of students who eat from school $o$ between $t_k(\rho)$ and $t_{k+1}(\rho)$.  
  
  First suppose that $k_1 \ne k \ne k_2$.    The key idea is that for each $h$, the ratio of $|J_{P^h} \cap \bigcup_{o' \in S_k} L_{ko'}|$ to $|L_{P^ho}|$ is the same for all $h$.  The reason for this is that the limits need to be reached simultaneously along a range of $\rho$.
  
  
  Let $k_1$ be the first $k$ such that either $q_{o^*}(t_k(\rho),\bare^\rho) = 0$ or there is a $P \subset O$ such that $\sigma_P(t_k(\rho),\bare^\rho) = 0$ and $i \in J_P^c$.
  The second assertion of Lemma \ref{lemma:MonotoneCutoff} follows from the results above once we show that 
  $$\sum_{k = k_1}^\bark \sum_{j \in E_{ko} \setminus E_{k-1,o}} \iota_k(j) \le 1 \quad \text{and} \quad \sum_{k = k_1}^\bark \sum_{j \in E_{k-1,o} \setminus E_{ko}} \iota_k(j) < 1$$ because the first sum is the total extent to which commencement of consumption of $o$ is moved earlier per unit increase of $\rho$ and the second  sum is the total extent to which cessation of consumption of $o$ is moved earlier per unit increase of $\rho$.

  
  
  We first show that $\sum_{j \in J_{ko}} < 2$.  The idea is that there is at most one $k$ such that $o^* \in S_k \cap Q_k$ and at most one $k^*$ in which there is a $P \in T_{k^*}$ such that $o^* \in P$, $o \notin P$, and $i \notin J_P$.  This is enough to give us 
  $$\sum_{j \in E_{ko} \setminus E_{k+1,o}} \iota_{k+1}(j) + \sum_{j \in E_{k+1,o}} \iota_{k+1}(j) = \sum_{j \in E_{ko}} \iota_k(j)$$ if $k \ne k^*$ and  
  $$\sum_{j \in E_{k^*o} \setminus E_{k^*+1,o}} \iota_{k^*+1}(j) + \sum_{j \in E_{k^*+1,o}} \iota_{k^*+1}(j) < 1 + \sum_{j \in E_{k^*o}} \iota_{k^*}(j).$$
  
  \norev


  We will show that 
  $$\sum_{j \in J_k \setminus J_{k+1}} \iota_{k+1}(j) = \sum_{j \in J_k \setminus J_{k+1}} \iota_k(j)$$ except for two events, each of which brings at most one more unit of influence.  For the sake of concreteness suppose that $Q_k$ is critical.  
  
  
  The sets $J_{P^h} \setminus \{i\}$ are pairwise disjoint subsets of $J_{ko} \setminus \{i\}$, and $J_{k+1,o} \setminus \{i\} = (J_{ko} \setminus \{i\}) \setminus \bigcup_h J_{P^h}$.
  
  \norev
  
  Let $J_{0o} = I \setminus \{i\}$, and for define $J_{1o}, \ldots, J_{Ko}$ inductively by setting
  $$J_{ko} = J_{k-1,o} \setminus \Big( \bigcup_{P \in T_k \,:\, o \notin P} J_P \cup \bigcup_{P \in T_k \,:\, o \in P} J_P^c \Big).$$
  We claim that $\sum_{j \in J_{ko}} \iota_k(j) \le 1$ for all $k$.  This is clearly the case for all $k$ less than the first $k_1$ such that either $o^* \in S_{k_1}$ or there is a $P \in T_{k_1}$ such that $o^* \in P$ and $i \notin J_P$.  
  
  Recall that $\iota_{k_1-1}(i) = 1$ and $\iota_{k_1-1}(j) = 0$ for all $j \ne i$.  If $o^* \in S_{k_1}$, then the formulas above imply that $\theta_{k_1} = - 1/|L_{k_1o^*}|$, which implies that $\iota_{k_1}(j) = -\theta_{k_1}$ for all $j \in L_{k_1o^*}$, and we must have $S_{k_1} = \{o^*\}$.  If there is a $P \in T_k$, it must be the case that $o^* \in P$ and $i \notin J_P$ (so there is only one such $P$) and  $\theta_{k_1} = -1/|L_{k_1P}|$ and $\iota_{k_1}(j) = -\theta_{k_1}$ for all $j \in L_{k_1P}$.  Thus the claim holds for $k_1$ unless $o^* \in S_{k_1}$ and there is a $P \in T_{k_1}$, but if $o \in P$ then $J_{k_1o} \cap (L_{k_1o^*} \cup L_{k_1P}) \subset L_{k_1o^*}$, and if $o \notin P$, then $J_{k_1o} \cap (L_{k_1o^*} \cup L_{k_1P}) \subset L_{k_1P}$, so the claim holds in this case as well.

  Let $P_{ko}$ be the smallest subset of $O$ such that $(J_{P_{ko}},P_{ko})$ is critical at $k$.  What happens to elements of $J_{k-1,o}$ when we go to $J_{ko}$?  Those who are eating some $o' \in P_{ko} \cap S_k$ have their influence redistributed.  It cannot happen that $o' = o^*$ because that would imply that the initial period with distributed influence excluded $i$ from eating $o^*$, and if $o$ was in the same cell as $o^*$, then $o$ would be unavailable to $i$.  There are students who leave because they are elements of $J_P$ for some $P \in T_k$ that does not contain $o$, and it is the influence they receive as they go out the door that concerns us.  The total such influence is not greater than the total of the departing group, which is a redistribution of what they took out, unless $i$ is a member of the departing group, in which case this is the end of $o$'s availability to $i$.  This gives a boost to the bottom inequality.  

  Let's try to give a description of what we want.  In the first period where $o^*$ figures, there is a certain amount of influence of the agents who might eat $o$.  As time goes on, the sum of the influences of those who start eating $o$ is never greater than this.  The sum of the departing influences of those who stop eating $o$ is never greater than this, except possibly at the final period of $o$ begin available to $i$.  We can see what's going on, but we need concepts and notation to describe it.  Let $E_{ko}$ be the set of student who are actually eating $o$.  
  
  \norev
  
  We claim that $\sum_j \iota_k(j) = 1$ for all $k \ge k_0$.  Clearly this holds for $k_0$, so by induction we may assume that it holds for $k-1$.  It suffices to show that the average of $\iota_{k-1}$ over $$U_k = \bigcup_{o \in S_k} L_{ko} \cup \bigcup_{P \in T_k} L_{kP}$$ is the average of $\iota_k$ over this set, which is $-\theta_k$.  Note that the sets $L_{kP}$ for $P \in T_k$ are pairwise disjoint.  For each $P \in T_k$ and $o \in P \cap S_k$, the average of $\iota_{k-1}$ over elements of $L_{ko}$ is $-\theta_k$, and the average of $\iota_{k-1}$ over elements of $L_{kP}$ is $-\theta_k$, so the average of $\iota_{k-1}$ over elements of $L_{kP} \setminus \bigcup_{o \in S_k} L_{ko}$ is $-\theta_k$.  Finally, the average over $L_{ko}$ for each $o \in S_k \setminus \bigcup_{P \in T_k} P$ is $-\theta_k$.  We have found a representation of $U_k$ as a disjoint union of sets such that the average of $\iota_{k-1}$ over each of the sets is $-\theta_k$, so the average of $\iota_{k-1}$ over $U_k$ is $-\theta_k$.
  
  Suppose that $(J_Q,Q)$ is a critical pair at time $t_{k-1}(\rho)$.  For each $o \in S_k$, either $o \in Q$ and $L_{ko} \subset J_Q$ or $o \in Q^c$ and $L_{ko} \subset J_Q^c$.  For each $P \in T_k$, either $P \subset Q$ and $L_{kP} \subset J_Q$ or $P \subset Q^c$ and $L_{kP} \subset J_Q^c$.  Proceeding as above gives a  representation of $J_Q \cap U_k$ as a disjoint union of sets such that the average of $\iota_{k-1}$ over each of the sets is $-\theta_k$, which is the average of $\iota_k$ over the set.  Since $\iota_k(j) = \iota_{k-1}(j)$ for all $j \in J_Q \setminus U_k$ we conclude that $$\sum_{j \in J_Q} \iota_k(j) = \sum_{j \in J_Q} \iota_{k-1}(j).$$
  
  Consider $o \ne o^*$.  We can assume that $t < \tau_o(\bare^\rho)$.  The partial of $q_o(t,\bare^\rho)$ with respect to $\rho$ is the sum over $j$ that consume $o$ prior to $t$ of $\iota_k(j)$ if they start eating $o$ at $t_k(\bare^\rho)$ less $\iota_l(j)$ if they are forced to stop consuming at $t_l(\rho)$.  This is less than sum over $j$ that consume $o$ prior to $t$ of $\iota_k(j)$ if they start eating $o$ at $t_k(\rho)$.  Suppose that for each $k$, $P_k$ is the smallest critical set at time $t_k(\rho)$ such that $o \in P_k$, so that all the people eating $o$ starting at $t_k(\rho)$ are in $J_{P_k}$.  For those $j \in P_k$ such that $\bare_j(t_{k-1}(\rho)) = o$, $\iota_k(j) = \iota_{k-1}(j)$  agrees with $\iota_l(j)$ if they start eating $o$ at $t_l(\rho)$.  Therefore the sum over $j \in P_k$ of the $o$-initial influence of those eating $o$ at $t_k(\rho)$ is not greater than $\sum_{j \in P_k} \iota_k(j)$.  There is more detail to add, but basically I think I understand this.
  
  The remaining problem is $o = o^*$.  The first impact of $i$'s increased eating of $o^*$ is to more quickly trigger the criticality of a pair $(J_P,P)$ with $o^* \in P$ and $i \in J_P^c$.  We arrive at this pair with less of $o^*$ and weakly more of everything else.  Exhaustions of schools that might lead people to $o^*$ come later, and critical sets $(J_Q,Q)$ with $o^* \notin Q$ should arrive later.  
\end{proof}

We now a second preference $\succ_i'$ for $i$ for which $\emptyset$ is the $\succ_i'$-worst element of $\hO$, and we let $\succ' = (\succ_i',\succ_{-i})$.
Let $e^\succ$ and $e^{\succ'}$ be the eating functions generated by the GCPS procedure when agents report $\succ$ and $\succ'$ respectively.
Let $\bare_i$ be the eating schedule
$$\bare_i(t) = 
\begin{cases}
  e_i^\succ(t) & \text{if $e_i^\succ(t) = e_i^{\succ'}(t)$,} \\
  \emptyset & \text{otherwise},
\end{cases}$$
and let $\bare$ be the eating schedule given by Lemma \ref{lemma:EatDefined} for this $\bare_i$.  In view of Lemma \ref{lemma:MonotoneCutoff} we have $\tau_o(e^\succ), \tau_o(e^{\succ'}) \le \tau_o(\bare)$ for all $o$ and $\tau_P(e^\succ), \tau_P(e^{\succ'}) \le \tau_P(\bare)$ for all $P$, so $\bare_i$ does not $i$ to eat objects that are unavailable under $\bare$, and thus $\bare$ is feasible.

Let $\beta(t)$, $\gamma(t)$, and $\delta(t)$ denote the sums of the lengths of time intervals, before time $t$, on which agent $i$'s consumption in the eating algorithm is $\succ_i$-preferred, $\succ_i$-less preferred, and different, respectively, when the reported preferences change from $\succ$ to $\succ'$.  Formally,
$$\beta(t) = \int_0^t \bone_{e_i^{\succ'}(s) \succ_i e_i^\succ(s)} ds, \quad \gamma(t) = \int_0^t \bone_{e_i^{\succ}(s) \succ_i e_i^{\succ'}(s)} ds, \quad \text{and} \quad \delta(t) = \beta(t) + \gamma(t).$$  

\begin{lem}
  For all $o \in O$, $0 \le \tau_o(\bare) - \tau_o(e^\succ) \le \beta(\tau_o(\bare))$ and $0 \le \tau_o(\bare) - \tau_o(e^{\succ'}) \le \beta(\tau_o(\bare))$.  
  For all $P \subset O$, $0 \le \tau_P(\bare) - \tau_P(e^\succ) \le \beta(\tau_P(\bare))$ and $0 \le \tau_P(\bare) - \tau_P(e^{\succ'}) \le \beta(\tau_o(\bare))$.
\end{lem}

\begin{proof}
  These inequalities are obtained by integrating the inequalities of derivatives given by Lemma \ref{lemma:MonotoneCutoff}.
\end{proof}

\norev

\begin{lem} \label{lemma:KM3}
  For all $t \in [0,1]$, if $P$ is a set of schools that are available to $i$ at $t$,  then
  $$\sigma_P(t,e^\succ) \ge \sigma_P(t,\bare) - \delta(t).$$
\end{lem}

\begin{proof}
  For $o \in P$, Lemma \ref{lemma:ReallyNotKM} gives $p_{jo}(t,e^\succ) \ge p_{jo}(t,\bare)$ if $j \ne i$, and the definition of $\bare$ gives $\sum_{o \in P} p_{io}(t,e^\succ) \ge \sum_{o \in P} p_{io}(t,\bare) - \delta(t)$.
\end{proof}

The definition of $\bare$ is symmetric with respect to interchange of $\succ$ and $\succ'$, so Lemmas \ref{lemma:NotKM}--\ref{lemma:KM3} apply equally with $e^{\succ'}$ in place of $e^\succ$. 

\begin{lem} \label{lemma:KM4}
  For all $t \in [0,1]$, if $P$ is a set of schools that are available to $i$ at $t$,  then
  $$\sigma_P(t,e^\succ) - \sigma_P(t,e^{\succ'}) \le \delta(t).$$
\end{lem}

\begin{proof}
  This follows from Lemmas \ref{lemma:KM1} and \ref{lemma:KM3}, since
  \begin{equation*}
    \sigma_P(t,e^\succ) - \sigma_P(t,e^{\succ'}) = [\sigma_P(t,e^\succ) - \sigma_P(t,\bare)] - [\sigma_P(t,e^{\succ'}) - \sigma_P(t,\bare)]. \qedhere
  \end{equation*}
\end{proof}

Let
$$\{o_1, o_2, \ldots, o_{\barl}\} = \{\, o \in O : \text{$o = e_i^{\succ'}(t) \succ_i e_i^\succ(t)$ for some $t \in [0,1)$} \,\}$$
be the set of objects $o$ such that for some time $t$, $o = e_i^{\succ'}(t)$ is $\succ_i$-preferred to $e_i^\succ(t)$.  
These objects are indexed so that 
$o_1 \succ_i' o_2 \succ_i' \cdots \succ_i' o_{\barl}$.  For $l = 1, \ldots, \barl$ let
$$T_l = \inf \{\, t : o_l = e_i^{\succ'}(t) \succ_i e_i^\succ(t) \,\}$$ 
be the first instant $t$ when $o_l = e_i^{\succ'}(t)$ is $\succ_i$-preferred to $e_i^\succ(t)$.  For each $l$ let 
$$T_l' = \sup \{\, t : o_l = e_i^{\succ'}(t) \,\}$$ 
Clearly, $0 < T_1 < T_1' \le T_2 < \cdots < T_{\barl - 1}' \le T_{\barl} < T_{\barl}' \le1$.  Let $T_0= 0$ and $T_{\barl + 1} = 1$.

Since consumption under $e^{\succ'}_i$ is in decreasing order according to $\succ'_i$,  the object $o_l$ is not available to $i$ after time $T_l'$ under the eating function $e^{\succ'}$, i.e., either $T_l'$ is the first time $t$ such that $q_{o_l}(t,e^{\succ'}) = 0$ or there is a $P_l$ such that $o_l \in P_l$, $i \notin J_{P_l}$, and $T_l'$ is the first time $t$ such that $\sigma_{P_l}(t,e^{\succ'}) = 0$. 

\begin{lem} \label{lemma:KM5new}
  For all $l = 1, \ldots, \barl$, if $T_l'$ is the first time $t$ such that $q_{o_l}(t,e^{\succ'}) = 0$, then
  $$T_l' - T_l \le \frac{\delta(T_l)}{N_0 + 1}.$$
\end{lem}

\begin{proof}
  Since $o_l = e_i^{\succ'}(T_l) \succ_i e_i^\succ(T_l)$, it follows that the object $o_l$ is not available at time $T_l$ under the eating function $e^\succ$, i.e., $v_{o_l}(T_l,e^\succ) = q_{o_l}$.  By Lemma 4,
  $$v_{o_l}(T_l,e^{\succ'}) \ge v_{o_l}(T_l,e^\succ) - \delta(T_l).$$
  Since $v_{o_l}(T_l,e^{\succ'}) = q_{o_l}$ we have 
  \begin{equation*}
  T_l' - T_l \le \frac{q_{o_l} - v_{o_l}(T_l,e^{\succ'})}{N_0 + 1} \le \frac{\delta(T_l)}{N_0 + 1}. \qedhere
  \end{equation*}
\end{proof}

\begin{lem} \label{lemma:KM5}
  For all $l = 1, \ldots, \barl$, if  there is a $P_l$ such that $o_l \in P_l$, $i \notin J_{P_l}$, and $T_l'$ is the first time $t$ such that $\sigma_{P_l}(t,e^{\succ'}) = 0$, then
  $$T_l' - T_l \le \frac{\delta(T_l)}{N_0 + 1}.$$
\end{lem}

\begin{proof}
  We may replace $P_l$ with a minimal set satisfying the condition, so we may assume that $\sigma_P(T_l,e^{\succ'}) > 0$ for all nonempty $P \subset P_l$.  Lemma \ref{lemma:KM4} implies that
  $$\delta(T_l) \ge \sigma_{P_l}(T_l,e^{\succ'}) - \sigma_{P_l}(T_l,e^{\succ}).$$  Since $P_l$ contains at least one object and there are at least $N_0$ students eating this object, $T_l' - T_l \le (\sigma_{P_l}(T_l,e^{\succ'}) - \sigma_{P_l}(T_l,e^{\succ}))/(N_0 + 1)$.
\end{proof}

Let $\lambda = (N_0 + 2)/(N_0 + 1)$.

\begin{lem} \label{lemma:KM6}
  For all $l = 1, \ldots, \barl$,
  $$T_l' - T_l \le \gamma(1)(\lambda - 1)\lambda^{l-1}.$$
\end{lem}

\begin{proof}
  We prove the lemma by induction on $l$.  We have $\delta(T_1) = \gamma(T_1) \le \gamma(1) \le 1$, so Lemma \ref{lemma:KM5} implies that $T_1' - T_1 \le \delta(T_1) /(N_0 + 1) \le \gamma(1)(\lambda - 1)$. 
  Suppose that $l \ge 2$ and the induction hypothesis holds for $1, \ldots, l - 1$.  Then
  $$\delta(T_l) = \gamma(T_l) + \beta(T_l) \le \gamma(1) + \sum_{g = 1}^{l-1} \beta(T_{g+1}) - \beta(T_g) = \gamma(1) + \sum_{g = 1}^{l-1} T_g' - T_g$$
  $$\le \gamma(1)\Big(1 + (\lambda - 1)\sum_{g = 0}^{l-2}\lambda^g\Big) = \gamma(1)\lambda^{l-1}.$$
  Applying Lemma \ref{lemma:KM5} again gives
  \begin{equation*}
  T_l' - T_l \le \frac{\delta(T_l)}{N_0 + 1} \le \gamma(1)(\lambda - 1)\lambda^{l-1}. \qedhere
  \end{equation*}
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:StrategyProof}.]
  We have
  $$u_i(GCPS(\succ)) - u_i(GCPS(\succ')) = \int_0^1 u_i(e_i^\succ(s)) - u_i(e_i^{\succ'}(s)) \, ds \ge d_i\gamma(1) - D_i\beta(1).$$
  Since $\beta(T_1) = 0$, adding up the inequalities from Lemma \ref{lemma:KM6} for gives
  $$\beta(1) = \sum_{g = 1}^{\barl} \beta(T_{g+1}) - \beta(T_g) = \sum_{g = 1}^{\barl} T_g' - T_g \le \gamma(1)(\lambda - 1)
  \sum_{g = 1}^{\barl}\lambda^{g-1} = \gamma(1)(\lambda^{\barl} - 1).$$ 
  Therefore
  $$u_i(GCPS(\succ)) - u_i(GCPS(\succ')) \ge \gamma(1)\big(d_i - D_i(\lambda^{\barl} - 1)\big),$$
  and since $\barl \le |O|$, this is nonnegative if
  \begin{equation*}
  \big(1 + \frac{d_i}{D_i}\big)^{1/|O|} \ge \lambda = \frac{N_0 + 2}{N_0 + 1}. \qedhere
  \end{equation*}
\end{proof}

\norev

Note that over the period when $o$ has not been exhausted, $n_o(t,e^\succ)$ is a weakly increasing function because agents may switch to eating $o$ as other objects become unavailable, and $n_o(t,J,\bare)$ is a weakly increasing function  over the period when $\bare$ is defined and $o$ has not been exhausted.  

\norev

\noindent
[\emph{
The following argument is not working, because it is not the case that ``$n_{o_l}(\cdot, e^{\succ'})$ is increasing on the time interval when $o_l$ is available under $e^{\succ'}$,'' and we will need to strenghthen assumptions.  Roughly, the idea should be that we assume that the number of people who are compelled to consume $o_l$ is large enough to minimize potential gains.
}]

\begin{lem} % \label{lemma:KM5new}
  For all $l = 1, \ldots, \barl$, if $T_l'$ is the first time $t$ such that $q_{o_l}(t,e^{\succ'}) = 0$, then
  $$T_l' - T_l \le \frac{\delta(T_l)}{q_{o_l}}.$$
\end{lem}

\begin{proof}
  Since $o_l = e_i^{\succ'}(T_l) \succ_i e_i^\succ(T_l)$, it follows that the object $o_l$ is not available at time $T_l$ under the eating function $e^\succ$, i.e., $v_{o_l}(T_l,e^\succ) = q_{o_l}$.  By Lemma 4,
  $$v_{o_l}(T_l,e^{\succ'}) \ge v_{o_l}(T_l,e^\succ) - \delta(T_l) > q_{o_l} - 1.$$
  As $n_{o_l}(\cdot, e^{\succ'})$ is increasing on the time interval when $o_l$ is available under $e^{\succ'}$, 
  $$n_{o_l}(T_l,e^{\succ'}) > n_{o_l}(T_l,e^{\succ'})T_l \ge \int_0^{T_l} n_{o_l}(s,e^{\succ'}) \, ds = v_{o_l}(T_l,e^{\succ'}) > q_{o_l} - 1.$$
  Then $n_{o_l}(T_l,e^{\succ'}) \ge q_{o_l}$ because $n_{o_l}(T_l,e^{\succ'})$ is an integer.  It follows that $n_{o_l}(s,e^{\succ'}) \ge q_{o_l}$ for all times $s \ge T_l$ when $o_l$ is still available under $e^{\succ'}$.  Note that $o_l$ is available under $e^{\succ'}$ at $s \ge T_l$ if $e_i^{\succ'}(s) = o_l$.  Therefore,
  $$n_{o_l}(s,e^{\succ'}) \ge q_{o_l} \bone_{e_i^{\succ'}(s) = o_l}$$ for all $s \in [T_l,T_{l+1})$.  By (6), $v_{o_l}(T_l,e^{\succ'}) \ge v_{o_l}(T_l,e^\succ) - \delta(T_l) = q_{o_l} - \delta(T_l)$.  Thus
  $$\delta(T_l) \ge q_{o_l} - v_{o_l}(T_l,e^{\succ'}) \ge v_{o_l}(T_{l+1},e^{\succ'}) - v_{o_l}(T_l,e^{\succ'}) = \int_{T_l}^{T_{l+1}} n_{o_l}(s,e^{\succ'}) \, ds$$
  $$\ge q_{o_l} \int_{T_l}^{T_{l+1}} \bone_{e_i^{\succ'}(s) = o_l} \, ds = q_{o_l}(T_l' - T_l),$$
  where the last inequality holds because, by the definition of $o_l$ and $T_l$, the times in $[T_l,T_{l+1})$ when agent $i$' consumption in the eating algorithm is $\succ_i$-preferred if the reported preferences change from $\succ$ to $\succ'$ are exactly those when $i$ eats $o_l$.  Thus the asserted inequality holds.
\end{proof}

\begin{lem} % \label{lemma:KM5}
  For all $l = 1, \ldots, \barl$, if  there is a $P_l$ such that $o_l \in P_l$, $i \notin J_{P_l}$, and $T_l'$ is the first time $t$ such that $\sigma_{P_l}(t,e^{\succ'}) = 0$, then
  $$T_l' - T_l \le \frac{\delta(T_l)}{s_{P_l} - \delta(T_l)}.$$
\end{lem}

\begin{proof}
  We may replace $P_l$ with a minimal set satisfying the condition, so we may assume that $\sigma_P(T_l,e^{\succ'}) > 0$ for all nonempty $P \subset P_l$.  Lemma \ref{lemma:KM4} implies that
  $$\delta(T_l) \ge \sigma_{P_l}(T_l,e^{\succ'}) - \sigma_{P_l}(T_l,e^{\succ}) = \sigma_{P_l}(T_l,e^{\succ'}).$$
  Since, for all $o \in P_l$, $n_o(\cdot, e^{\succ'})$ is weakly increasing on the time interval when $o$ is available, we have
  $$\sigma_{P_l}(T_l,e^{\succ'}) = \sigma_{P_l}(T_l,e^{\succ'}) - \sigma_{P_l}(T_l',e^{\succ'}) = \sum_{o \in P_l} \int_{T_l}^{T_l'} n_o(s,I \setminus J_{P_l},e^{\succ'}) \, ds \qquad \qquad$$
  $$\qquad \qquad \ge \sum_{o \in P_l} n_o(T_l,I \setminus J_{P_l},e^{\succ'})\int_{T_l}^{T_l'} \bone_{e_i^{\succ'}(s) = o} \, ds = \sum_{o \in P_l} n_o(T_l,I \setminus J_{P_l},e^{\succ'})(T_l' - T_l)$$
  and
  $$\sum_{o \in P_l} n_o(T_l,I \setminus J_{P_l},e^{\succ'}) > T_l \sum_{o \in P_l} n_o(T_l,I \setminus J_{P_l},e^{\succ'}) \ge \sum_{o \in P_l} \int_0^{T_l} n_o(s,I \setminus J_{P_l},e^{\succ'}) \, ds $$
  \begin{equation*}
  = s_{P_l} - \sigma_{P_l}(T_l,e^{\succ'})  \ge s_{P_l} - \delta(T_l). \qedhere
  \end{equation*}
\end{proof}


Recall that $Q = \big(1 - (1 + \tfrac{d_i}{D_i})^{-1/|O|})^{-1}$, and let $\lambda = Q/(Q - 1) =   (1 + \tfrac{d_i}{D_i})^{1/|O|}$.

\begin{lem} % \label{lemma:KM6}
  If, for all $P \subset O$, either $s_P \ge Q$ or $s_P = 0$, then  for all $l = 1, \ldots, \barl$,
  $$T_l' - T_l \le \gamma(1)(\lambda - 1)\lambda^{l-1}.$$
\end{lem}

\begin{proof}
  We prove the lemma by induction on $l$.  We have $\delta(T_1) = \gamma(T_1) \le \gamma(1) \le 1$, so Lemma \ref{lemma:KM5} implies that $T_1' - T_1' \le \delta(T_1) /(s_{P_1} - \delta(T_1)) \le \gamma(1)/(Q - 1) = \gamma(1)(\lambda - 1)$. 
  Suppose that $l \ge 2$ and the induction hypothesis holds for $1, \ldots, l - 1$.  Then
  $$\delta(T_l) = \gamma(T_l) + \beta(T_l) \le \gamma(1) + \sum_{g = 1}^{l-1} \beta(T_{g+1}) - \beta(T_g) = \gamma(1) + \sum_{g = 1}^{l-1} T_g' - T_g$$
  $$\le \gamma(1)\Big(1 + (\lambda - 1)\sum_{g = 0}^{l-2}\lambda^g\Big) = \gamma(1)\lambda^{l-1}.$$
  Applying Lemma \ref{lemma:KM5} again gives
  $$T_l' - T_l \le \frac{\delta(T_l)}{s_{P_l} - \delta(T_l)} \le \frac{\delta(T_l)}{Q - 1} \le \gamma(1)(\lambda - 1)\lambda^{l-1}.$$ 
\end{proof} 

\norev

For an eating function $e$, $o \in O$, $J \subset I$, and $t \in [0,1]$ let 
$$n_o(t,J,e) = |\{\, j \in J : e_j(t) = o \,\}|,$$
so $n_o(t,J,e)$ is the number of students in $J$ eating from school $o$ at time $t$.  Let $n_o(t,e) = n_o(t,I,e)$.  Let 
$$v_o(t,e) = \int_0^t n_o(s,e) \, ds$$
be the total consumption of $o$ by time $t$.

\norev

and for $j \ne i$, at each $t$, $\bare_j(t)$ agent is the $\succ_j$ most preferred element of $\alpha_i(t,\bare) \cup \{\emptyset\}$. Note that $\bare_j$ may diverge from $e_j^\succ$ or $e_j^{\succ'}$ since the available objects at each time may differ between $\bare$, $e^\succ$, and $e^{\succ'}$ due to the different eating behaviors of $i$.  In particular, we have not yet shown that $\bare$ is feasible on $[0,1]$. 
Let 
  $$t_0 = \sup \{\, t : \text{$\bare|_{[0,t]}$ is feasible, $\sigma_P(t,e^\succ) \le \sigma_P(t,\bare)$ for all $P \subset O$ such that $i \notin J_P$,}$$
  $$\text{and $v_o(t,e^\succ) \ge v_o(t,\bare)$ for each $o$ that is available to $i$ at $t$ under ??} \,\}.$$
  
\begin{lem} \label{lemma:NotKM}
   For each $t \le t_0$, each $o \in O$ that is available to $i$ at $t$ under ??, and each $j \in I$,
   $$\{\, s \in [0,t] : \bare_j(s) = o \,\} \subset \{\, s \in [0,t] : e^\succ_j(s) = o \,\}, \eqno{(*)}$$
   and $p_{jo}(t,e^\succ) \ge p_{jo}(t,\bare)$ if $j \ne i$.
\end{lem}

\begin{proof}
  The definition of $\bare_i$ implies ($*$) if $j = i$.  Consider $s \in [0,t]$.  By the definition of $t_0$ we have $\sigma_{P'}(s,e^\succ) \le \sigma_{P'}(s,\bare)$ for all $P' \subset O$.  (This holds trivially if $t_0 = 0$.)
  Therefore a set $P'$ of schools that is not closed off to students outside $J_{P'}$ at time $s$ under $e^\succ$ cannot be closed off to students outside $J_{P'}$ at $s$ under $\bare$ either.  Consequently $\alpha_j(s,e^\succ) \subset \alpha_j(s,\bare)$ for all $j \ne i$.  It  must be that if agent $j \ne i$ is eating object $o \in P$ at $s$ under $\bare$ and $o \in \alpha_j(s,e^\succ)$, then $j$ is eating $o$ at $s$ under $e^\succ$. Therefore ($*$) holds for $j \ne i$.    (For $j = i$ ($*$) follows from the definition of $\bare$.) If $j \ne i$, then integration gives $p_{jo}(t,e^\succ) \ge p_{jo}(t,\bare)$.
\end{proof}

\begin{lem} \label{lemma:KM1}
  $t_0 = 1$.
\end{lem}

\begin{proof}
  Aiming at a contradiction, suppose that $t_0 < 1$.  There are now three possibilities.   The first is that 
  $$\inf \{\, t : \text{$\bare|_{[0,t]}$ is not defined} \,\} = t_0 < 1.$$  From the definition of $\bare$, this happens only if, immediately after $t_0$, $\bare_i$ mandates consumption of an object $o$ that is not available to $i$.  Since $o$ is available under $e^\succ$, for each $P$ containing $o$ we have $\sigma_P(t_0,e^\succ) > 0$, and the definition of $t_0$ gives $\sigma_P(t_0,e^\succ) \le \sigma_P(t_0,\bare)$, so $o$ is available for some time after $t_0$ under $\bare$.
  
  The second possibility is that there is a $P \subset O$ such that 
  $$\inf \{\, t : \text{$\bare|_{[0,t]}$ is defined and $\sigma_P(t,e^\succ) > \sigma_P(t,\bare)$} \,\} = t_0 < 1.$$
  Of course $\sigma_P(t_0,e^\succ) = \sigma_P(t_0,\bare) > 0$, and $e_i^\succ(t_0) \in \alpha_i(t_0,\bare)$.  Given the right continuity of $e^\succ$ and $\bare$, Lemma \ref{lemma:NotKM} implies that if $\varep > 0$ is sufficiently small, then,  for all $t \in [t_0,t_0 + \varep)$, $\bare|_{[0,t]}$ is defined and $n_o(t,I \setminus J_P,e^\succ) \ge n_o(t,I \setminus J_P,\bare)$. This implies that $\sigma_P(t,e^\succ) \le \sigma_P(t,\bare)$  for all $t \in [t_0,t_0 + \varep)$, and since this is the case for all $P$ such that $\inf \{\, t : \sigma_P(t,e^\succ) > \sigma_P(t,\bare) \,\} = t_0$, this implies that $t_0 < t_0$.
  
  The third possibility is that there is an $o$ such that  
  $$\inf \{\, t : \text{$\bare|_{[0,t]}$ is defined, $o$ is available to $i$ at $t$, and  $v_o(t,e^\succ) < v_o(t,\bare)$} \,\} = t_0 < 1.$$
  Continuity implies that $v_o(t_0,e^\succ) = v_o(t_0,\bare)$.  As we saw in the last argument, $\alpha_j(t_0,e^\succ) \subset \alpha_j(t_0,\bare)$ for all $j \ne i$, and right continuity implies that $\alpha_j(t,e^\succ) \subset \alpha_j(t,\bare)$ for all $j \ne i$ and all $t$ in some interval $[t_0,t_0 + \varep)$.
  Therefore if agent $j \ne i$ is eating object $o \in P$ at $t_0$ under $\bare$, then $j$ is eating $o$ at all $t \in [t_0,t_0 + \varep)$ under $e^\succ$.  By definition student $i$'s consumption of $o$ is at least as large under $e^\succ_i$ as under $\bare_i$.
\end{proof}

The next two results are immediate corollaries.

\begin{lem} \label{lemma:KMcor}
  For all $t \in [0,1]$ and $P \subset O$,
  $\sigma_P(t,e^\succ) \le \sigma_P(t,\bare)$.
\end{lem}
  
\begin{lem} \label{lemma:ReallyNotKM}
   For each $t \in [0,1]$, each $o$ that is available to $i$ at $t$, and each $j \ne i$, $p_{jo}(t,e^\succ) \ge p_{jo}(t,\bare)$.
\end{lem}

\end{appendix}

%%%------------------------------------------------------------------------------------
%%%------------------------------------------------------------------------------------
\bibliographystyle{agsm}
\bibliography{pa_ref}
\end{document}


\section{Weak Strategy Proofness} \label{app:WeakStrategyProof}

Let $E = (I,O,r,q,g)$ be an eligibility CEE.  As we stated in Section \ref{sec:StrategyProof}, we wish to prove something stronger than Theorem \ref{th:WeakStrategyProof}, namely that there is no eating strategy for an agent that results in an allocation that strictly stochastically dominates the GCPS allocation.  We now fix an agent $i$.  We need to explain the consequences of $i$ following a particular eating function.

Assume that $E$ is simple.  We imagine that the process begins at time $t_0 \ge 0$, and it specify how it continues until the first time $t^*$ such that the resulting residual economy is not simple.  We assume that there is an eating function $\te_i \colon [t_0,t^*] \to O$ that is piecewise constant, with additional properties described below.
For each $t \in [t_0,t^*]$ there are the following objects:
\begin{enumerate}
  \item[(a)] $p^{\te_i}(t)$ is a partial allocation.
  \item[(b)] $E^{\te_i}(t) = (I,O,r^{\te_i}(t),q^{\te_i}(t),g^{\te_i}(t)) = E - p^{\te_i}(t)$ is a CEE that satisfies the GMC.
  \item[(c)] For each $j$, $\alpha^{\te_i}_j(t) = \{\, o : \text{$q^{\te_i}_o(t) > 0$ and $g_{jo} > 0$} \,\}$ is $j$'s set of available objects.
  \item[(d)] For each $j \ne i$ such that $r^{\te_i}_j(t) > 0$, $e^{\te_i}_j(t)$ is the $\succ_j$-best element of $\alpha^{\te_i}_j(t)$.
  \item[(e)] If $r^{\te_i}_i(t) > 0$, then $e^{\te_i}_i(t) = \te_i(t) \in \alpha^{\te_i}_i(t)$.
\end{enumerate}
We require that $p^{\te_i}(t_0) = 0$.  We also require that $r^{\te_i}(t)$, $q^{\te_i}(t)$, $g^{\te_i}(t)$, and $p^{\te_i}(t)$ are continuous and piecewise linear functions of $t$, and that when their derivatives  $\dr^{\te_i}(t)$, $\dq^{\te_i}(t)$, $\dg^{\te_i}(t)$, and $\ddp^{\te_i}(t)$ with respect to time  are defined, for all $j$ they satisfy:
\begin{enumerate}
  \item[(a)] $\dr^{\te_i}_j(t) = -1$ if $r^{\te_i}_j(t) > 0$, and otherwise $\dr^{\te_i}_j(t) = 0$.
  \item[(b)] $\dq^{\te_i}_o(t) = -|\{\, j : \text{$r^{\te_i}_j(t) > 0$ and $e^{\te_i}_j(t) = o$} \,\}|$.
  \item[(c)] $\dg^{\te_i}_{jo}(t) = -1$ if $r^{\te_i}_j(t) > 0$ and $e^{\te_i}_j(t) = o$, and otherwise $\dg^{\te_i}_{jo}(t) = 0$.
  \item[(d)] $\ddp^{\te_i}_{jo}(t) = 1$ if $r^{\te_i}_j(t) > 0$ and $e^{\te_i}_j(t) = o$, and otherwise $\ddp^{\te_i}_{jo}(t) = 0$.
\end{enumerate}
We define $t^*$ to be the smallest number greater than $t_0$ such that either $r^{\te_i}(t^*) = 0$ or $E^{\te_i}(t^*)$ is not simple.

What we described above is one stage of a larger process that we now explain.  There is a given eligibility economy $E = (I,O,r,q,g)$.  
Let $\te_i \colon [0,r_i] \to O$ be a piecewise continuous function.  We wish to define the outcome for $i$ of following this eating function.  
Thus there is a sequence of times $0 = t_0 < t_1 < \cdots < t_{K-1} < t_K$ with $t_{K-1} < r_i \le t_K$, and for each $k = 0, \ldots, K-1$ there is a CEE $E_k$ with $E_0 = E$.  During the interval $[t_k,t_{k+1}]$ the process described above is followed beginning with $E_k$, and $E_{k+1}$ is the component of the simple decomposition of $E_k(t_{k+1})$ that contains $i$.  The overall allocation for $i$ is the sum of the allocations of the various stages.

Let $a$ be $i$'s favorite element of $\{\, o : g_{io} = r_i \,\}$.  Our main contention is that every eating function for $i$ that maximizes the overall allocation of $a$ for $i$ has $i$ eating $a$ at all times when $a$ is available to $i$.   Consider two eating functions for $i$, say $e_i$ and $e_i'$, that differ only insofar as $e_i'$ has $i$ eating something (say $x$) other than $a$ during an interval $[t_0 - \delta, t_0]$, while $e_i$ has $i$ eating $a$ during this interval.  Assume that under both eating functions, $i$ eats $a$ from $t_0$ until it becomes unavailable.  We claim that the total eating of $a$ by $i$ is greater under $e_i$ than under $e_i'$.  Equivalently, the time at which $a$ becomes unavailable to $i$ under $e_i'$ is less than $\delta$ plus the time at which $a$ becomes unavailable to $i$ under $e_i$.

Let $t_1 \in [t_0,r_i]$ be the first time such that $t_1 = r_i$, $q_a^{e_i}(t_1) = 0$, or there is a critical pair $(J_1,P_1)$ for $e_i$ with $a \in P_1$ and $i \in J_1^c$.   Let $t'_1 \in [t_0,r_i]$ be the first time such that $t_1' = r_i$, $q_a^{e_i'}(t_1') = 0$, or  there is a critical pair $(J_1',P_1')$ for $e_i'$ with $a \in P_1'$ and $i \in {J_1'}^c$.  During the interval $[t_0,\min\{t_1,t_1'\}]$ the events that change the availability of objects to agents are exhaustion of objects,  criticality of pairs $(J,P)$ with $a \in P$ and $i \in J$, and criticality of pairs $(J,P)$ with $a \in P^c$.  (Note that for such a pair we must have $i \in J^c$ because elements of $J$ are not able to consume objects outside of $P$.)  

Let $t^*$ be the greatest lower bound of the set of $t \in [t_0,\min\{t_1,t_1'\}]$ such that there is some $j \in I(t) \setminus \{i\}$ and $o \in O(t) \setminus \{a\}$ such that $o$ is available to $j$ under $e_i'$ but not under $e_i$.
For each $t \in [t_0,t^*]$, $j \ne i$, and $o \ne a$,  if $j$ was consumes $o$ at time $t$ under $e_i$, and $o$ is available to $j$ at time $t$ under $e_i'$, then $j$ is consuming $o$ at time $t$ under $e_i'$ because the set of things in $O \setminus \{a\}$ that are available to $j$ at time $t$ under $e_i'$ is a subset of the set of things  in $O \setminus \{a\}$ that are available to $j$ at time $t$ under $e_i$.

\medskip

\textit{
[This is not working.  Roughly, the problem is that when a pair $(J,P)$ becomes critical, the people in $J^c$ can no longer consume elements of $P \setminus \{a\}$, and this undoes the monotonicity argument we are trying to mount.  While the conjecture that no other eating function can equal or increase the overall onsumption of $a$ remains plausible, I see no way to prove it.]
}

\norev

We claim that at each time $t \in [t_0,\min\{t_1,t_1'\}]$, total consumption of each $o \in O \setminus \{a\}$ under $e_i'$ is weakly greater than under $e_i$, roughly because exhaustion of such objects and criticality of pairs $(J,P)$ with $a \in P^c$ occur weakly earlier under $e_i'$.  Formally, the first such event that does not occur at the same time for $e_i$ and $e_i'$ is either exhaustion of $x$ or criticality of a pair $(J,P)$ with $a \in P^c$ and $x \in P$.  We claim that from this time going forward,  for each $j \ne i$ and $o \in O \setminus \{a\}$, if $j$ was consuming $o$ under $e_i$, and $o$ is available to $j$ under $e_i'$, then $j$ is consuming $o$ under $e_i'$ because the set of things in $O \setminus \{a\}$ that are available to $j$ under $e_i'$ is a subset of the set of things  in $O \setminus \{a\}$ that are available to $j$ under $e_i$.  This implies that exhaustion of objects in $O \setminus \{a\}$  occurs weakly earlier under $e_i'$ than under $e_i$.  For each pair  $(J,P)$ with $a \in P^c$ , consumption of elements of $P$ by elements of $J^c$ is weakly greater under $e_i'$ than under $e_i$, so criticality of the pair occurs weakly earlier under $e_i'$ than under $e_i$.  Both of these considerations reinforce this reasoning.

To reiterate,  at each time $t \in [t_0,\min\{t_1,t_1'\}]$, total consumption of each $o \in O \setminus \{a\}$ under $e_i'$ is weakly greater than under $e_i$.  By material balance the aggregate increase in total consumption  of objects other than $a$ at time $t$ is $\delta$ minus the aggregate increase in consumption of $a$ by people other than $i$.

Suppose, for the sake of contradiction, that $t_1' < t_1$.  Of course $t_1' = r_i$ is impossible.  At all times in $[t_0,\min\{t_1,t_1'\}]$ total consumption of $a$ under $e_i'$ is not greater than total consumption under $e_i$, so $q_a^{e_i'}(t_1') = 0$ is impossible, and it must be that at time $t_1'$ total consumption of objects in $P_1'$ by agents outside $J_1'$ under $e_i'$ is enough to make $(J_1',P_1')$ critical under $e_i'$, but not under $e_1$.  Since the additional  consumption of objects in $P_1'$ by agents outside $J_1'$ under $e_i'$, in comparison with $e_i$, is not  greater than $\delta$ minus the additional consumption of $a$, this is not possible.

At $t_1$ there are several possibilities to consider.  If $t_1 = r_i$, then overall consumption of $a$ by $i$ under $e_i$ is greater than overall consumption of $a$ by $i$ under $e_i'$.  

If $q_a^{e_i}(t_1) = 0$, then the only way that overall consumption of $a$ by $i$ under $e_i'$ could even equal overall consumption of $a$ by $i$ under $e_i$ is that $t_1 + \delta$ is the first time such that $q_a^{e_i'}(t_1) = 0$.  This happens only if $i$ is the only agent who is eating $a$ during this interval and the set of agents eating $a$ at each time during $[t_0,t_1]$ is the same under $e_i$ and $e_i'$.  This set cannot decrease to $\{i\}$ unless there is a pair $(J_1,P_1)$ that is critical at $t_1$ under $e_1$, and $i$ is the only element of $J_1$ who was eating $a$ previously.

Next suppose that $(J_1,P_1)$ becomes critical at $t_1$ under $e_i$ and $i \in J_1^c$.   The only way that overall consumption of $a$ by $i$ under $e_i'$ could even equal overall consumption of $a$ by $i$ under $e_i$ is that $t_1 + \delta$ is the first time such that $(J_1,P_1)$ becomes critical under $e_i'$.  In order for this to happen it has to be the case that no one in $J_1$ is eating anything other than $a$, and that $i$ is the only person in $J_1$ eating $a$.  That is, at some time earlier $a$ became the only thing that $i$ could eat.  Of course that time must be after $t_0$.  

Finally  suppose that $(J_1,P_1)$ becomes critical at $t_1$ under $e_i$ and $i \in J_1$. This case should really be part of the analysis above.

\norev

Let $b$ be $i$'s second favorite element of $\{\, o : g_{io} = r_i \,\}$.  The logic of the argument above easily extends to show that among the eating functions for $i$ that maximize the overall allocation of $a$ for $i$, those that maximize the overall allocation of $b$ for $i$ have $i$ eating $b$ at every time when $a$ is not available and $b$ is.  Extending this inductively, if an function for $i$ results in an allocation for $i$ that stochastically dominates the allocation resulting from the GCPS mechanism, then it agrees with the eating function $e^{\succ_i}$ of the GCPS mechanism, and therefore the resulting allocation is the GCPS allocation, which is the assertion of Theorem \ref{th:WeakStrategyProof}.
